@article {Mary2022,
      author = "Mary Elston",
      title = "Becoming Turāth: the Islamic Tradition in the Modern Period",
      journal = "Die Welt des Islams",
      year = "2022",
      publisher = "Brill",
      address = "Leiden, The Netherlands",
      volume = "63",
      number = "4",
      doi = "10.1163/15700607-20220026",
      pages=      "441 - 473",
      url = "https://brill.com/view/journals/wdi/63/4/article-p441_003.xml"
}
@incollection{10.1093/oxfordhb/9780199696703.013.48,
    author = {Schmidtke, Sabine},
    isbn = {9780199696703},
    title = {Introduction},
    booktitle = {The Oxford Handbook of Islamic Theology},
    publisher = {Oxford University Press},
    year = {2016},
    month = {03},
    abstract = {This book explores the history of Islamic theology, with particular emphasis on the doctrinal thought of all the various intellectual strands of Islam that were concerned with theological issues—including groups such as the Ismāʿīlīs and philosophers. It also discusses the inter-communal exchanges between Muslim, Christian, and Jewish thinkers over the course of the centuries to show how the theological thought of Jews and Christians intertwined with that of Muslims, and how Muslim theological thinking was influenced by Christian methodologies of speculative reasoning and doctrinal concepts. The rest of the book considers the impact of political and social history on Islamic theology. This introduction provides an overview of the foundations of Islamic theology and the advances that have been made in the scholarly study of Islamic theology.},
    doi = {10.1093/oxfordhb/9780199696703.013.48},
    url = {https://doi.org/10.1093/oxfordhb/9780199696703.013.48},
    
}



@article {Jonathan2008,
      author = "Jonathan Brown",
      title = "How We Know Early Hadīth Critics Did Matn Criticism and Why It's So Hard to Find",
      journal = "Islamic Law and Society",
      year = "2008",
      publisher = "Brill",
      address = "Leiden, The Netherlands",
      volume = "15",
      number = "2",
      doi = "10.1163/156851908X290574",
      pages=      "143 - 184",
      url = "https://brill.com/view/journals/ils/15/2/article-p143_1.xml"
}
@book{rippin2022qur,
  title={The Qur'an and its interpretative tradition},
  author={Rippin, Andrew},
  year={2022},
  publisher={Routledge}
}
@inbook{Versteegh_2014, 
title={The Arabic Linguistic Tradition}, 
booktitle={The Arabic Language}, 
publisher={Edinburgh University Press}, author={Versteegh, Kees}, 
year={2014}, 
pages={107–125}
}

@article{bellino2014classification,
  title        = {The Classification of Sciences in an Ottoman Arabic Encyclopaedia: Ta{\c{s}}k{\"o}pr{\"u}z{\=a}de's {Mift{\=a}{\d{h}} al-Sa{\textquotesingle}{\=a}da}},
  author       = {Bellino, Francesca},
  journal      = {Quaderni di Studi Arabi},
  pages        = {161--180},
  year         = {2014}
}

@incollection{10.1093/acprof:oso/9780198090458.003.0003,
    author = {Alatas, Syed Farid},
    isbn = {9780198090458},
    title = {3 Ibn Khaldun on Education and Knowledge},
    booktitle = {Ibn Khaldun},
    publisher = {Oxford University Press},
    year = {2013},
    month = {05},
    abstract = {Chapter 3 discusses Ibn Khaldun’s thoughts on education and knowledge. The classification of knowledge in the classical Islamic tradition functioned as a guide to the range of sciences in existence at the time and the relationship between them. There was, therefore, a pedagogical dimension to the classification of sciences. Ibn Khaldun’s own classification, his distinction between the intellectual and transmitted sciences, and the strength and weaknesses of his scheme, are discussed. So too are his views on learning capacity, memorization, curriculum, strict teachers, and the breadth and depth of education. He was a keen observer of the relationship between education and society and saw education as having multiple objectives.},
    doi = {10.1093/acprof:oso/9780198090458.003.0003},
    url = {https://doi.org/10.1093/acprof:oso/9780198090458.003.0003},    
}




@article{J21,
title = {{T}he {A}rabic {O}ntology - {A}n {A}rabic {W}ordnet with {O}ntologically {C}lean {C}ontent},
author = {Mustafa Jarrar},
journal = {Applied Ontology Journal},
volume ={16},
number ={1},
pages = {1-26},
year = {2021},
publisher = {IOS Press},
doi = {10.3233/AO-200241}
}

@InProceedings{pmlr-v202-gao23f,
  title     = {{PAL}: Program-aided Language Models},
  author    = {Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  pages     = {10764--10799},
  year      = {2023},
  editor    = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume    = {202},
  series    = {Proceedings of Machine Learning Research},
  month     = {23--29 Jul},
  publisher = {PMLR},
  url       = {https://proceedings.mlr.press/v202/gao23f.html}
}

@article{Akkila2016-AKKPES,
  author  = {Alaa N. Akkila and Samy S. Abu Naser},
  title   = {Proposed Expert System for Calculating Inheritance in Islam},
  journal = {World Wide Journal of Multidisciplinary Research and Development},
  year    = {2016},
  volume  = {2},
  number  = {9},
  pages   = {38--48}
}

@inproceedings{lewis2020rag,
  author       = {Patrick Lewis and
                  Ethan Perez and
                  Aleksandra Piktus and
                  Fabio Petroni and
                  Vladimir Karpukhin and
                  Naman Goyal and
                  Heinrich K{\"{u}}ttler and
                  Mike Lewis and
                  Wen{-}tau Yih and
                  Tim Rockt{\"{a}}schel and
                  Sebastian Riedel and
                  Douwe Kiela},
  editor       = {Hugo Larochelle and
                  Marc'Aurelio Ranzato and
                  Raia Hadsell and
                  Maria{-}Florina Balcan and
                  Hsuan{-}Tien Lin},
  title        = {Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
  booktitle    = {Advances in Neural Information Processing Systems 33: Annual Conference
                  on Neural Information Processing Systems 2020, NeurIPS 2020, December
                  6--12, 2020, virtual},
  year         = {2020},
  url          = {https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html}
}

@inproceedings{petroni-etal-2021-kilt,
  title = "{KILT}: a Benchmark for Knowledge Intensive Language Tasks",
  author = {Petroni, Fabio and Piktus, Aleksandra and Fan, Angela and Lewis, Patrick and Yazdani, Majid and De Cao, Nicola and Thorne, James and Jernite, Yacine and Karpukhin, Vladimir and Maillard, Jean and Plachouras, Vassilis and Rockt{\"a}schel, Tim and Riedel, Sebastian},
  editor = "Toutanova, Kristina and Rumshisky, Anna and Zettlemoyer, Luke and Hakkani-Tur, Dilek and Beltagy, Iz and Bethard, Steven and Cotterell, Ryan and Chakraborty, Tanmoy and Zhou, Yichao",
  booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
  month = jun,
  year = "2021",
  address = "Online",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2021.naacl-main.200/",
  doi = "10.18653/v1/2021.naacl-main.200",
  pages = "2523--2544"
}

@inproceedings{gao-etal-2023-enabling,
  title = "Enabling Large Language Models to Generate Text with Citations",
  author = "Gao, Tianyu and Yen, Howard and Yu, Jiatong and Chen, Danqi",
  editor = "Bouamor, Houda and Pino, Juan and Bali, Kalika",
  booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
  month = dec,
  year = "2023",
  address = "Singapore",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2023.emnlp-main.398/",
  doi = "10.18653/v1/2023.emnlp-main.398",
  pages = "6465--6488"
}

@inproceedings{niu-etal-2024-ragtruth,
  title = "{RAGT}ruth: A Hallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models",
  author = "Niu, Cheng and Wu, Yuanhao and Zhu, Juno and Xu, Siliang and Shum, KaShun and Zhong, Randy and Song, Juntong and Zhang, Tong",
  editor = "Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek",
  booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  month = aug,
  year = "2024",
  address = "Bangkok, Thailand",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2024.acl-long.585/",
  doi = "10.18653/v1/2024.acl-long.585",
  pages = "10862--10878"
}

@article{wen-etal-2025-know,
  title = "Know Your Limits: A Survey of Abstention in Large Language Models",
  author = "Wen, Bingbing and Yao, Jihan and Feng, Shangbin and Xu, Chenjun and Tsvetkov, Yulia and Howe, Bill and Wang, Lucy Lu",
  journal = "Transactions of the Association for Computational Linguistics",
  volume = "13",
  year = "2025",
  address = "Cambridge, MA",
  publisher = "MIT Press",
  url = "https://aclanthology.org/2025.tacl-1.26/",
  doi = "10.1162/tacl_a_00754",
  pages = "529--556"
}

@inproceedings{wallat2025correctness,
  author    = {Jonas Wallat and Maria Heuss and Maarten de Rijke and Avishek Anand},
  title     = {Correctness is not Faithfulness in Retrieval Augmented Generation Attributions},
  booktitle = {Proceedings of the 2025 International ACM SIGIR Conference on Innovative Concepts and Theories in Information Retrieval (ICTIR '25)},
  year      = {2025},
  address   = {Padua, Italy},
  publisher = {ACM},
  doi       = {10.1145/3731120.3744592},
  url       = {https://doi.org/10.1145/3731120.3744592}
}

@article{mohammed2025aftina,
  author  = {Marryam Yahya Mohammed and Sama Ayman Ali and Salma Khaled Ali and Ayad Abdul Majeed and Ensaf Hussein Mohamed},
  title   = {Aftina: enhancing stability and preventing hallucination in AI-based Islamic fatwa generation using LLMs and {RAG}},
  journal = {Neural Computing and Applications},
  volume  = {37},
  number  = {25},
  pages   = {20957--20982},
  year    = {2025},
  doi     = {10.1007/S00521-025-11229-Y},
  url     = {https://doi.org/10.1007/s00521-025-11229-y}
}



@article{abouzied2025combating,
  title={Combating misinformation in the Arab World: Challenges and opportunities},
  author={Abouzied, Azza and Alam, Firoj and Ali, Raian and Papotti, Paolo},
  journal={Communications of the ACM},
  volume={68},
  number={10},
  pages={48--53},
  year={2025},
  publisher={ACM New York, NY, USA}
}

@article{alzubaidi2025evaluating,
  title={Evaluating Arabic Large Language Models: A Survey of Benchmarks, Methods, and Gaps},
  author={Alzubaidi, Ahmed and Alsuwaidi, Shaikha and Boussaha, Basma El Amel and AlQadi, Leen and Alkaabi, Omar and Alyafeai, Mohammed and Alobeidli, Hamza and Hacid, Hakim},
  journal={arXiv preprint arXiv:2510.13430},
  year={2025}
}
@inproceedings{rhel2025large,
  title={Large language models and arabic content: A review},
  author={Rhel, Haneh and Roussinov, Dmitri},
  booktitle={International Conference on AI: Current Research, Industry Trends, and Innovations},
  pages={402--419},
  year={2025},
  organization={Springer}
}
@article{mashaabi2024survey,
  title={A Survey of Large Language Models for Arabic Language and its Dialects},
  author={Mashaabi, Malak and Al-Khalifa, Shahad and Al-Khalifa, Hend},
  journal={arXiv preprint arXiv:2410.20238},
  year={2024}
}

@article{alnefaie2023islamic,
  title={Islamic question answering systems survey and evaluation criteria},
  author={Alnefaie, SSM and Atwell, Eric and Alsalka, Mohammad Ammar},
  journal={International Journal on Islamic Applications in Computer Science And Technology},
  volume={11},
  number={1},
  pages={9--18},
  year={2023},
  publisher={Design For Scientific Renaissance}
}

@article{Azmi2019,
  author  = {Azmi, Aqil M. and Al-Qabbany, Abdulaziz O. and Hussain, Amir},
  title   = {Computational and natural language processing based studies of hadith literature: a survey},
  journal = {Artificial Intelligence Review},
  year    = {2019},
  volume  = {52},
  number  = {2},
  pages   = {1369--1414},
  month   = aug,
  doi     = {10.1007/s10462-019-09692-w},
  url     = {https://doi.org/10.1007/s10462-019-09692-w},
  issn    = {1573-7462}
}

@article{Bashir2023,
  author  = {Bashir, Muhammad Huzaifa and Azmi, Aqil M. and Nawaz, Haq and Zaghouani, Wajdi and Diab, Mona and Al-Fuqaha, Ala and Qadir, Junaid},
  title   = {{Arabic} natural language processing for {Qur'anic} research: a systematic review},
  journal = {Artificial Intelligence Review},
  year    = {2023},
  volume  = {56},
  number  = {7},
  pages   = {6801--6854},
  month   = jul,
  doi     = {10.1007/s10462-022-10313-2},
  url     = {https://doi.org/10.1007/s10462-022-10313-2},
  issn    = {1573-7462}
}

@inproceedings{JH24,
title = {Qabas: An {O}pen-{S}ource {A}rabic {L}exicographic {D}atabase},
author = {Jarrar, Mustafa and Hammouda, Tymaa Hasanain},
booktitle = {Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
month = {May},
year = {2024},
address = {Torino, Italy},
publisher = {ELRA and ICCL},
pages = {13363--13370},
url={https://aclanthology.org/2024.lrec-main.1170.pdf}}

@techreport{AHJ25,
title = "{Q}uran{M}orph: {M}orphologically {A}nnotated {Q}uranic {C}orpus",
author = "Akra, Diyam and Hammouda, Tymaa and Jarrar, Mustafa",
year = {2025},
institution = {Birzeit University},
url = {https://arxiv.org/pdf/2506.18148}
}

@inproceedings{AEM25,
title = "{P}alm: {A} {C}ulturally {I}nclusive and {L}inguistically {D}iverse {D}ataset for {A}rabic {L}{L}{M}",
author = " Fakhraddin Alwajih and Abdellah El Mekki and Samar Mohamed Magdy and Abdelrahim A. Elmadany and Omer Nacar and El Moatez Billah Nagoudi and Reem Abdel-Salam and Hanin Atwany and Youssef Nafea and Abdulfattah Mohammed Yahya and Rahaf Alhamouri and Hamzah A. Alsayadi and Hiba Zayed and Sara Shatnawi and Serry Sibaee and Yasir Ech-Chammakhy and Walid Al-Dhabyani and Marwa Mohamed Ali and Imen Jarraya and Ahmed Oumar El-Shangiti and Aisha Alraeesi and Mohammed Anwar Al-Ghrawi and Abdulrahman S. Al-Batati and Elgizouli Mohamed and Noha Taha Elgindi and Muhammed Saeed and Houdaifa Atou and Issam Ait Yahia and Abdelhak Bouayad and Mohammed Machrouh and Amal Makouar and Dania Alkawi and Mukhtar Mohamed and Safaa Taher Abdelfadil and Amine Ziad Ounnoughene and Rouabhia Anfel and Rwaa Assi and Ahmed Sorkatti and Mohamedou Cheikh Tourad and Anis Koubaa and Ismail Berrada and Mustafa Jarrar and Shady Shehata and Muhammad Abdul-Mageed",
booktitle = {Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics},
address = {Vienna, Austria},
month = {August},
year = {2025},
publisher = {Association for Computational Linguistics},
url = {https://arxiv.org/pdf/2503.00151},
}

@article{sukkar2024analytical,
  author  = {Ahmad W. Sukkar and Mohamed W. Fareed and Moohammed Wasim Yahia and Salem Buhashima Abdalla and Iman Ibrahim and Khaldoun Abdul Karim Senjab},
  title   = {Analytical Evaluation of Midjourney Architectural Virtual Lab: Defining Major Current Limits in {AI}-Generated Representations of Islamic Architectural Heritage},
  journal = {Buildings},
  year    = {2024},
  volume  = {14},
  number  = {3},
  pages   = {786},
  doi     = {10.3390/buildings14030786}
}

@article{ashour2025heritage,
  author  = {Ayman Fathy Ashour and Wael Rashdan},
  title   = {Heritage-Aware Generative {AI} Workflow for Islamic Geometry in Interiors},
  journal = {Heritage},
  year    = {2025},
  volume  = {8},
  number  = {11},
  pages   = {486},
  doi     = {10.3390/heritage8110486}
}

@article{sumayli2025handwritten,
  author  = {Afnan Sumayli and Mohamed Alkaoud},
  title   = {Handwritten Arabic Calligraphy Generation: A Systematic Literature Review},
  journal = {International Journal of Advanced Computer Science and Applications},
  year    = {2025},
  volume  = {16},
  number  = {3},
  doi     = {10.14569/IJACSA.2025.0160381}
}

@inproceedings{elsharif2025arapic,
  author    = {Wala Adil Osman Elsharif and Mahmood Alzubaidi and James She and Marco Agus},
  title     = {Ara-Pic: A Framework for Enhancing Arabic Cultural Representation in {AI}-Generated Images},
  booktitle = {2025 {IEEE} International Conference on Multimedia and Expo Workshops ({ICMEW})},
  year      = {2025},
  doi       = {10.1109/ICMEW68306.2025.11152135}
}

@inproceedings{gurer2025textextraction,
  author    = {Dilara Zeynep G\"urer and \"Umit Atlamaz and {\c{S}}aziye Bet\"ul \"Ozate{\c{s}}},
  title     = {Text Extraction and Script Completion in Images of Arabic Script-Based Calligraphy: A Thesis Proposal},
  booktitle = {Proceedings of the 2025 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop},
  year      = {2025},
  publisher = {Association for Computational Linguistics}
}

@inproceedings{elsharif2024cri,
  author    = {Wala Adil Osman Elsharif and Marco Agus and Mahmoud Alzubaidi and James She},
  title     = {Cultural Relevance Index: Measuring Cultural Relevance in {AI}-Generated Images},
  booktitle = {2024 {IEEE} 7th International Conference on Multimedia Information Processing and Retrieval ({MIPR})},
  year      = {2024},
  doi       = {10.1109/MIPR62202.2024.00071}
}

@inproceedings{hassan-bhatti-etal-2025-cultranai,
    title = "{C}ultran{AI} at {P}alm{X} 2025: Data Augmentation for Cultural Knowledge Representation",
    author = "Hassan Bhatti, Hunzalah  and
      Ahmed, Youssef  and
      Arid Hasan, Md  and
      Alam, Firoj",
    editor = "Darwish, Kareem  and
      Ali, Ahmed  and
      Abu Farha, Ibrahim  and
      Touileb, Samia  and
      Zitouni, Imed  and
      Abdelali, Ahmed  and
      Al-Ghamdi, Sharefah  and
      Alkhereyf, Sakhar  and
      Zaghouani, Wajdi  and
      Khalifa, Salam  and
      AlKhamissi, Badr  and
      Almatham, Rawan  and
      Hamed, Injy  and
      Alyafeai, Zaid  and
      Alowisheq, Areeb  and
      Inoue, Go  and
      Mrini, Khalil  and
      Alshammari, Waad",
    booktitle = "Proceedings of The Third Arabic Natural Language Processing Conference: Shared Tasks",
    month = nov,
    year = "2025",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.arabicnlp-sharedtasks.111/",
    doi = "10.18653/v1/2025.arabicnlp-sharedtasks.111",
    pages = "809--817",
    ISBN = "979-8-89176-356-2",
    abstract = ""
}
@inproceedings{tajrin-etal-2025-aya,
    title = "{AYA} at {P}alm{X} 2025: Modeling Cultural and Islamic Knowledge in {LLM}s",
    author = "Tajrin, Jannatul  and
      Ballav Roy, Bir  and
      Alam, Firoj",
    editor = "Darwish, Kareem  and
      Ali, Ahmed  and
      Abu Farha, Ibrahim  and
      Touileb, Samia  and
      Zitouni, Imed  and
      Abdelali, Ahmed  and
      Al-Ghamdi, Sharefah  and
      Alkhereyf, Sakhar  and
      Zaghouani, Wajdi  and
      Khalifa, Salam  and
      AlKhamissi, Badr  and
      Almatham, Rawan  and
      Hamed, Injy  and
      Alyafeai, Zaid  and
      Alowisheq, Areeb  and
      Inoue, Go  and
      Mrini, Khalil  and
      Alshammari, Waad",
    booktitle = "Proceedings of The Third Arabic Natural Language Processing Conference: Shared Tasks",
    month = nov,
    year = "2025",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.arabicnlp-sharedtasks.114/",
    doi = "10.18653/v1/2025.arabicnlp-sharedtasks.114",
    pages = "830--836",
    ISBN = "979-8-89176-356-2",
    abstract = ""
}

@article{page2021prisma,
  title={The {PRISMA} 2020 statement: an updated guideline for reporting systematic reviews},
  author={Page, Matthew J and McKenzie, Joanne E and Bossuyt, Patrick M and Boutron, Isabelle and Hoffmann, Tammy C and Mulrow, Cynthia D and Shamseer, Larissa and Tetzlaff, Jennifer M and Akl, Elie A and Brennan, Sue E and others},
  journal = {BMJ},
  volume={372},
  year={2021},
  publisher={British Medical Journal Publishing Group}
}
@article{hui2025trident,
  title    = {{TRIDENT}: Benchmarking LLM Safety in Finance, Medicine, and Law},
  author   = {Hui, Zheng and Dong, Yijiang River and Shareghi, Ehsan and Collier, Nigel},
  journal  = {arXiv preprint arXiv:2507.21134},
  year     = {2025},
  url      = {https://arxiv.org/abs/2507.21134}
}



@inproceedings{hendrycks2021aligning,
  title     = {Aligning AI With Shared Human Values},
  author    = {Hendrycks, Dan and Burns, Collin and Basart, Steven and Critch, Andrew and Li, Jerry and Song, Dawn and Steinhardt, Jacob},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2021},
  url       = {https://openreview.net/forum?id=dNy_RKzJacY}
}

@inproceedings{bhatia-etal-2025-swan,
    title = "Swan and {A}rabic{MTEB}: Dialect-Aware, {A}rabic-Centric, Cross-Lingual, and Cross-Cultural Embedding Models and Benchmarks",
    author = "Bhatia, Gagan  and
      Nagoudi, El Moatez Billah  and
      El Mekki, Abdellah  and
      Alwajih, Fakhraddin  and
      Abdul-Mageed, Muhammad",
    editor = "Chiruzzo, Luis  and
      Ritter, Alan  and
      Wang, Lu",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2025",
    month = apr,
    year = "2025",
    address = "Albuquerque, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-naacl.263/",
    doi = "10.18653/v1/2025.findings-naacl.263",
    pages = "4654--4670",
    ISBN = "979-8-89176-195-7",
    abstract = "In this paper, we introduce Swan, a family of embedding models centred around the Arabic language, addressing both small-scale and large-scale use cases. Swan includes two variants: Swan-Small, based on ARBERTv2, and Swan-Large, built on ArMistral, a pretrained Arabic large language model. To evaluate these models, we propose ArabicMTEB, a comprehensive benchmark suite that assesses cross-lingual, multi-dialectal, multi-domain, and multi-cultural Arabic text embedding performance, covering eight diverse tasks and spanning 94 datasets. Swan-Large achieves state-of-the-art results, outperforming Multilingual-E5-large in most Arabic tasks, while the Swan-Small consistently surpasses Multilingual-E5-base. Our extensive evaluations demonstrate that Swan models are dialectally and culturally aware, excelling across various Arabic domains while offering significant monetary efficiency. This work significantly advances the field of Arabic language modelling and provides valuable resources for future research and applications in Arabic natural language processing. Our models and benchmarks will be made publicly accessible for research."
}


@inproceedings{atif2025sacred,
  title={Sacred or Synthetic? Evaluating LLM Reliability and Abstention for Religious Questions},
  author={Atif, Farah and Askarbekuly, Nursultan and Darwish, Kareem and Choudhury, Monojit},
  booktitle={Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
  volume={8},
  number={1},
  pages={217--226},
  year={2025}
}
@article{c,
  title={{PerHalluEval}: Persian Hallucination Evaluation Benchmark for Large Language Models},
  author={Hosseini, Mohammad and Hosseini, Kimia and Bali, Shayan and Zanjani, Zahra and Momtazi, Saeedeh},
  journal={arXiv preprint arXiv:2509.21104},
  year={2025}
}
@inproceedings{alansari2025arahallueval,
  title     = "{A}ra{H}allu{E}val: A Fine-grained Hallucination Evaluation Framework for {A}rabic {LLM}s",
  author    = "Alansari, Aisha and Luqman, Hamzah",
  editor    = "Darwish, Kareem and Ali, Ahmed and Abu Farha, Ibrahim and Touileb, Samia and Zitouni, Imed and Abdelali, Ahmed and Al-Ghamdi, Sharefah and Alkhereyf, Sakhar and Zaghouani, Wajdi and Khalifa, Salam and AlKhamissi, Badr and Almatham, Rawan and Hamed, Injy and Alyafeai, Zaid and Alowisheq, Areeb and Inoue, Go and Mrini, Khalil and Alshammari, Waad",
  booktitle = "Proceedings of The Third Arabic Natural Language Processing Conference",
  month     = nov,
  year      = "2025",
  address   = "Suzhou, China",
  publisher = "Association for Computational Linguistics",
  url       = "https://aclanthology.org/2025.arabicnlp-main.12/",
  doi       = "10.18653/v1/2025.arabicnlp-main.12",
  pages     = "148--161",
  isbn      = "979-8-89176-352-4"
}

@inproceedings{guo2025care,
  title     = "{CARE}: Multilingual Human Preference Learning for Cultural Awareness",
  author    = "Guo, Geyang  and
               Naous, Tarek  and
               Wakaki, Hiromi  and
               Nishimura, Yukiko  and
               Mitsufuji, Yuki  and
               Ritter, Alan  and
               Xu, Wei",
  editor    = "Christodoulopoulos, Christos  and
               Chakraborty, Tanmoy  and
               Rose, Carolyn  and
               Peng, Violet",
  booktitle = "Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing",
  month     = nov,
  year      = "2025",
  address   = "Suzhou, China",
  publisher = "Association for Computational Linguistics",
  url       = "https://aclanthology.org/2025.emnlp-main.1669/",
  doi       = "10.18653/v1/2025.emnlp-main.1669",
  pages     = "32854--32883",
  isbn      = "979-8-89176-332-6"
}

@inproceedings{plaza-del-arco2024divine,
  title     = "Divine {LL}a{MA}s: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models",
  author    = "Plaza-del-Arco, Flor Miriam  and
               Curry, Amanda Cercas  and
               Paoli, Susanna  and
               Cercas Curry, Alba  and
               Hovy, Dirk",
  editor    = "Al-Onaizan, Yaser  and
               Bansal, Mohit  and
               Chen, Yun-Nung",
  booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
  month     = nov,
  year      = "2024",
  address   = "Miami, Florida, USA",
  publisher = "Association for Computational Linguistics",
  url       = "https://aclanthology.org/2024.findings-emnlp.251/",
  doi       = "10.18653/v1/2024.findings-emnlp.251",
  pages     = "4346--4366"
}

@inproceedings{mubarak-etal-2025-islamiceval,
    title = "{I}slamic{E}val 2025: The First Shared Task of Capturing {LLM}s Hallucination in Islamic Content",
    author = "Mubarak, Hamdy  and
      Malhas, Rana  and
      Mansour, Watheq  and
      Mohamed, Abubakr  and
      Fawzi, Mahmoud  and
      Hawasly, Majd  and
      Elsayed, Tamer  and
      Darwish, Kareem Mohamed  and
      Magdy, Walid",
    editor = "Darwish, Kareem  and
      Ali, Ahmed  and
      Abu Farha, Ibrahim  and
      Touileb, Samia  and
      Zitouni, Imed  and
      Abdelali, Ahmed  and
      Al-Ghamdi, Sharefah  and
      Alkhereyf, Sakhar  and
      Zaghouani, Wajdi  and
      Khalifa, Salam  and
      AlKhamissi, Badr  and
      Almatham, Rawan  and
      Hamed, Injy  and
      Alyafeai, Zaid  and
      Alowisheq, Areeb  and
      Inoue, Go  and
      Mrini, Khalil  and
      Alshammari, Waad",
    booktitle = "Proceedings of The Third Arabic Natural Language Processing Conference: Shared Tasks",
    month = nov,
    year = "2025",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.arabicnlp-sharedtasks.67/",
    doi = "10.18653/v1/2025.arabicnlp-sharedtasks.67",
    pages = "480--493",
    ISBN = "979-8-89176-356-2",
    abstract = "Hallucination in Large Language Models (LLMs) remains a significant challenge and continues to draw substantial research attention. The problem becomes especially critical when hallucinations arise in sensitive domains, such as religious discourse. To address this gap, we introduce IslamicEval 2025{---}the first shared task specifically focused on evaluating and detecting hallucinations in Islamic content. The task consists of two subtasks: (1) Hallucination Detection and Correction of quoted verses (Ayahs) from the Holy Quran and quoted Hadiths; and (2) Qur{'}an and Hadith Question Answering, which assesses retrieval models and LLMs by requiring answers to be retrieved from grounded, authoritative sources. Thirteen teams participated in the final phase of the shared task, employing a range of pipelines and frameworks. Their diverse approaches underscore both the complexity of the task and the importance of effectively managing hallucinations in Islamic discourse."
}

@misc{2025halluverse25benchmark,
	title        = {
		HalluVerse25: Fine-grained Multilingual Benchmark Dataset for LLM
		Hallucinations
	},
	author       = {Samir Abdaljalil and Hasan Kurban and Erchin Serpedin},
	year         = {2025},
	url          = {https://arxiv.org/abs/2503.07833},
	journal       = {2503.07833},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{3C3H,
	title        = {Rethinking LLM Evaluation with 3C3H: AraGen Benchmark and Leaderboard},
	author       = {
		El Filali, Ali and Sengupta, Neha and Abouelseoud and Nakov, Preslav and
		Fourrier, Clémentine
	},
	year         = {2024},
	publisher    = {AraGEN},
	howpublished = {\url{https://https://huggingface.co/blog/leaderboard-3c3h-aragen}}
}

@article{alwaneen2022arabicqa,
  title   = {Arabic question answering system: a survey},
  author  = {Alwaneen, Tahani H. and Azmi, Aqil M. and Aboalsamh, Hatim A. and Cambria, Erik and Hussain, Amir},
  journal = {Artificial Intelligence Review},
  volume  = {55},
  pages   = {207--253},
  year    = {2022},
  doi     = {10.1007/s10462-021-10031-1},
  note    = {Published online 12 July 2021},
  url     = {https://link.springer.com/article/10.1007/s10462-021-10031-1}
}

@article{alkhurayyif2023comprehensive,
  title   = {A comprehensive survey of techniques for developing an Arabic question answering system},
  author  = {Alkhurayyif, Yazeed and Sait, Abdul Rahaman Wahab},
  journal = {PeerJ Computer Science},
  volume  = {9},
  pages   = {e1413},
  year    = {2023},
  month   = jun,
  doi     = {10.7717/peerj-cs.1413},
  url     = {https://peerj.com/articles/cs-1413/}
}

@article{gallegos-etal-2024-bias,
  title     = {Bias and Fairness in Large Language Models: A Survey},
  author    = {Gallegos, Isabel O. and Rossi, Ryan A. and Barrow, Joe and Tanjim, Md Mehrab and Kim, Sungchul and Dernoncourt, Franck and Yu, Tong and Zhang, Ruiyi and Ahmed, Nesreen K.},
  journal   = {Computational Linguistics},
  volume    = {50},
  number    = {3},
  month     = sep,
  year      = {2024},
  address   = {Cambridge, MA},
  publisher = {MIT Press},
  url       = {https://aclanthology.org/2024.cl-3.8/},
  doi       = {10.1162/coli_a_00524},
  pages     = {1097--1179}
}

@article{chu2024fairness,
  title   = {Fairness in Large Language Models: A Taxonomic Survey},
  author  = {Chu, Zhibo and Wang, Zichong and Zhang, Wenbin},
  journal = {SIGKDD Explorations Newsletter},
  volume  = {26},
  number  = {1},
  pages   = {34--48},
  year    = {2024},
  month   = jun,
  doi     = {10.1145/3682112},
  url     = {https://kdd.org/exploration_files/p34-Fairness_in_Large_Language_Models_A_Taxonomic_Survey_camera-ready.pdf}
}

@article{hakim2023aiislamicstudies,
  title   = {Artificial Intelligence in Teaching Islamic Studies: Challenges and Opportunities},
  author  = {Hakim, Abdul and Anggraini, Pauli},
  journal = {Molang: Journal Islamic Education},
  volume  = {1},
  number  = {2},
  pages   = {19--30},
  year    = {2023},
  doi     = {10.32806/jm.v1i2.619},
  url     = {https://jurnalalkhairat.org/ojs/index.php/molang/article/view/619}
}

@article{alhammad2025integrating,
  title   = {Integrating Artificial Intelligence in Islamic Education: A Review on Pedagogical Approaches and Learning Outcomes},
  author  = {Alhammad, Noorjihan and Awae, Fareed and Yussuf, Ahmad},
  journal = {International Journal of Academic Research in Business and Social Sciences},
  volume  = {15},
  number  = {7},
  pages   = {563--579},
  year    = {2025},
  doi     = {10.6007/IJARBSS/v15-i7/25947}
}

@article{ahmad2025aiquraniceducation,
  title   = {Artificial Intelligence (AI) In Quranic Education: Systematic Review},
  author  = {Ahmad, K. A. and Shohibuddin, W. A. J. and Eldeib, A. A. M.},
  journal = {Quranica},
  volume  = {14},
  number  = {1},
  pages   = {58--69},
  year    = {2025},
  url     = {https://ejournal.um.edu.my/index.php/quranica/article/view/64955}
}
@article{Yudiono_Permadi_2025, 
title={Artificial Intelligence and Spirituality: Can AI Understand the Divine in Sufism?}, 
volume={1}, 
url={https://suhu.lakaspia.org/index.php/suhu/article/view/28}, 
abstract={
Amid the rapid advancement of artificial intelligence (AI) across various domains of life, philosophical and theological questions arise regarding the limitations of AI in understanding the spiritual dimensions of human existence, particularly within the tradition of Islamic Sufism. This research aims to explore the ability of AI to comprehend and represent transcendental spiritual meanings, and to analyze the limitations of AI from spiritual and metaphysical perspectives. Using a qualitative phenomenological approach, data were collected through documentations. The findings reveal that although AI is capable of mimicking religious knowledge verbally, it remains fundamentally incapable of grasping and reflecting esoteric aspects of Sufism, such as the experiential connection with the Divine, due to its lack of consciousness, intuition, and spiritual essence. True spiritual meaning can only be accessed through inner experience and spiritual practice —not through algorithmic processes. In conclusion, this study affirms that artificial intelligence cannot replace the role of spiritual experience in Sufism and highlights the need for a humanistic and ethical approach in the development of technology. The research contributes to the interdisciplinary discourse between Sufism, Islamic philosophy, and modern technology, offering a critical reflection on the epistemological boundaries of AI in religious contexts.
}, number={1}, journal={SUHU: Journal of Sufism and Humanities}, year={2025}, month={Apr.}, pages={19–30},
author = {
    Iqbal Ramadhan Irsyad Yudiono and Danur Putut Permadi
}

}

@misc{iajit2025ai_islamicstudies_systematicreview,
  title        = {Applications of Artificial Intelligence in Islamic Studies (2010--2025): A Systematic Review of Methodologies, Empirical Outcomes, and Research Gaps},
  journal = {Manuscript submission to the International Arab Journal of Information Technology (IAJIT), Manuscript ID: IAJIT-2025-08-950},
  year         = {2025},
  month        = aug,
  url          = {https://www.ejmanager.com/mnstemps/259/259-1756467969-REV.pdf},
  note         = {Submission date: 29-Aug-2025. The publicly accessible manuscript file does not include author metadata.}
}
@article{abdul2024nadi,
	title        = {Nadi 2024: The fifth nuanced arabic dialect identification shared task},
	author       = {
		Abdul-Mageed, Muhammad and Keleg, Amr and Elmadany, AbdelRahim and Zhang,
		Chiyu and Hamed, Injy and Magdy, Walid and Bouamor, Houda and Habash, Nizar
	},
	year         = {2024},
	journal      = {arXiv preprint arXiv:2407.04910}
}
@inproceedings{abdulmageed2021arbert,
	title        = {{ARBERT} \& {MARBERT}: Deep Bidirectional Transformers for {A}rabic},
	author       = {
		Abdul-Mageed, Muhammad and Elmadany, AbdelRahim and Nagoudi, El Moatez Billah
	},
	year         = {2021},
	booktitle    = {
		Proceedings of the 59th Annual Meeting of the Association for Computational
		Linguistics and the 11th International Joint Conference on Natural Language
		Processing (Volume 1: Long Papers)
	},
	publisher    = {Association for Computational Linguistics},
	pages        = {7088--7105}
}
@article{abidin2021arabic,
	title        = {
		Arabic Language Learning Model Through Extracurricular Activities At Wali
		Songo Islamic Boarding School Ngabar Ponorogo
	},
	author       = {N. Abidin},
	year         = {2021},
	url          = {
		https://www.semanticscholar.org/paper/c7228b7df05109842a600e4d897e03da504f1ef3
	},
	abstract     = {
		The Wali Songo Islamic Boarding School located in the village of Ngabar
		Ponorogo which was established in 1961 is one of the cottages that implement
		Arabic language learning that combines formal and non-formal education.
		Non-formal education is carried out by teaching Arabic through
		extracurricular activities. The combination of these two learning models has
		proven to be able to produce alumni who are proficient in Arabic, both
		written and spoken.The type of research conducted by researchers in this
		study is qualitative. While the data acquisition is obtained in the field
		directly at the location of the data source. Data were also obtained from
		observations, interviews, and documentation.The purpose of this research is
		to find out what models have been implemented by Boarding School, how the
		implementation of the model, and how the results of the application of the
		model. So that this model is expected to be developed by the Boarding School
		and can inspire other institutions to improve the quality of Arabic learning
		for their students.The results of this study conclude that the Wali Songo
		Ngabar Islamic Boarding School in improving Arabic language skills, learning
		is not only delivered in class, but Arabic learning is applied and taught
		outside of class hours through extracurricular activities. There are several
		models of extracurricular activities in Arabic learning that are designed and
		have been practiced at the Wali Songo Islamic Boarding School Ngabar, namely:
		Ilqoul Mufrodat Jadidah (delivery of new vocabulary), Muhadatsah
		(conversation), Muhadhoroh (speech), Idhof lughowi (language tutoring),
		Shohafiyah (journalism), and Fanniyatul khoth (writing).
	},
	source       = {semantic_scholar}
}
@misc{harvey2020_factsheet_islam,
  author    = {Harvey, Sarah},
  title     = {Factsheet: Islam},
  date      = {2020-09-30},
year         = {2020},
  url       = {https://religionmediacentre.org.uk/factsheets/islam/},
  urldate   = {2026-01-10},
  publisher = {{Religion Media Centre}}
}
@misc{britannica2026_islam,
  author       = {Mahdi, Muhsin S.},
  title        = {Islam},
  howpublished = {\url{https://www.britannica.com/topic/Islam}},
  note         = {Encyclopaedia Britannica. Last updated 2026-01-05. Accessed 2026-01-10},
  year         = {2026}
}


@misc{absher2025,
	title        = {
		Absher: A Benchmark for Evaluating Large Language Models’ Understanding of
		Saudi Dialects
	},
	author       = {
		Al-Monef, Renad and Alhuzali, Hassan and Alturayeif, Nora and Alasmari,
		Ashwag
	},
	year         = {2025},
	url          = {https://arxiv.org/abs/2507.10216},
	journal       = {2507.10216},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@article{afif2024enhancing,
	title        = {
		Enhancing Student Motivation in Arabic Language Learning through the
		Cooperative Integrated Reading and Composition (CIRC) Model: A Case Study in
		Islamic Schools of Banten
	},
	author       = {Nur Afif},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/188abef8059c0437f47ce94f8f63725977691ce4
	},
	abstract     = {
		Arabic language proficiency is vital in Islamic education to understand
		religious texts and strengthen connections to Islamic heritage. Despite its
		importance, motivation in learning Arabic often remains low among students.
		This study aims to evaluate the Cooperative Integrated Reading and
		Composition (CIRC) model’s effectiveness in enhancing student motivation in
		Arabic language learning. A quasi-experimental design with a pretest-posttest
		control group was employed, involving 60 students from Islamic schools in
		Banten. Participants were divided equally into an experimental group, taught
		using the CIRC model, and a control group, which followed conventional
		methods. Data were collected through validated motivation scales, classroom
		observations, and interviews. The experimental group demonstrated a
		significant increase in motivation scores, from an average of 62.5 to 80.3,
		compared to a smaller improvement in the control group (61.7 to 65.4).
		Observational data revealed greater student engagement, active participation,
		and collaborative efforts in the CIRC group. Interviews confirmed that the
		collaborative elements of the CIRC model fostered enthusiasm, peer
		interaction, and confidence among students. The findings underscore the CIRC
		model’s potential to create an engaging and interactive learning environment,
		enhancing student motivation in Arabic language classes. The collaborative
		framework of CIRC appears to address diverse student needs effectively.
		Implementing the CIRC model in Islamic schools could significantly improve
		Arabic language learning outcomes. Future studies should explore its
		long-term impact on language proficiency and application across various
		subjects and educational contexts.
	},
	source       = {semantic_scholar}
}
@article{aftab2025enhancing,
	title        = {
		Enhancing Quranic Ethics and Morality: An NLP- Based Semantic Search Model
		for Urdu Translation
	},
	author       = {Yasir Aftab and Dr. Muhammad Arshad Awan and Danish Khaleeq and Tehmima Ismail},
	year         = {2025},
	url          = {
		https://www.semanticscholar.org/paper/03ec0af0712fbb4e0b5acb846d52487da6f1af82
	},
	abstract     = {
		he Quran offers unparalleled guidance on ethics and morality, but extracting
		relevant teachings from its Urdu translations remains a challenge due to
		conventional keyword-based search methods that lack contextual understanding.
		This research proposes a Natural Language Processing (NLP)--based query model
		designed to improve the retrieval of Quranic verses related to ethics and
		morality in Urdu translations. By integrating Sentence Transformers for
		semantic search and a custom synonym expansion module, the model enhances
		accuracy and relevance in retrieving verses. The dataset widely accepted Urdu
		translation of the Quran, and the system is evaluated using precision,
		recall,and relevance scoring metrics to ensure effectiveness. The study
		demonstrates how NLP techniques can bridge the gap between traditional
		Quranic studies and modern computational methods, providing scholars,
		educators, and researchers with an advanced tool for exploring Quranic
		ethics. The proposed system achieves high precision and recall, offering a
		more effective approach to Quranic verse retrieval compared to conventional
		keyword-based searches. The research also highlights future opportunities for
		expanding the model to support multiple languages and broader thematic
		searches, further enhancing accessibility to Quranic knowledge.
	},
	source       = {semantic_scholar},
    journal      =
    {International Journal of Agriculture and Sustainable Development}
}
@misc{AIAstrolabe2025,
	title        = {Redteaming Frontier LLMs with AI Astrolabe Arabic Safety Index (ASAS)},
	author       = {aiastrolabe},
	year         = {2025},
	month        = apr,
	note         = {Accessed: Oct. 3, 2025}
}
@article{al-ani2024the,
	title        = {The Holy Quran},
	author       = {Asma Abdul-Qader Abdullah Al-Ani, Imad Abdul-Karim Saleem Al-Khasawneh},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/d15deb526ca59e3d8891e32bf18b6bad9f994e14
	},
	abstract     = {
		This paper provides an editorial reflection on the enduring relevance of the
		Holy Quran as a foundational text in Islam. The Quran, which is believed to
		be the word of God as revealed to the Prophet Muhammad, serves as a
		comprehensive guide for Muslims in both spiritual and worldly matters. It
		addresses ethical dilemmas, social justice, governance, and personal conduct,
		offering timeless wisdom for modern society. The paper explores the structure
		of the Quran, its literary and linguistic excellence, and its profound impact
		on Islamic civilization. Furthermore, it delves into the various
		interpretations of the Quran and discusses its continued relevance in
		addressing contemporary global issues such as social justice, environmental
		ethics, and interfaith dialogue.
	},
	source       = {semantic_scholar},
journal={Mesopotamian journal of Quran studies}
}
@article{al2024ahd,
	title        = {AHD: Arabic healthcare dataset},
	author       = {Al-Majmar, Nashwan Ahmed and Gawbah, Hezam and Alsubari, Akram},
	year         = {2024},
	journal      = {Data in Brief},
	publisher    = {Elsevier},
	volume       = {56},
	pages        = {110855}
}
@article{al2024qiyas,
	title        = {
		The Qiyas Benchmark: Measuring ChatGPT Mathematical and Language
		Understanding in Arabic
	},
	author       = {Al-Khalifa, Shahad and Al-Khalifa, Hend},
	year         = {2024},
	journal      = {arXiv preprint arXiv:2407.00146}
}
@article{alagrami2020smartajweed,
	title        = {Smartajweed Automatic Recognition of Arabic Quranic Recitation Rules},
	author       = {Ali M. Alagrami, Maged M. Eljazzar},
	year         = {2020},
	url          = {http://arxiv.org/abs/2101.04200v1},
	abstract     = {
		Tajweed is a set of rules to read the Quran in a correct Pronunciation of the
		letters with all its Qualities, while Reciting the Quran. which means you
		have to give every letter in the Quran its due of characteristics and apply
		it to this particular letter in this specific situation while reading, which
		may differ in other times. These characteristics include melodic rules, like
		where to stop and for how long, when to merge two letters in pronunciation or
		when to stretch some, or even when to put more strength on some letters over
		other. Most of the papers focus mainly on the main recitation rules and the
		pronunciation but not (Ahkam AL Tajweed) which give different rhythm and
		different melody to the pronunciation with every different rule of (Tajweed).
		Which is also considered very important and essential in Reading the Quran as
		it can give different meanings to the words. In this paper we discuss in
		detail full system for automatic recognition of Quran Recitation Rules
		(Tajweed) by using support vector machine and threshold scoring system
	},
	source       = {arxiv}
}
@inproceedings{alangari2025nn,
	title        = {
		{N\&N} at {QIAS} 2025: Chain-of-Thought Ensembles with Retrieval-Augmented
		framework for Classical Arabic Islamic {MCQ}s
	},
	author       = {Alangari, N. and Team, N\&N},
	year         = {2025},
	booktitle    = {Proceedings of the ArabicNLP 2025 Shared Tasks},
	publisher    = {Association for Computational Linguistics}
}
@inproceedings{alasmari2024aramed,
	title        = {
		Aramed: Arabic medical question answering using pretrained transformer
		language models
	},
	author       = {Alasmari, Ashwag and Alhumoud, Sarah and Alshammari, Waad},
	year         = {2024},
	booktitle    = {
		Proceedings of the 6th Workshop on Open-Source Arabic Corpora and Processing
		Tools (OSACT) with Shared Tasks on Arabic LLMs Hallucination and Dialect to
		MSA Machine Translation@ LREC-COLING 2024
	},
	pages        = {50--56}
}
@article{alballaa2025gatmath,
	title        = {
		GATmath and GATLc: Comprehensive benchmarks for evaluating Arabic large
		language models
	},
	author       = {
		AlBallaa, Safa and AlTwairesh, Nora and AlSalman, Abdulmalik and Alfarhood,
		Sultan
	},
	year         = {2025},
	journal      = {PLoS One},
	publisher    = {Public Library of Science San Francisco, CA USA},
	volume       = {20},
	number       = {9},
	pages        = {e0329129}
}
@article{aleid2025hajj,
	title        = {
		Hajj-FQA: A benchmark Arabic dataset for developing question-answering
		systems on Hajj fatwas: H. Aleid and A. Azmi
	},
	author       = {Aleid, Hayfa A and Azmi, Aqil M},
	year         = {2025},
	journal      = {Journal of King Saud University Computer and Information Sciences},
	publisher    = {Springer},
	volume       = {37},
	number       = {6},
	pages        = {135}
}
@article{alghallabi2025fann,
	title        = {
		Fann or Flop: A Multigenre, Multiera Benchmark for Arabic Poetry
		Understanding in LLMs
	},
	author       = {
		Alghallabi, Wafa and Thawkar, Ritesh and Ghaboura, Sara and More, Ketan and
		Thawakar, Omkar and Cholakkal, Hisham and Khan, Salman and Anwer, Rao
		Muhammad
	},
	year         = {2025},
	journal      = {arXiv preprint arXiv:2505.18152}
}

@inproceedings{alghamdi-etal-2025-aratrust,
    title = "{A}ra{T}rust: An Evaluation of Trustworthiness for {LLM}s in {A}rabic",
    author = "Alghamdi, Emad A.  and
      Masoud, Reem I.  and
      Alnuhait, Deema  and
      Alomairi, Afnan Y.  and
      Ashraf, Ahmed  and
      Zaytoon, Mohamed",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.579/",
    pages = "8664--8679",
    abstract = "The swift progress and widespread acceptance of artificial intelligence (AI) systems highlight a pressing requirement to comprehend both the capabilities and potential risks associated with AI. Given the linguistic complexity, cultural richness, and underrepresented status of Arabic in AI research, there is a pressing need to focus on Large Language Models (LLMs) performance and safety for Arabic related tasks. Despite some progress in their development, there is a lack of comprehensive trustworthiness evaluation benchmarks which presents a major challenge in accurately assessing and improving the safety of LLMs when prompted in Arabic. In this paper, we introduce AraTrust, the first comprehensive trustworthiness benchmark for LLMs in Arabic. AraTrust comprises 522 human-written multiple-choice questions addressing diverse dimensions related to truthfulness, ethics, privacy, illegal activities, mental health, physical health, unfairness, and offensive language. We evaluated a set of LLMs against our benchmark to assess their trustworthiness. GPT-4 was the most trustworthy LLM, while open-source models, particularly AceGPT 7B and Jais 13B, struggled to achieve a score of 60{\%} in our benchmark. The benchmark dataset is publicly available at https://huggingface.co/datasets/asas-ai/AraTrust"
}

@misc{alghamdi2024aratrustevaluationtrustworthinessllms,
	title        = {AraTrust: An Evaluation of Trustworthiness for LLMs in Arabic},
	author       = {
		Emad A. Alghamdi and Reem I. Masoud and Deema Alnuhait and Afnan Y. Alomairi
		and Ahmed Ashraf and Mohamed Zaytoon
	},
	year         = {2024},
	url          = {https://arxiv.org/abs/2403.09017},
	journal       = {2403.09017},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@article{alkaoud2024bilingual,
	title        = {A bilingual benchmark for evaluating large language models},
	author       = {Alkaoud, Mohamed},
	year         = {2024},
	journal      = {PeerJ Computer Science},
	publisher    = {PeerJ Inc.},
	volume       = {10},
	pages        = {e1893}
}
@article{allandscape,
	title        = {The Landscape of Arabic Large Language Models},
	author       = {Al-Khalifa, Shahad and Durrani, Nadir and Al-Khalifa, Hend and Alam, Firoj},
	year         = {2025},
	journal      = {Communications of the ACM},
	publisher    = {ACM New York, NY}
}
@inproceedings{almazrouei-etal-2023-alghafa,
	title        = {{A}l{G}hafa Evaluation Benchmark for {A}rabic Language Models},
	author       = {
		Almazrouei, Ebtesam  and Cojocaru, Ruxandra  and Baldo, Michele  and
		Malartic, Quentin  and Alobeidli, Hamza  and Mazzotta, Daniele  and Penedo,
		Guilherme  and Campesan, Giulia  and Farooq, Mugariya  and Alhammadi, Maitha
		and Launay, Julien  and Noune, Badreddine
	},
	year         = {2023},
	month        = dec,
	booktitle    = {Proceedings of ArabicNLP 2023},
	publisher    = {Association for Computational Linguistics},
	address      = {Singapore (Hybrid)},
	pages        = {244--275},
	doi          = {10.18653/v1/2023.arabicnlp-1.21},
	url          = {https://aclanthology.org/2023.arabicnlp-1.21/},
	editor       = {
		Sawaf, Hassan  and El-Beltagy, Samhaa  and Zaghouani, Wajdi  and Magdy, Walid
		and Abdelali, Ahmed  and Tomeh, Nadi  and Abu Farha, Ibrahim  and Habash,
		Nizar  and Khalifa, Salam  and Keleg, Amr  and Haddad, Hatem  and Zitouni,
		Imed  and Mrini, Khalil  and Almatham, Rawan
	}
}
@inproceedings{alqasida2025,
	title        = {
		AL-QASIDA: Analyzing LLM Quality and Accuracy Systematically in Dialectal
		Arabic
	},
	author       = {
		Robinson, Nathaniel R. and Abdelmoneim, Shahd and Marchisio, Kelly and Ruder,
		Sebastian
	},
	year         = {2025},
	booktitle    = {Findings of the Association for Computational Linguistics: ACL 2025},
	url          = {https://aclanthology.org/2025.findings-acl.1137.pdf}
}
@article{alshaikh2025aratable,
  title={{AraTable}: Benchmarking {LLMs}' Reasoning and Understanding of Arabic Tabular Data},
  author={Alshaikh, Rana and Alghanmi, Israa and Jeawak, Shelan},
  journal={arXiv preprint arXiv:2507.18442},
  year={2025}
}
@misc{alshaikh2025aratablebenchmarkingllmsreasoning,
	title        = {
		AraTable: Benchmarking LLMs' Reasoning and Understanding of Arabic Tabular
		Data
	},
	author       = {Rana Alshaikh and Israa Alghanmi and Shelan Jeawak},
	year         = {2025},
	url          = {https://arxiv.org/abs/2507.18442},
	journal       = {2507.18442},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{alwajih2024peacockfamilyarabicmultimodal,
	title        = {Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks},
	author       = {
		Fakhraddin Alwajih and El Moatez Billah Nagoudi and Gagan Bhatia and
		Abdelrahman Mohamed and Muhammad Abdul-Mageed
	},
	year         = {2024},
	url          = {https://arxiv.org/abs/2403.01031},
	journal       = {2403.01031},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@article{ameen2024ai,
	title        = {AI model for Parsing the Text of Holy Quran Sentences},
	author       = {Haval H. Ameen, A. Khidhir},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/b2bad1b1231ed4d1a2f07a08c21c91fc6c194e74
	},
	abstract     = {
		The Holy Quran is of immense importance to many societies due to the position
		that this book holds for Muslims around the world and the religious teachings
		it contains. The Holy Quran employs a high-standard Arabic language, which
		requires analysis and simplification of expressions to enhance comprehension
		and application of its teachings. The digitization and combining of the Holy
		Quran with computing operations have made it easier to discover the vast
		amounts of information contained within its verses. Using these applications,
		academics and erudite researchers have successfully developed norms that
		govern the study of Qur'anic knowledge, thus expanding the illustration of
		the Quran. NLP is a well-known branch of study that has been the subject of
		research for many years. The intrinsic intricacy of this field has resulted
		in slower progress when compared to other areas of inquiry. Furthermore,
		despite having the most sophisticated syntax, structure, and verb conjugation
		of all-natural languages, Arabic has received comparatively little attention.
		As a result, there is an urgent need for study in this area to aid in the
		discovery of inclusive lexical knowledge. This research is concerned with the
		parsing of holy Quranic sentences. A neural network was used Consisting of
		two layers to training the token word attribute depending on the neural
		network input words characteristics. This research is based on a knowledge
		base that consists of 160 features was used, and 26 features related to the
		grammatical case were selected. The first group comprised an entered dataset
		with 128,221 rows, whereas the second group had 99.540 rows. We ran seven
		different experiments within each group and achieved a 96% accuracy rate.
		This accuracy was reached by using a training set size of 90,000 rows and a
		testing set size of 9,000 rows. Furthermore, we achieved 94% accuracy within
		the broader dataset of 128,221 rows by employing a training set size of
		90,000 rows and a testing set size of 38,000 rows.
	},
	source       = {semantic_scholar},
    journal      = {arxiv}
}
@misc{anonymous2025cameleval,
	title        = {
		CamelEval: Advancing Culturally Aligned Arabic Language Models and Benchmarks
	},
	author       = {Zhaozhi Qian and Faroq Altam and Muhammad Alqurishi and Riad Souissi},
	year         = {2024},
	url          = {https://arxiv.org/abs/2409.12623},
	journal       = {2409.12623},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@inproceedings{antoun-etal-2021-aragpt2,
	title        = {{A}ra{GPT}2: Pre-Trained Transformer for {A}rabic Language Generation},
	author       = {Antoun, Wissam  and Baly, Fady  and Hajj, Hazem},
	year         = {2021},
	month        = apr,
	booktitle    = {Proceedings of the Sixth Arabic Natural Language Processing Workshop},
	publisher    = {Association for Computational Linguistics},
	address      = {Kyiv, Ukraine (Virtual)},
	pages        = {196--207},
	url          = {https://aclanthology.org/2021.wanlp-1.21/},
	editor       = {
		Habash, Nizar  and Bouamor, Houda  and Hajj, Hazem  and Magdy, Walid  and
		Zaghouani, Wajdi  and Bougares, Fethi  and Tomeh, Nadi  and Abu Farha,
		Ibrahim  and Touileb, Samia
	}
}
@inproceedings{antoun2020arabert,
	title        = {AraBERT: Transformer-based Model for Arabic Language Understanding},
	author       = {Antoun, Wissam and Baly, Fady and Hajj, Hazem},
	year         = {2020},
	booktitle    = {
		Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing
		Tools, with a Shared Task on Offensive Language Detection
	},
	publisher    = {European Language Resources Association (ELRA)},
	pages        = {9--15}
}
@misc{arabic-gsm8k,
	title        = {Arabic GSM8K: Arabic Grade School Math Dataset},
	author       = {Omartificial-Intelligence-Space},
	year         = {2025},
	howpublished = {
		\url{https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-gsm8k-v2}
	}
}
@inproceedings{aradice2025,
	title        = {{A}ra{D}i{CE}: Benchmarks for Dialectal and Cultural Capabilities in {LLM}s},
	author       = {
		Mousi, Basel  and Durrani, Nadir  and Ahmad, Fatema  and Hasan, Md. Arid  and
		Hasanain, Maram  and Kabbani, Tameem  and Dalvi, Fahim  and Chowdhury,
		Shammur Absar  and Alam, Firoj
	},
	year         = {2025},
	month        = jan,
	booktitle    = {
		Proceedings of the 31st International Conference on Computational Linguistics
	},
	publisher    = {Association for Computational Linguistics},
	address      = {Abu Dhabi, UAE},
	pages        = {4186--4218},
	url          = {https://aclanthology.org/2025.coling-main.283/},
	editor       = {
		Rambow, Owen  and Wanner, Leo  and Apidianaki, Marianna  and Al-Khalifa, Hend
		and Eugenio, Barbara Di  and Schockaert, Steven
	}
}

@inproceedings{ashraf-etal-2025-arabic,
    title = "{A}rabic Dataset for {LLM} Safeguard Evaluation",
    author = "Ashraf, Yasser  and
      Wang, Yuxia  and
      Gu, Bin  and
      Nakov, Preslav  and
      Baldwin, Timothy",
    editor = "Chiruzzo, Luis  and
      Ritter, Alan  and
      Wang, Lu",
    booktitle = "Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = apr,
    year = "2025",
    address = "Albuquerque, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.naacl-long.285/",
    doi = "10.18653/v1/2025.naacl-long.285",
    pages = "5529--5546",
    ISBN = "979-8-89176-189-6",
    abstract = "The growing use of large language models (LLMs) has raised concerns regarding their safety. While many studies have focused on English, the safety of LLMs in Arabic, with its linguistic and cultural complexities, remains under-explored. Here, we aim to bridge this gap. In particular, we present an Arab-region-specific safety evaluation dataset consisting of 5,799 questions, including direct attacks, indirect attacks, and harmless requests with sensitive words, adapted to reflect the socio-cultural context of the Arab world. To uncover the impact of different stances in handling sensitive and controversial topics, we propose a dual-perspective evaluation framework. It assesses the LLM responses from both governmental and opposition viewpoints. Experiments over five leading Arabic-centric and multilingual LLMs reveal substantial disparities in their safety performance. This reinforces the need for culturally specific datasets to ensure the responsible deployment of LLMs."
}

@misc{ashraf2025arabicdatasetllmsafeguard,
	title        = {Arabic Dataset for LLM Safeguard Evaluation},
	author       = {
		Yasser Ashraf and Yuxia Wang and Bin Gu and Preslav Nakov and Timothy Baldwin
	},
	year         = {2025},
	url          = {https://arxiv.org/abs/2410.17040},
	journal       = {2410.17040},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}

@article{aslam2023universal,
	title        = {Universal Language Modelling agent},
	author       = {Aneesa Aslam},
	year         = {2023},
	url          = {
		https://www.semanticscholar.org/paper/a89398dbe455796abf9398241e397d3753544ef2
	},
	abstract     = {
		Large Language Models are designed to understand complex Human Language. Yet,
		Understanding of animal language has long intrigued researchers striving to
		bridge the communication gap between humans and other species. This research
		paper introduces a novel approach that draws inspiration from the linguistic
		concepts found in the Quran, a revealed Holy Arabic scripture dating back
		1400 years. By exploring the linguistic structure of the Quran, specifically
		the components of ism, fil, and harf, we aim to unlock the underlying
		intentions and meanings embedded within animal conversations using audio
		data. To unravel the intricate complexities of animal language, we employ
		word embedding techniques to analyze each distinct frequency component. This
		methodology enables the identification of potential correlations and the
		extraction of meaningful insights from the data. Furthermore, we leverage a
		bioacoustics model to generate audio, which serves as a valuable resource for
		training natural language processing (NLP) techniques. This Paper aims to
		find the intention* behind animal language rather than having each word
		translation.
	},
	source       = {semantic_scholar}
}
@article{atabik2023life,
	title        = {
		Life Skills Approach in Arabic Language Learning at Islamic Boarding
		School-Based Madrasah Aliyah
	},
	author       = {Atabik Atabik, M. Yahya, Mustajab Mustajab},
	year         = {2023},
	url          = {
		https://www.semanticscholar.org/paper/3b36a46acbe82d5f4ffe50aa8b5a95175e9e9450
	},
	abstract     = {
		This study aimed to find a life skills approach to learning Arabic in Islamic
		boarding schools based on Islamic high schools. This research is field
		research using qualitative methods. The location of this research is the
		Islamic boarding school-based Madrasah Aliyah. Using the form of observation,
		interviews and documentation in collecting data. As for analyzing the data,
		researchers carried out several stages of analysis, starting from data
		collection, reduction, review and evaluation. The results of this study cover
		two aspects, namely first, the Arabic language learning curriculum
		implemented in MA Salafiyah and MA Darussangadah is an integrated curriculum
		between the curriculum of the Ministry of Religion and the curriculum of
		Islamic boarding schools, based on classical studies and modern books with a
		language learning orientation. Arabic language actively or passively. Second,
		the Arabic language learning model at Madrasah Aliyah is based on Islamic
		boarding schools in Kebumen Regency, namely (1) Arabic learning at MA
		Salafiyah Wonoyoso is more oriented towards maharah lughawiyah (istima',
		kalam, qira'ah, and kitabah) as the basis of student competence. The process
		of learning Arabic is taught by integrating the four maharah lugawiyah
		through learning Arabic subjects, religious subjects, and linguistic
		practices in Islamic boarding schools; (2) Learning Arabic at MA
		Darussangadah develops learning Arabic that is oriented towards active and
		passive communication skills. This active communication skill is the skill of
		using spoken and written language. At the same time, the passive ability is
		the skill of understanding Arabic reading and other people's speech.
	},
	source       = {semantic_scholar}
}
@article{atabik2024arabic,
	title        = {
		Arabic Language Learning Models in Schools: A Comparative Study of Islamic
		Boarding School-Based Madrasah Aliyah in The Kebumen, Indonesia
	},
	author       = {Atabik, M. Yahya, Mustajab},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/f21489b022f78c03d2f971f51c21d4a22f9de73b
	},
	abstract     = {
		There are variances in learning Arabic across different institutions, such as
		Islamic boarding schools and Madrasah Aliyah. The objective of this study is
		to identify the similarities and distinctions across Arabic language learning
		models at Islamic boarding schools in Kebumen, Central Java, Indonesia. The
		focus of the research is restricted to MA Salafiyah and MA Yapika, which are
		the prominent Islamic schools in the Kebumen district. The research findings
		encompass two key aspects. Firstly, the Arabic language learning curriculum
		at MA Yapika and MA Salafiyah is a comprehensive curriculum that combines the
		Ministry of Religion curriculum with the Islamic boarding school curriculum.
		Secondly, the Arabic language learning model at the Islamic boarding
		school-based Madrasah Aliyah in Kebumen district consists of two approaches.
		(1) MA Yapika applies an Active Arabic Language Learning strategy (Active
		Learning) with specific practical objectives. (2) MA Salafiyah Wonoyoso
		focuses more on developing maharah lughawiyah (listening, speaking, reading,
		and writing) as the foundation of student competence.
	},
	source       = {semantic_scholar}
}
@misc{austin2021programsynthesislargelanguage,
	title        = {Program Synthesis with Large Language Models},
	author       = {
		Jacob Austin and Augustus Odena and Maxwell Nye and Maarten Bosma and Henryk
		Michalewski and David Dohan and Ellen Jiang and Carrie Cai and Michael Terry
		and Quoc Le and Charles Sutton
	},
	year         = {2021},
	url          = {https://arxiv.org/abs/2108.07732},
	journal       = {2108.07732},
	archiveprefix = {arXiv},
	primaryclass = {cs.PL}
}
@article{bahaj2025mizanqa,
	title        = {
		MizanQA: Benchmarking Large Language Models on Moroccan Legal Question
		Answering
	},
	author       = {Bahaj, Adil and Ghogho, Mounir},
	year         = {2025},
	journal      = {arXiv preprint arXiv:2508.16357}
}
@misc{balsam,
	title        = {BALSAM: A Platform for Benchmarking Arabic Large Language Models},
	author       = {
		Rawan Al-Matham and Kareem Darwish and Raghad Al-Rasheed and Waad Alshammari
		and Muneera Alhoshan and Amal Almazrua and Asma Al Wazrah and Mais Alheraki
		and Firoj Alam and Preslav Nakov and Norah Alzahrani and Eman alBilali and
		Nizar Habash and Abdelrahman El-Sheikh and Muhammad Elmallah and Haonan Li
		and Hamdy Mubarak and Mohamed Anwar and Zaid Alyafeai and Ahmed Abdelali and
		Nora Altwairesh and Maram Hasanain and Abdulmohsen Al Thubaity and Shady
		Shehata and Bashar Alhafni and Injy Hamed and Go Inoue and Khalid Elmadani
		and Ossama Obeid and Fatima Haouari and Tamer Elsayed and Emad Alghamdi and
		Khalid Almubarak and Saied Alshahrani and Ola Aljarrah and Safa Alajlan and
		Areej Alshaqarawi and Maryam Alshihri and Sultana Alghurabi and Atikah
		Alzeghayer and Afrah Altamimi and Abdullah Alfaifi and Abdulrahman AlOsaimy
	},
	year         = {2025},
	url          = {https://arxiv.org/abs/2507.22603},
	journal       = {2507.22603},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}

@article{balula2021automatic,
	title        = {
		Automatic Speech Recognition (ASR) Systems for Learning Arabic Language and
		Al-Quran Recitation: A Review
	},
	author       = {Nazik O’mar Balula, M. Rashwan, S. Abdou},
	year         = {2021},
	url          = {
		https://www.semanticscholar.org/paper/14c916e5000f9c0b2107afdd65016ca5058335f9
	},
	abstract     = {
		This paper provides a literature survey about Automatic Speech Recognition
		(ASR) systems for learning Arabic language and Al-Quran Recitation. The
		growth in communication technologies and AI (specially Machine learning and
		Deep learning) led researchers in ASR field to thinking of and developing ASR
		systems which mimic humans in their understand of natural speech and
		recognition. One of the most important applications in ASR is natural
		language processing (NLP). Arabic language is one of these languages. ASR
		systems which developed for Arabic language help Arabs and non-Arabs in
		learning Arabic language and so Al-Quran recitation and memorization in
		proper way according to recitation rules (Tajweed). This paper concentrate on
		ASR systems in general, challenges, PROS, CONS, Arabic language ASR systems
		and challenges faced them and finally Al-Quran recitation verification
		systems.
	},
	source       = {semantic_scholar}
}

@inproceedings{bari2024allamlargelanguagemodels,
	title        = {{ALL}aM: Large Language Models for Arabic and English},
	author       = {
		M Saiful Bari and Yazeed Alnumay and Norah A. Alzahrani and Nouf M. Alotaibi
		and Hisham Abdullah Alyahya and Sultan AlRashed and Faisal Abdulrahman Mirza
		and Shaykhah Z. Alsubaie and Hassan A. Alahmed and Ghadah Alabduljabbar and
		Raghad Alkhathran and Yousef Almushayqih and Raneem Alnajim and Salman
		Alsubaihi and Maryam Al Mansour and Saad Amin Hassan and Dr. Majed Alrubaian
		and Ali Alammari and Zaki Alawami and Abdulmohsen Al-Thubaity and Ahmed
		Abdelali and Jeril Kuriakose and Abdalghani Abujabal and Nora Al-Twairesh and
		Areeb Alowisheq and Haidar Khan
	},
	year         = {2025},
	booktitle    = {The Thirteenth International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=MscdsFVZrN}
}

@article{liu2024measuring,
Author        = {Songyuan Liu and Ziyang Zhang and Runze Yan and Wei Wu and Carl Yang and Jiaying Lu},
Title         = {Measuring Spiritual Values and Bias of Large Language Models},
Journal       = {2410.11647v2},
ArchivePrefix = {arXiv},
PrimaryClass  = {cs.CL},
Abstract      = {Large language models (LLMs) have become integral tool for users from various backgrounds. LLMs, trained on vast corpora, reflect the linguistic and cultural nuances embedded in their pre-training data. However, the values and perspectives inherent in this data can influence the behavior of LLMs, leading to potential biases. As a result, the use of LLMs in contexts involving spiritual or moral values necessitates careful consideration of these underlying biases. Our work starts with verification of our hypothesis by testing the spiritual values of popular LLMs. Experimental results show that LLMs' spiritual values are quite diverse, as opposed to the stereotype of atheists or secularists. We then investigate how different spiritual values affect LLMs in social-fairness scenarios e.g., hate speech identification). Our findings reveal that different spiritual values indeed lead to different sensitivity to different hate target groups. Furthermore, we propose to continue pre-training LLMs on spiritual texts, and empirical results demonstrate the effectiveness of this approach in mitigating spiritual bias.},
Year          = {2024},
Month         = {Oct},
Note          = {in Proceedings of KDD 2025 SciSoc LLM Workshop},
Url           = {http://arxiv.org/abs/2410.11647v2},
File          = {2410.11647v2.pdf}
}

@article{zhong2024opportunities,
Author        = {Tianyang Zhong and Zhenyuan Yang and Zhengliang Liu and Ruidong Zhang and Yiheng Liu and Haiyang Sun and Yi Pan and Yiwei Li and Yifan Zhou and Hanqi Jiang and Junhao Chen and Tianming Liu},
Title         = {Opportunities and Challenges of Large Language Models for Low-Resource Languages in Humanities Research},
Journal       = {2412.04497v3},
ArchivePrefix = {arXiv},
PrimaryClass  = {cs.CL},
Abstract      = {Low-resource languages serve as invaluable repositories of human history, embodying cultural evolution and intellectual diversity. Despite their significance, these languages face critical challenges, including data scarcity and technological limitations, which hinder their comprehensive study and preservation. Recent advancements in large language models (LLMs) offer transformative opportunities for addressing these challenges, enabling innovative methodologies in linguistic, historical, and cultural research. This study systematically evaluates the applications of LLMs in low-resource language research, encompassing linguistic variation, historical documentation, cultural expressions, and literary analysis. By analyzing technical frameworks, current methodologies, and ethical considerations, this paper identifies key challenges such as data accessibility, model adaptability, and cultural sensitivity. Given the cultural, historical, and linguistic richness inherent in low-resource languages, this work emphasizes interdisciplinary collaboration and the development of customized models as promising avenues for advancing research in this domain. By underscoring the potential of integrating artificial intelligence with the humanities to preserve and study humanity's linguistic and cultural heritage, this study fosters global efforts towards safeguarding intellectual diversity.},
Year          = {2024},
Month         = {Nov},
Url           = {http://arxiv.org/abs/2412.04497v3},
File          = {2412.04497v3.pdf}
}


"@article{kucuk2023western,
Author        = {Eyup Engin Kucuk and Muhammed Yusuf Kocyigit},
Title         = {Western, Religious or Spiritual: An Evaluation of Moral Justification in Large Language Models},
Journal       = {2311.07792v1},
ArchivePrefix = {arXiv},
PrimaryClass  = {cs.CY},
Abstract      = {The increasing success of Large Language Models (LLMs) in variety of tasks lead to their widespread use in our lives which necessitates the examination of these models from different perspectives. The alignment of these models to human values is an essential concern in order to establish trust that we have safe and responsible systems. In this paper, we aim to find out which values and principles are embedded in LLMs in the process of moral justification. For this purpose, we come up with three different moral perspective categories: Western tradition perspective (WT), Abrahamic tradition perspective (AT), and Spiritualist/Mystic tradition perspective (SMT). In two different experiment settings, we asked models to choose principles from the three for suggesting a moral action and evaluating the moral permissibility of an action if one tries to justify an action on these categories, respectively. Our experiments indicate that tested LLMs favors the Western tradition moral perspective over others. Additionally, we observe that there potentially exists an over-alignment towards religious values represented in the Abrahamic Tradition, which causes models to fail to recognize an action is immoral if it is presented as a ""religious-action"". We believe that these results are essential in order to direct our attention in future efforts.},
Year          = {2023},
Month         = {Nov},
Url           = {http://arxiv.org/abs/2311.07792v1},
File          = {2311.07792v1.pdf}
}"
"@article{ridoy2025bengalimoralbench,
Author        = {Shahriyar Zaman Ridoy and Azmine Toushik Wasi and Koushik Ahamed Tonmoy},
Title         = {BengaliMoralBench: A Benchmark for Auditing Moral Reasoning in Large Language Models within Bengali Language and Culture},
Journal       = {2511.03180v1},
ArchivePrefix = {arXiv},
PrimaryClass  = {cs.CL},
Abstract      = {As multilingual Large Language Models (LLMs) gain traction across South Asia, their alignment with local ethical norms, particularly for Bengali, which is spoken by over 285 million people and ranked 6th globally, remains underexplored. Existing ethics benchmarks are largely English-centric and shaped by Western frameworks, overlooking cultural nuances critical for real-world deployment. To address this, we introduce BengaliMoralBench, the first large-scale ethics benchmark for the Bengali language and socio-cultural contexts. It covers five moral domains, Daily Activities, Habits, Parenting, Family Relationships, and Religious Activities, subdivided into 50 culturally relevant subtopics. Each scenario is annotated via native-speaker consensus using three ethical lenses: Virtue, Commonsense, and Justice ethics. We conduct systematic zero-shot evaluation of prominent multilingual LLMs, including Llama, Gemma, Qwen, and DeepSeek, using a unified prompting protocol and standard metrics. Performance varies widely (50-91% accuracy), with qualitative analysis revealing consistent weaknesses in cultural grounding, commonsense reasoning, and moral fairness. BengaliMoralBench provides a foundation for responsible localization, enabling culturally aligned evaluation and supporting the deployment of ethically robust AI in diverse, low-resource multilingual settings such as Bangladesh.},
Year          = {2025},
Month         = {Nov},
Url           = {http://arxiv.org/abs/2511.03180v1},
File          = {2511.03180v1.pdf}
}"
"@article{asl2025farsiqa,
Author        = {Mohammad Aghajani Asl and Behrooz Minaei Bidgoli},
Title         = {FARSIQA: Faithful and Advanced RAG System for Islamic Question Answering},
Journal       = {2510.25621v1},
ArchivePrefix = {arXiv},
PrimaryClass  = {cs.CL},
Abstract      = {The advent of Large Language Models (LLMs) has revolutionized Natural Language Processing, yet their application in high-stakes, specialized domains like religious question answering is hindered by challenges like hallucination and unfaithfulness to authoritative sources. This issue is particularly critical for the Persian-speaking Muslim community, where accuracy and trustworthiness are paramount. Existing Retrieval-Augmented Generation (RAG) systems, relying on simplistic single-pass pipelines, fall short on complex, multi-hop queries requiring multi-step reasoning and evidence aggregation. To address this gap, we introduce FARSIQA, a novel, end-to-end system for Faithful Advanced Question Answering in the Persian Islamic domain. FARSIQA is built upon our innovative FAIR-RAG architecture: a Faithful, Adaptive, Iterative Refinement framework for RAG. FAIR-RAG employs a dynamic, self-correcting process: it adaptively decomposes complex queries, assesses evidence sufficiency, and enters an iterative loop to generate sub-queries, progressively filling information gaps. Operating on a curated knowledge base of over one million authoritative Islamic documents, FARSIQA demonstrates superior performance. Rigorous evaluation on the challenging IslamicPCQA benchmark shows state-of-the-art performance: the system achieves a remarkable 97.0% in Negative Rejection - a 40-point improvement over baselines - and a high Answer Correctness score of 74.3%. Our work establishes a new standard for Persian Islamic QA and validates that our iterative, adaptive architecture is crucial for building faithful, reliable AI systems in sensitive domains.},
Year          = {2025},
Month         = {Oct},
Url           = {http://arxiv.org/abs/2510.25621v1},
File          = {2510.25621v1.pdf}
}"
"@article{kröger2025don't,
Author        = {Paul Kröger and Emilio Barkett},
Title         = {Don't Change My View: Ideological Bias Auditing in Large Language Models},
Journal       = {2509.12652v1},
ArchivePrefix = {arXiv},
PrimaryClass  = {cs.CL},
Abstract      = {As large language models (LLMs) become increasingly embedded in products used by millions, their outputs may influence individual beliefs and, cumulatively, shape public opinion. If the behavior of LLMs can be intentionally steered toward specific ideological positions, such as political or religious views, then those who control these systems could gain disproportionate influence over public discourse. Although it remains an open question whether LLMs can reliably be guided toward coherent ideological stances and whether such steering can be effectively prevented, a crucial first step is to develop methods for detecting when such steering attempts occur. In this work, we adapt a previously proposed statistical method to the new context of ideological bias auditing. Our approach carries over the model-agnostic design of the original framework, which does not require access to the internals of the language model. Instead, it identifies potential ideological steering by analyzing distributional shifts in model outputs across prompts that are thematically related to a chosen topic. This design makes the method particularly suitable for auditing proprietary black-box systems. We validate our approach through a series of experiments, demonstrating its practical applicability and its potential to support independent post hoc audits of LLM behavior.},
Year          = {2025},
Month         = {Sep},
Url           = {http://arxiv.org/abs/2509.12652v1},
File          = {2509.12652v1.pdf}
}"
@article{bashir2021arabic,
	title        = {
		Arabic natural language processing for Qur’anic research: a systematic review
	},
	author       = {
		Bashir, Muhammad Huzaifa and Azmi, Aqil M and Nawaz, Haq and Zaghouani, Wajdi
		and Diab, Mona
	},
	year         = {2021},
	journal      = {Artificial Intelligence Review},
	publisher    = {Springer},
	volume       = {56},
	number       = {Suppl 1},
	pages        = {13951--13993}
}
@inproceedings{benayed2025comparative,
	title        = {A Comparative Study of Arabic Embedding Models in RAG-Based Fatwa Retrieval},
	author       = {Ben Ayed, Hassan and Najari, Montassar and Makni, W. and Samet, Hekmet},
	year         = {2025},
	booktitle    = {ResearchGate},
	note         = {Conference Paper}
}


@article{wang2025do,
  abstract = {As the demand for emotional intelligence in large language models (LLMs) grows, a key challenge lies in understanding the internal mechanisms that give rise to emotional expression and in controlling emotions in generated text. This study addresses three core questions: (1) Do LLMs contain context-agnostic mechanisms shaping emotional expression? (2) What form do these mechanisms take? (3) Can they be harnessed for universal emotion control? We first construct a controlled dataset, SEV (Scenario-Event with Valence), to elicit comparable internal states across emotions. Subsequently, we extract context-agnostic emotion directions that reveal consistent, cross-context encoding of emotion (Q1). We identify neurons and attention heads that locally implement emotional computation through analytical decomposition and causal analysis, and validate their causal roles via ablation and enhancement interventions. Next, we quantify each sublayer's causal influence on the model's final emotion representation and integrate the identified local components into coherent global emotion circuits that drive emotional expression (Q2). Directly modulating these circuits achieves 99.65% emotion-expression accuracy on the test set, surpassing prompting- and steering-based methods (Q3). To our knowledge, this is the first systematic study to uncover and validate emotion circuits in LLMs, offering new insights into interpretability and controllable emotional intelligence.},
  archiveprefix = {arXiv},
  author = {Chenxi Wang and Yixuan Zhang and Ruiji Yu and Yufei Zheng and Lang Gao and Zirui Song and Zixiang Xu and Gus Xia and Huishuai Zhang and Dongyan Zhao and Xiuying Chen},
  file = {2510.11328v1.pdf},
  journal = {2510.11328v1},
  month = {Oct},
  primaryclass = {cs.CL},
  title = {Do LLMs ""Feel""? Emotion Circuits Discovery and Control},
  url = {http://arxiv.org/abs/2510.11328v1},
  year = {2025},
}

@article{jiashen2025are,
  abstract = {One open question in the study of Large Language Models (LLMs) is whether they can emulate human ethical reasoning and act as believable proxies for human judgment. To investigate this, we introduce a benchmark dataset comprising 196 real-world ethical dilemmas and expert opinions, each segmented into five structured components: Introduction, Key Factors, Historical Theoretical Perspectives, Resolution Strategies, and Key Takeaways. We also collect non-expert human responses for comparison, limited to the Key Factors section due to their brevity. We evaluate multiple frontier LLMs (GPT-4o-mini, Claude-3.5-Sonnet, Deepseek-V3, Gemini-1.5-Flash) using a composite metric framework based on BLEU, Damerau-Levenshtein distance, TF-IDF cosine similarity, and Universal Sentence Encoder similarity. Metric weights are computed through an inversion-based ranking alignment and pairwise AHP analysis, enabling fine-grained comparison of model outputs to expert responses. Our results show that LLMs generally outperform non-expert humans in lexical and structural alignment, with GPT-4o-mini performing most consistently across all sections. However, all models struggle with historical grounding and proposing nuanced resolution strategies, which require contextual abstraction. Human responses, while less structured, occasionally achieve comparable semantic similarity, suggesting intuitive moral reasoning. These findings highlight both the strengths and current limitations of LLMs in ethical decision-making.},
  archiveprefix = {arXiv},
  author = { Jiashen and  Du and Jesse Yao and Allen Liu and Zhekai Zhang},
  file = {2505.08106v1.pdf},
  journal = {2505.08106v1},
  month = {May},
  primaryclass = {cs.CL},
  title = {Are LLMs complicated ethical dilemma analyzers?},
  url = {http://arxiv.org/abs/2505.08106v1},
  year = {2025},
}

@article{mohammadi2025exploring,
  abstract = {Large Language Models (LLMs) have shown strong performance across many tasks, but their ability to capture culturally diverse moral values remains unclear. In this paper, we examine whether LLMs can mirror variations in moral attitudes reported by two major cross-cultural surveys: the World Values Survey and the PEW Research Center's Global Attitudes Survey. We compare smaller, monolingual, and multilingual models (GPT-2, OPT, BLOOMZ, and Qwen) with more recent instruction-tuned models (GPT-4o, GPT-4o-mini, Gemma-2-9b-it, and Llama-3.3-70B-Instruct). Using log-probability-based moral justifiability scores, we correlate each model's outputs with survey data covering a broad set of ethical topics. Our results show that many earlier or smaller models often produce near-zero or negative correlations with human judgments. In contrast, advanced instruction-tuned models (including GPT-4o and GPT-4o-mini) achieve substantially higher positive correlations, suggesting they better reflect real-world moral attitudes. While scaling up model size and using instruction tuning can improve alignment with cross-cultural moral norms, challenges remain for certain topics and regions. We discuss these findings in relation to bias analysis, training data diversity, and strategies for improving the cultural sensitivity of LLMs.},
  archiveprefix = {arXiv},
  author = {Hadi Mohammadi and Efthymia Papadopoulou and Yasmeen F. S. S. Meijer and Ayoub Bagheri},
  file = {2506.12433v1.pdf},
  journal = {2506.12433v1},
  month = {Jun},
  primaryclass = {cs.CL},
  title = {Exploring Cultural Variations in Moral Judgments with Large Language Models},
  url = {http://arxiv.org/abs/2506.12433v1},
  year = {2025},
}

@article{abhishek2025beats,
  abstract = {In this research, we introduce BEATS, a novel framework for evaluating Bias, Ethics, Fairness, and Factuality in Large Language Models (LLMs). Building upon the BEATS framework, we present a bias benchmark for LLMs that measure performance across 29 distinct metrics. These metrics span a broad range of characteristics, including demographic, cognitive, and social biases, as well as measures of ethical reasoning, group fairness, and factuality related misinformation risk. These metrics enable a quantitative assessment of the extent to which LLM generated responses may perpetuate societal prejudices that reinforce or expand systemic inequities. To achieve a high score on this benchmark a LLM must show very equitable behavior in their responses, making it a rigorous standard for responsible AI evaluation. Empirical results based on data from our experiment show that, 37.65\% of outputs generated by industry leading models contained some form of bias, highlighting a substantial risk of using these models in critical decision making systems. BEATS framework and benchmark offer a scalable and statistically rigorous methodology to benchmark LLMs, diagnose factors driving biases, and develop mitigation strategies. With the BEATS framework, our goal is to help the development of more socially responsible and ethically aligned AI models.},
  archiveprefix = {arXiv},
  author = {Alok Abhishek and Lisa Erickson and Tushar Bandopadhyay},
  file = {2503.24310v1.pdf},
  journal = {2503.24310v1},
  month = {Mar},
  primaryclass = {cs.CL},
  title = {BEATS: Bias Evaluation and Assessment Test Suite for Large Language Models},
  url = {http://arxiv.org/abs/2503.24310v1},
  year = {2025},
}

@article{liu2025diagnosing,
  abstract = {Ensuring that Large Language Models (LLMs) return just responses which adhere to societal values is crucial for their broader application. Prior research has shown that LLMs often fail to perform satisfactorily on tasks requiring moral cognizance, such as ethics-based judgments. While current approaches have focused on fine-tuning LLMs with curated datasets to improve their capabilities on such tasks, choosing the optimal learning paradigm to enhance the ethical responses of LLMs remains an open research debate. In this work, we aim to address this fundamental question: can current learning paradigms enable LLMs to acquire sufficient moral reasoning capabilities? Drawing from distributional semantics theory and the pragmatic nature of moral discourse, our analysis indicates that performance improvements follow a mechanism similar to that of semantic-level tasks, and therefore remain affected by the pragmatic nature of morals latent in discourse, a phenomenon we name the pragmatic dilemma. We conclude that this pragmatic dilemma imposes significant limitations on the generalization ability of current learning paradigms, making it the primary bottleneck for moral reasoning acquisition in LLMs.},
  archiveprefix = {arXiv},
  author = {Guangliang Liu and Zimo Qi and Xitong Zhang and Lei Jiang and Kristen Marie Johnson},
  file = {2502.16600v5.pdf},
  journal = {2502.16600v5},
  month = {Feb},
  primaryclass = {cs.CL},
  title = {Diagnosing Moral Reasoning Acquisition in Language Models: Pragmatics and Generalization},
  url = {http://arxiv.org/abs/2502.16600v5},
  year = {2025},
}


@article{bouchekif2025assessing,
	title        = {
		Assessing Large Language Models on Islamic Legal Reasoning: Evidence from
		Inheritance Law Evaluation
	},
	author       = {
		Abdessalam Bouchekif and Samer Rashwani and Heba Sbahi and Shahd Gaben and Mutaz
		Al-Khatib and Mohammed Ghaly
	},
	year         = {2025},
	url          = {http://arxiv.org/abs/2509.01081v2},
	abstract     = {
		This paper evaluates the knowledge and reasoning capabilities of Large
		Language Models in Islamic inheritance law, known as 'ilm al-mawarith. We
		assess the performance of seven LLMs using a benchmark of 1,000
		multiple-choice questions covering diverse inheritance scenarios, designed to
		test models' ability to understand the inheritance context and compute the
		distribution of shares prescribed by Islamic jurisprudence. The results
		reveal a significant performance gap: o3 and Gemini 2.5 achieved accuracies
		above 90%, whereas ALLaM, Fanar, LLaMA, and Mistral scored below 50%. These
		disparities reflect important differences in reasoning ability and domain
		adaptation. We conduct a detailed error analysis to identify recurring
		failure patterns across models, including misunderstandings of inheritance
		scenarios, incorrect application of legal rules, and insufficient domain
		knowledge. Our findings highlight limitations in handling structured legal
		reasoning and suggest directions for improving performance in Islamic legal
		reasoning. Code: https://github.com/bouchekif/inheritance_evaluation
	},
	source       = {arxiv},
    journal      = {arxiv}
}
@article{boussaha20253lm,
	title        = {3LM: Bridging Arabic, STEM, and Code through Benchmarking},
	author       = {
		Boussaha, Basma El Amel and AlQadi, Leen and Farooq, Mugariya and Alsuwaidi,
		Shaikha and Campesan, Giulia and Alzubaidi, Ahmed and Alyafeai, Mohammed and
		Hacid, Hakim
	},
	year         = {2025},
	journal      = {arXiv preprint arXiv:2507.15850}
}
@misc{chatgpt,
	title        = {ChatGPT},
	author       = {{OpenAI}},
	year         = {2023},
	note         = {Accessed: 2 October 2025},
	howpublished = {\url{https://chat.openai.com/chat}},
	version      = {Mar 14 version}
}
@misc{chen2021codex,
	title        = {Evaluating Large Language Models Trained on Code},
	author       = {
		Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde
		de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and
		Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen
		Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela
		Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and
		Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and
		Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias
		Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and
		William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie
		Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William
		Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh
		Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight
		and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob
		McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech
		Zaremba
	},
	year         = {2021},
	journal       = {2107.03374},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@misc{claude3,
	title        = {Introducing the next generation of Claude},
	author       = {Anthropic},
	year         = {2024},
	url          = {https://www.anthropic.com/news/claude-3-family}
}
@article{cobbe2021gsm8k,
	title        = {Training Verifiers to Solve Math Word Problems},
	author       = {
		Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and
		Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and
		Hilton, Jacob and Nakano, Reiichiro and Hesse, Christopher and Schulman, John
	},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2110.14168}
}
@inproceedings{commonsense2025,
	title        = {Commonsense Reasoning in {A}rab Culture},
	author       = {
		Sadallah, Abdelrahman  and Tonga, Junior Cedric  and Almubarak, Khalid  and
		Almheiri, Saeed  and Atif, Farah  and Qwaider, Chatrine  and Kadaoui, Karima
		and Shatnawi, Sara  and Alesh, Yaser  and Koto, Fajri
	},
	year         = {2025},
	month        = jul,
	booktitle    = {
		Proceedings of the 63rd Annual Meeting of the Association for Computational
		Linguistics (Volume 1: Long Papers)
	},
	publisher    = {Association for Computational Linguistics},
	address      = {Vienna, Austria},
	pages        = {7695--7710},
	doi          = {10.18653/v1/2025.acl-long.380},
	isbn         = {979-8-89176-251-0},
	url          = {https://aclanthology.org/2025.acl-long.380/},
	editor       = {
		Che, Wanxiang  and Nabende, Joyce  and Shutova, Ekaterina  and Pilehvar,
		Mohammad Taher
	}
}
@article{daoud2025medarabiq,
	title        = {Medarabiq: Benchmarking large language models on arabic medical tasks},
	author       = {
		Daoud, Mouath Abu and Abouzahir, Chaimae and Kharouf, Leen and Al-Eisawi,
		Walid and Habash, Nizar and Shamout, Farah E
	},
	year         = {2025},
	journal      = {arXiv preprint arXiv:2505.03427}
}
@article{DBLP:journals/corr/abs-1906-05394,
	title        = {Neural Arabic Question Answering},
	author       = {Hussein Mozannar and Karl El Hajal and Elie Maamary and Hazem M. Hajj},
	year         = {2019},
	journal      = {CoRR},
	volume       = {abs/1906.05394},
	url          = {http://arxiv.org/abs/1906.05394},
	eprinttype   = {arXiv},
	journal       = {1906.05394},
	timestamp    = {Wed, 26 Jun 2019 17:13:12 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-1906-05394.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{dolphin,
	title        = {Dolphin: A Challenging and Diverse Benchmark for {A}rabic {NLG}},
	author       = {
		Nagoudi, El Moatez Billah  and Elmadany, AbdelRahim  and El-Shangiti, Ahmed
		Oumar  and Abdul-Mageed, Muhammad
	},
	year         = {2023},
	month        = dec,
	booktitle    = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	publisher    = {Association for Computational Linguistics},
	address      = {Singapore},
	pages        = {1404--1422},
	doi          = {10.18653/v1/2023.findings-emnlp.98},
	url          = {https://aclanthology.org/2023.findings-emnlp.98/},
	editor       = {Bouamor, Houda  and Pino, Juan  and Bali, Kalika}
}
@misc{dubois2023alpacafarm,
	title        = {
		AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback
	},
	author       = {
		Yann Dubois and Xuechen Li and Rohan Taori and Tianyi Zhang and Ishaan
		Gulrajani and Jimmy Ba and Carlos Guestrin and Percy Liang and Tatsunori B.
		Hashimoto
	},
	year         = {2023},
	journal       = {2305.14387},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@inproceedings{el-kheir-etal-2025-iqraeval,
	title        = {Iqra{'}Eval: A Shared Task on Qur{'}anic Pronunciation Assessment},
	author       = {
		El Kheir, Yassine  and

		Meghanani, Amit  and

		Toyin, Hawau Olamide  and

		Almarwani, Nada  and

		Ibrahim, Omnia  and

		Elshahawy, Yousseif Ahmed  and

		Shahin, Mostafa  and

		Ali, Ahmed
	},
	year         = {2025},
	month        = nov,
	booktitle    = {
		Proceedings of The Third Arabic Natural Language Processing Conference:
		Shared Tasks
	},
	publisher    = {Association for Computational Linguistics},
	address      = {Suzhou, China},
	pages        = {443--452},
	doi          = {10.18653/v1/2025.arabicnlp-sharedtasks.61},
	isbn         = {979-8-89176-356-2},
	url          = {https://aclanthology.org/2025.arabicnlp-sharedtasks.61/},
	editor       = {
		Darwish, Kareem  and

		Ali, Ahmed  and

		Abu Farha, Ibrahim  and

		Touileb, Samia  and

		Zitouni, Imed  and

		Abdelali, Ahmed  and

		Al-Ghamdi, Sharefah  and

		Alkhereyf, Sakhar  and

		Zaghouani, Wajdi  and

		Khalifa, Salam  and

		AlKhamissi, Badr  and

		Almatham, Rawan  and

		Hamed, Injy  and

		Alyafeai, Zaid  and

		Alowisheq, Areeb  and

		Inoue, Go  and

		Mrini, Khalil  and

		Alshammari, Waad
	},
	abstract     = {
		We present the findings of the first shared task on Qur{'}anic pronunciation
		assessment, which focuses on addressing the unique challenges of evaluating
		the precise pronunciation of Qur{'}anic recitation. To fill an existing
		research gap, the Iqra{'}Eval 2025 shared task introduces the first open
		benchmark for Mispronunciation Detection and Diagnosis (MDD) in Qur{'}anic
		recitation, using Modern Standard Arabic (MSA) reading of Qur{'}anic texts as
		its case study. The task provides a comprehensive evaluation framework with
		increasingly complex subtasks: error localization and detailed error
		diagnosis. Leveraging the recently developed QuranMB benchmark dataset along
		with auxiliary training resources, this shared task aims to stimulate
		research in an area of both linguistic and cultural significance while
		addressing computational challenges in pronunciation assessment.
	}
}
@article{eljazzar2017towards,
	title        = {Towards A Time Based Video Search Engine for Al Quran Interpretation},
	author       = {Maged M. Eljazzar, Afnan Hassan, Amira A. AlSharkawy},
	year         = {2017},
	url          = {http://arxiv.org/abs/1701.09138v1},
	abstract     = {
		The number of Internet Muslim-users is remarkably increasing from all over
		the world countries. There are a lot of structured, and well-documented text
		resources for the Quran interpretation, Tafsir, over the Internet with
		several languages. Nevertheless, when searching for the meaning of specific
		words, many users prefer watching short videos rather than reading a script
		or a book. This paper introduces the solution for the challenge of
		partitioning the common Tafsir videos into short videos according to the
		search query and sharing these result videos on the social networks.
		Furthermore, we provide the ability of user commenting on a specific
		time-based frame on the video or a specific verse in a particular subject. It
		would be very valuable to apply the current technologies on Holy Quran and
		Tafsir to easy the query for verses, understanding of its meaning, and
		sharing it on the different social media.
	},
	source       = {arxiv}
}
@misc{eval-harness,
	title        = {The Language Model Evaluation Harness},
	author       = {
		Gao, Leo and Tow, Jonathan and Abbasi, Baber and Biderman, Stella and Black,
		Sid and DiPofi, Anthony and Foster, Charles and Golding, Laurence and Hsu,
		Jeffrey and Le Noac'h, Alain and Li, Haonan and McDonell, Kyle and
		Muennighoff, Niklas and Ociepa, Chris and Phang, Jason and Reynolds, Laria
		and Schoelkopf, Hailey and Skowron, Aviya and Sutawika, Lintang and Tang,
		Eric and Thite, Anish and Wang, Ben and Wang, Kevin and Zou, Andy
	},
	year         = {2024},
	month        = {07},
	publisher    = {Zenodo},
	doi          = {10.5281/zenodo.12608602},
	url          = {https://zenodo.org/records/12608602},
	version      = {v0.4.3}
}
@misc{falcon-arabic,
	title        = {Falcon-Arabic: A Breakthrough in Arabic Language Models},
	author       = {TII},
	year         = {2025},
	url          = {https://falcon-lm.github.io/blog/falcon-arabic/}
}

@article{fanarteam2025fanararabiccentricmultimodalgenerative,
	title        = {Fanar: An Arabic-Centric Multimodal Generative AI Platform},
	author       = {
		Fanar Team and Ummar Abbas and Mohammad Shahmeer Ahmad and Firoj Alam and
		Enes Altinisik and Ehsannedin Asgari and Yazan Boshmaf and Sabri Boughorbel
		and Sanjay Chawla and Shammur Chowdhury and Fahim Dalvi and Kareem Darwish
		and Nadir Durrani and Mohamed Elfeky and Ahmed Elmagarmid and Mohamed
		Eltabakh and Masoomali Fatehkia and Anastasios Fragkopoulos and Maram
		Hasanain and Majd Hawasly and Mus'ab Husaini and Soon-Gyo Jung and Ji Kim
		Lucas and Walid Magdy and Safa Messaoud and Abubakr Mohamed and Tasnim
		Mohiuddin and Basel Mousi and Hamdy Mubarak and Ahmad Musleh and Zan Naeem
		and Mourad Ouzzani and Dorde Popovic and Amin Sadeghi and Husrev Taha Sencar
		and Mohammed Shinoy and Omar Sinan and Yifan Zhang and Ahmed Ali and Yassine
		El Kheir and Xiaosong Ma and Chaoyi Ruan
	},
	year         = {2025},
	url          = {https://arxiv.org/abs/2501.13944},
	journal       = {2501.13944},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@article{fauzan2023discoursebased,
	title        = {
		Discourse-Based Teaching in English Language Teaching at Islamic Universities
		in Borneo: A Critical Discourse Analysis Perspective
	},
	author       = {Umar Fauzan, Muhammad Saparuddin},
	year         = {2023},
	url          = {
		https://www.semanticscholar.org/paper/7d5cf6560c278244f00213c91a651ee37b691de9
	},
	abstract     = {
		This critical discourse analysis aims to uncover what ideologies emerge in
		English language teaching at Islamic universities in Borneo, explain how
		discourse-based teaching is implemented, and why discourse-based teaching is
		necessary for English language teaching at Islamic universities in Borneo.
		This is qualitative phenomenological research using Fairclough's Critical
		Discourse Analysis model. The primary data sources for this research are
		English language lecturers and college students at universities in Borneo,
		namely UIN Sultan Aji Muhammad Idris Samarinda, UIN Antasari Banjarmasin,
		IAIN Palangkaraya, and IAIN Pontianak. The researcher used several research
		instruments to collect the data: interviews, questionnaires, observations,
		and documentation. The data analysis technique used in this research is the
		interactive model from Miles et al. with the stages of data collection, data
		condensation, data display, and conclusion. This research concludes that
		English language education at Islamic universities in Borneo has an ideology
		of character development, influenced by several factors such as the shift in
		character values, the spirit of nationalism, and political policies of the
		Ministry of Religion to maintain national unity with a religious moderation
		agenda, and the vision to develop graduates who have solid Islamic character.
		In addition, English language education aims not only to master English
		language skills but also to compete in the era of information technology with
		critical thinking skills. Therefore, English language teaching at Islamic
		universities in Borneo is based on a discourse approach, from lesson planning
		and teaching implementation to teaching evaluation. This research implies
		that English language teaching should not only focus on English language
		skills or TEFL content but also on achieving learning outcomes from the goals
		of the study program, students’ needs, and the roles of lecturers as
		educators of Islamic and national character values.
	},
	source       = {semantic_scholar}
}
@misc{ghaboura2024camelbenchcomprehensivearabiclmm,
	title        = {CAMEL-Bench: A Comprehensive Arabic LMM Benchmark},
	author       = {
		Sara Ghaboura and Ahmed Heakl and Omkar Thawakar and Ali Alharthi and Ines
		Riahi and Abduljalil Saif and Jorma Laaksonen and Fahad S. Khan and Salman
		Khan and Rao M. Anwer
	},
	year         = {2024},
	url          = {https://arxiv.org/abs/2410.18976},
	journal       = {2410.18976},
	archiveprefix = {arXiv},
	primaryclass = {cs.CV}
}
@misc{ghaboura2025arbcomprehensivearabicmultimodal,
	title        = {ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark},
	author       = {
		Sara Ghaboura and Ketan More and Wafa Alghallabi and Omkar Thawakar and Jorma
		Laaksonen and Hisham Cholakkal and Salman Khan and Rao Muhammad Anwer
	},
	year         = {2025},
	url          = {https://arxiv.org/abs/2505.17021},
	journal       = {2505.17021},
	archiveprefix = {arXiv},
	primaryclass = {cs.CV}
}
@article{ghufron2023the,
	title        = {
		The Model of Developing Arabic Language Skills at Daarul Ukhuwwah Islamic
		Boarding School Malang
	},
	author       = {Boby Ghufron, N. Nurhadi, Syaiful Mustofa, Moch. Fikri Abdul Aziz},
	year         = {2023},
	url          = {
		https://www.semanticscholar.org/paper/26925766f19f46657a69a0e246bba3645a70c86d
	},
	abstract     = {
		The success of learning Arabic in Islamic boarding school can be measured by
		the number of students who are able to speak Arabic and have four Arabic
		skills. The learning model in Daarul Ukhuwwah Islamic boarding school is seen
		as effective in developing students' language skills. Therefore, it is
		necessary to carry out research related to the development model of Arabic
		language learning in Daarul Ukhuwwah Islamic boarding school.  The purpose of
		this research is to determine the model of developing Arabic language skills
		in Daarul Ukhuwwah Islamic boarding school. The method used is a descriptive
		qualitative method. The research data includes primary data in the form of
		core data from the research location, and secondary data in the form of
		documentation. Research data collection techniques use observation,
		interviews, and documentation. The process of analyzing research data
		includes data reduction, data presentation, and conclusion making.  The
		results showed that Daarul Ukhuwwah Islamic boarding school uses the imigram
		model in designing and implementing language agendas that are useful for
		developing the four Arabic language skills of its students. The model seeks
		to provide a balance between Arabic practice and theory. This research can be
		used as an example of an innovative model of developing Arabic language
		skills.
	},
	source       = {semantic_scholar}
}
@article{goel2024a,
	title        = {
		A Comparative Study of Religious Scriptures Using Natural Language Processing
	},
	author       = {Pramit Goel, Rashida Arsiwala},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/ae2b197afc03970b2705444ea09b0cf8bb4438a1
	},
	abstract     = {
		Over the past few years, Natural Language Processing (“NLP”) has emerged as a
		powerful tool and has enabled computational analysis of texts by offering
		insights into the subtleties of language, emotion, and thematic frameworks.
		This research paper employs NLP strategies such as topic modelling and
		sentiment analysis to compare translations of three religious scriptures: the
		Bhagavad Gita representing Hinduism, Quran representing Islam and the Bible
		representing Christianity. Before carrying out the tests, text was
		pre-processed and cleaned to ensure that the most optimum results were
		obtained. Topic modelling uses algorithms such as Latent Dirichlet Allocation
		to find prominent themes while sentiment analysis makes use of an NLTK VADER
		sentiment module ‘Sentiment Analyzer’ to interpret emotional undertones in
		text. This research paper finds that the texts share similar views on topics
		such as generosity, devotion to God among others and have differing opinions
		on themes including sacrifice and violence. It is also interesting to note
		that while the religions of the Bhagavad Gita and Quran (Hinduism and Islam
		respectively) have been pitted against each other for centuries in countries
		such as India, they share several similar principles and ideologies.
	},
	source       = {semantic_scholar}
}
@misc{grattafiori2024llama,
	title        = {The Llama 3 Herd of Models},
	author       = {
		Aaron Grattafiori and Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey
		and Abhishek Kadian and Ahmad Al-Dahle and Aiesha Letman and Akhil Mathur and
		Alan Schelten and Alex Vaughan and Amy Yang and Angela Fan and Anirudh Goyal
		and Anthony Hartshorn and Aobo Yang and Archi Mitra and Archie Sravankumar
		and Artem Korenev and Arthur Hinsvark and Arun Rao and Aston Zhang and
		Aurelien Rodriguez and Austen Gregerson and Ava Spataru and Baptiste Roziere
		and Bethany Biron and Binh Tang and Bobbie Chern and Charlotte Caucheteux and
		Chaya Nayak and Chloe Bi and Chris Marra and Chris McConnell and Christian
		Keller and Christophe Touret and Chunyang Wu and Corinne Wong and Cristian
		Canton Ferrer and Cyrus Nikolaidis and Damien Allonsius and Daniel Song and
		Danielle Pintz and Danny Livshits and Danny Wyatt and David Esiobu and Dhruv
		Choudhary and Dhruv Mahajan and Diego Garcia-Olano and Diego Perino and
		Dieuwke Hupkes and Egor Lakomkin and Ehab AlBadawy and Elina Lobanova and
		Emily Dinan and Eric Michael Smith and Filip Radenovic and Francisco Guzmán
		and Frank Zhang and Gabriel Synnaeve and Gabrielle Lee and Georgia Lewis
		Anderson and Govind Thattai and Graeme Nail and Gregoire Mialon and Guan Pang
		and Guillem Cucurell and Hailey Nguyen and Hannah Korevaar and Hu Xu and Hugo
		Touvron and Iliyan Zarov and Imanol Arrieta Ibarra and Isabel Kloumann and
		Ishan Misra and Ivan Evtimov and Jack Zhang and Jade Copet and Jaewon Lee and
		Jan Geffert and Jana Vranes and Jason Park and Jay Mahadeokar and Jeet Shah
		and Jelmer van der Linde and Jennifer Billock and Jenny Hong and Jenya Lee
		and Jeremy Fu and Jianfeng Chi and Jianyu Huang and Jiawen Liu and Jie Wang
		and Jiecao Yu and Joanna Bitton and Joe Spisak and Jongsoo Park and Joseph
		Rocca and Joshua Johnstun and Joshua Saxe and Junteng Jia and Kalyan Vasuden
		Alwala and Karthik Prasad and Kartikeya Upasani and Kate Plawiak and Ke Li
		and Kenneth Heafield and Kevin Stone and Khalid El-Arini and Krithika Iyer
		and Kshitiz Malik and Kuenley Chiu and Kunal Bhalla and Kushal Lakhotia and
		Lauren Rantala-Yeary and Laurens van der Maaten and Lawrence Chen and Liang
		Tan and Liz Jenkins and Louis Martin and Lovish Madaan and Lubo Malo and
		Lukas Blecher and Lukas Landzaat and Luke de Oliveira and Madeline Muzzi and
		Mahesh Pasupuleti and Mannat Singh and Manohar Paluri and Marcin Kardas and
		Maria Tsimpoukelli and Mathew Oldham and Mathieu Rita and Maya Pavlova and
		Melanie Kambadur and Mike Lewis and Min Si and Mitesh Kumar Singh and Mona
		Hassan and Naman Goyal and Narjes Torabi and Nikolay Bashlykov and Nikolay
		Bogoychev and Niladri Chatterji and Ning Zhang and Olivier Duchenne and Onur
		Çelebi and Patrick Alrassy and Pengchuan Zhang and Pengwei Li and Petar Vasic
		and Peter Weng and Prajjwal Bhargava and Pratik Dubal and Praveen Krishnan
		and Punit Singh Koura and Puxin Xu and Qing He and Qingxiao Dong and Ragavan
		Srinivasan and Raj Ganapathy and Ramon Calderer and Ricardo Silveira Cabral
		and Robert Stojnic and Roberta Raileanu and Rohan Maheswari and Rohit Girdhar
		and Rohit Patel and Romain Sauvestre and Ronnie Polidoro and Roshan Sumbaly
		and Ross Taylor and Ruan Silva and Rui Hou and Rui Wang and Saghar Hosseini
		and Sahana Chennabasappa and Sanjay Singh and Sean Bell and Seohyun Sonia Kim
		and Sergey Edunov and Shaoliang Nie and Sharan Narang and Sharath Raparthy
		and Sheng Shen and Shengye Wan and Shruti Bhosale and Shun Zhang and Simon
		Vandenhende and Soumya Batra and Spencer Whitman and Sten Sootla and Stephane
		Collot and Suchin Gururangan and Sydney Borodinsky and Tamar Herman and Tara
		Fowler and Tarek Sheasha and Thomas Georgiou and Thomas Scialom and Tobias
		Speckbacher and Todor Mihaylov and Tong Xiao and Ujjwal Karn and Vedanuj
		Goswami and Vibhor Gupta and Vignesh Ramanathan and Viktor Kerkez and Vincent
		Gonguet and Virginie Do and Vish Vogeti and Vítor Albiero and Vladan Petrovic
		and Weiwei Chu and Wenhan Xiong and Wenyin Fu and Whitney Meers and Xavier
		Martinet and Xiaodong Wang and Xiaofang Wang and Xiaoqing Ellen Tan and Xide
		Xia and Xinfeng Xie and Xuchao Jia and Xuewei Wang and Yaelle Goldschlag and
		Yashesh Gaur and Yasmine Babaei and Yi Wen and Yiwen Song and Yuchen Zhang
		and Yue Li and Yuning Mao and Zacharie Delpierre Coudert and Zheng Yan and
		Zhengxing Chen and Zoe Papakipos and Aaditya Singh and Aayushi Srivastava and
		Abha Jain and Adam Kelsey and Adam Shajnfeld and Adithya Gangidi and Adolfo
		Victoria and Ahuva Goldstand and Ajay Menon and Ajay Sharma and Alex
		Boesenberg and Alexei Baevski and Allie Feinstein and Amanda Kallet and Amit
		Sangani and Amos Teo and Anam Yunus and Andrei Lupu and Andres Alvarado and
		Andrew Caples and Andrew Gu and Andrew Ho and Andrew Poulton and Andrew Ryan
		and Ankit Ramchandani and Annie Dong and Annie Franco and Anuj Goyal and
		Aparajita Saraf and Arkabandhu Chowdhury and Ashley Gabriel and Ashwin
		Bharambe and Assaf Eisenman and Azadeh Yazdan and Beau James and Ben Maurer
		and Benjamin Leonhardi and Bernie Huang and Beth Loyd and Beto De Paola and
		Bhargavi Paranjape and Bing Liu and Bo Wu and Boyu Ni and Braden Hancock and
		Bram Wasti and Brandon Spence and Brani Stojkovic and Brian Gamido and Britt
		Montalvo and Carl Parker and Carly Burton and Catalina Mejia and Ce Liu and
		Changhan Wang and Changkyu Kim and Chao Zhou and Chester Hu and Ching-Hsiang
		Chu and Chris Cai and Chris Tindal and Christoph Feichtenhofer and Cynthia
		Gao and Damon Civin and Dana Beaty and Daniel Kreymer and Daniel Li and David
		Adkins and David Xu and Davide Testuggine and Delia David and Devi Parikh and
		Diana Liskovich and Didem Foss and Dingkang Wang and Duc Le and Dustin
		Holland and Edward Dowling and Eissa Jamil and Elaine Montgomery and Eleonora
		Presani and Emily Hahn and Emily Wood and Eric-Tuan Le and Erik Brinkman and
		Esteban Arcaute and Evan Dunbar and Evan Smothers and Fei Sun and Felix Kreuk
		and Feng Tian and Filippos Kokkinos and Firat Ozgenel and Francesco Caggioni
		and Frank Kanayet and Frank Seide and Gabriela Medina Florez and Gabriella
		Schwarz and Gada Badeer and Georgia Swee and Gil Halpern and Grant Herman and
		Grigory Sizov and Guangyi and Zhang and Guna Lakshminarayanan and Hakan Inan
		and Hamid Shojanazeri and Han Zou and Hannah Wang and Hanwen Zha and Haroun
		Habeeb and Harrison Rudolph and Helen Suk and Henry Aspegren and Hunter
		Goldman and Hongyuan Zhan and Ibrahim Damlaj and Igor Molybog and Igor
		Tufanov and Ilias Leontiadis and Irina-Elena Veliche and Itai Gat and Jake
		Weissman and James Geboski and James Kohli and Janice Lam and Japhet Asher
		and Jean-Baptiste Gaya and Jeff Marcus and Jeff Tang and Jennifer Chan and
		Jenny Zhen and Jeremy Reizenstein and Jeremy Teboul and Jessica Zhong and
		Jian Jin and Jingyi Yang and Joe Cummings and Jon Carvill and Jon Shepard and
		Jonathan McPhie and Jonathan Torres and Josh Ginsburg and Junjie Wang and Kai
		Wu and Kam Hou U and Karan Saxena and Kartikay Khandelwal and Katayoun Zand
		and Kathy Matosich and Kaushik Veeraraghavan and Kelly Michelena and Keqian
		Li and Kiran Jagadeesh and Kun Huang and Kunal Chawla and Kyle Huang and
		Lailin Chen and Lakshya Garg and Lavender A and Leandro Silva and Lee Bell
		and Lei Zhang and Liangpeng Guo and Licheng Yu and Liron Moshkovich and Luca
		Wehrstedt and Madian Khabsa and Manav Avalani and Manish Bhatt and Martynas
		Mankus and Matan Hasson and Matthew Lennie and Matthias Reso and Maxim
		Groshev and Maxim Naumov and Maya Lathi and Meghan Keneally and Miao Liu and
		Michael L. Seltzer and Michal Valko and Michelle Restrepo and Mihir Patel and
		Mik Vyatskov and Mikayel Samvelyan and Mike Clark and Mike Macey and Mike
		Wang and Miquel Jubert Hermoso and Mo Metanat and Mohammad Rastegari and
		Munish Bansal and Nandhini Santhanam and Natascha Parks and Natasha White and
		Navyata Bawa and Nayan Singhal and Nick Egebo and Nicolas Usunier and Nikhil
		Mehta and Nikolay Pavlovich Laptev and Ning Dong and Norman Cheng and Oleg
		Chernoguz and Olivia Hart and Omkar Salpekar and Ozlem Kalinli and Parkin
		Kent and Parth Parekh and Paul Saab and Pavan Balaji and Pedro Rittner and
		Philip Bontrager and Pierre Roux and Piotr Dollar and Polina Zvyagina and
		Prashant Ratanchandani and Pritish Yuvraj and Qian Liang and Rachad Alao and
		Rachel Rodriguez and Rafi Ayub and Raghotham Murthy and Raghu Nayani and
		Rahul Mitra and Rangaprabhu Parthasarathy and Raymond Li and Rebekkah Hogan
		and Robin Battey and Rocky Wang and Russ Howes and Ruty Rinott and Sachin
		Mehta and Sachin Siby and Sai Jayesh Bondu and Samyak Datta and Sara Chugh
		and Sara Hunt and Sargun Dhillon and Sasha Sidorov and Satadru Pan and
		Saurabh Mahajan and Saurabh Verma and Seiji Yamamoto and Sharadh Ramaswamy
		and Shaun Lindsay and Shaun Lindsay and Sheng Feng and Shenghao Lin and
		Shengxin Cindy Zha and Shishir Patil and Shiva Shankar and Shuqiang Zhang and
		Shuqiang Zhang and Sinong Wang and Sneha Agarwal and Soji Sajuyigbe and
		Soumith Chintala and Stephanie Max and Stephen Chen and Steve Kehoe and Steve
		Satterfield and Sudarshan Govindaprasad and Sumit Gupta and Summer Deng and
		Sungmin Cho and Sunny Virk and Suraj Subramanian and Sy Choudhury and Sydney
		Goldman and Tal Remez and Tamar Glaser and Tamara Best and Thilo Koehler and
		Thomas Robinson and Tianhe Li and Tianjun Zhang and Tim Matthews and Timothy
		Chou and Tzook Shaked and Varun Vontimitta and Victoria Ajayi and Victoria
		Montanez and Vijai Mohan and Vinay Satish Kumar and Vishal Mangla and Vlad
		Ionescu and Vlad Poenaru and Vlad Tiberiu Mihailescu and Vladimir Ivanov and
		Wei Li and Wenchen Wang and Wenwen Jiang and Wes Bouaziz and Will Constable
		and Xiaocheng Tang and Xiaojian Wu and Xiaolan Wang and Xilun Wu and Xinbo
		Gao and Yaniv Kleinman and Yanjun Chen and Ye Hu and Ye Jia and Ye Qi and
		Yenda Li and Yilin Zhang and Ying Zhang and Yossi Adi and Youngjin Nam and Yu
		and Wang and Yu Zhao and Yuchen Hao and Yundi Qian and Yunlu Li and Yuzi He
		and Zach Rait and Zachary DeVito and Zef Rosnbrick and Zhaoduo Wen and Zhenyu
		Yang and Zhiwei Zhao and Zhiyu Ma
	},
	year         = {2024},
	url          = {https://arxiv.org/abs/2407.21783},
	journal       = {2407.21783},
	archiveprefix = {arXiv},
	primaryclass = {cs.AI}
}
@misc{guha2023legalbench,
	title        = {
		LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning
		in Large Language Models
	},
	author       = {
		Neel Guha and Julian Nyarko and Daniel E. Ho and Christopher Ré and Adam
		Chilton and Aditya Narayana and Alex Chohlas-Wood and Austin Peters and
		Brandon Waldon and Daniel N. Rockmore and Diego Zambrano and Dmitry Talisman
		and Enam Hoque and Faiz Surani and Frank Fagan and Galit Sarfaty and Gregory
		M. Dickinson and Haggai Porat and Jason Hegland and Jessica Wu and Joe Nudell
		and Joel Niklaus and John Nay and Jonathan H. Choi and Kevin Tobia and
		Margaret Hagan and Megan Ma and Michael Livermore and Nikon Rasumov-Rahe and
		Nils Holzenberger and Noam Kolt and Peter Henderson and Sean Rehaag and
		Sharad Goel and Shang Gao and Spencer Williams and Sunny Gandhi and Tom Zur
		and Varun Iyer and Zehua Li
	},
	year         = {2023},
	url          = {https://arxiv.org/abs/2308.11462},
	journal       = {2308.11462},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@article{hamad2020quran,
	title        = {Quran content representation in NLP},
	author       = {Zineb Touati Hamad, M. R. Laouar, Issam Bendib},
	year         = {2020},
	url          = {
		https://www.semanticscholar.org/paper/6c2fadbf5068efa12785ffafb02708a2449f84fc
	},
	abstract     = {
		Word representation is a starting point for Natural Language Processing
		(NLP). These representations transform words into symbolic vectors of a given
		length that reveal the hidden linguistic and semantic similarities. This
		paper presents a study of the various word representation tools used for the
		content of the texts of the holy Quran in Arabic, which include the two main
		representation forms: Local representation and Distributed representation,
		with the aim of using them in different artificial intelligence subsets such
		as "machine learning" and "deep learning" algorithms that require NLP.
	},
	source       = {semantic_scholar}
}
@article{hamad2022arabic,
	title        = {Arabic Quran Verses Authentication Using Deep Learning and Word Embeddings},
	author       = {Zineb Touati Hamad and M. R. Laouar and Issam Bendib and S. Hakak},
	year         = {2022},
	url          = {
		https://www.semanticscholar.org/paper/533c68890751a45303b6d1a71724d02f9ea12347
	},
    journal = {The International Arab Journal of Information Technology},
	abstract     = {
		Nowadays, with the developments witnessed by the Internet, algorithms have
		come to control all aspects of digital content. Due to its Arabic roots, it
		is ironic to find that Arabic Quranic content is still thirsty to benefit
		from computer linguistics, especially with the advent of artificial
		intelligence algorithms. The massive spread of Islamic-typed websites and
		applications has led to a widespread of digital Quranic content.
		Unfortunately, such content lacks censorship and can rarely match
		resourcefulness. It is quite difficult, especially for a non-native speaker
		of the Arabic language, to distinguish and authenticate the provided Quranic
		verses from the non-Quranic Arabic texts. Text processing techniques
		classified outside the field of Natural Language Processing (NLP) give less
		qualified results, especially with Arabic texts. To address this problem, we
		propose to explore Word Embeddings (WE) with Deep Learning (DL) techniques to
		identify Quranic verses in Arabic textual content. The proposed work is
		evaluated using twelve different word embeddings models with two popular
		classifiers for binary classification, namely: Convolutional Neural Network
		(CNN) and Long Short Term Memory (LSTM). The experimental results showed the
		superiority of the proposed approach over traditional methods in
		distinguishing between the Quranic verses and the Arabic text with an
		accuracy of 98.33%.
	},
	source       = {semantic_scholar}
}
@article{hani2024predicting,
	title        = {Predicting Revelation Periods of Verses of the Quran via Deep Learning},
	author       = {Umme Hani, Ahsanur Rahman},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/4ce8831ba0b6517cc0e1f2842a925e737d81f6c9
	},
	abstract     = {
		The revelation period of a verse of the Quran provides invaluable insights
		into the historical context of that verse, helps us understand the prophet's
		biography, and empowers Islamic scholars to decide about the applicability of
		certain laws and/or to interpret that verse. They mostly relied on
		traditional methods (such as the occurrence of certain words and phrases,
		topics discussed, historical references, etc.) to decide the revelation
		periods of verses of the Quran. With modern deep-learning-based natural
		language processing (NLP) techniques, learning more complex patterns is
		possible, which may help us achieve this goal better. To our knowledge, no
		such attempt has been made before. Here, we attempt to fill this gap by
		employing different variations of a deep learning model to classify verses of
		the Quran into Meccan/Medinan categories. We analyze and interpret our
		results to get interesting insights.
	},
	source       = {semantic_scholar}, 
    journal      = {}
}
@article{hardalov2020exams,
	title        = {
		EXAMS: A multi-subject high school examinations dataset for cross-lingual and
		multilingual question answering
	},
	author       = {
		Hardalov, Momchil and Mihaylov, Todor and Zlatkova, Dimitrina and Dinkov,
		Yoan and Koychev, Ivan and Nakov, Preslav
	},
	year         = {2020},
	journal      = {arXiv preprint arXiv:2011.03080}
}
@article{harere2023quran,
	title        = {Quran Recitation Recognition using End-to-End Deep Learning},
	author       = {Ahmad Al Harere, Khloud Al Jallad},
	year         = {2023},
	url          = {http://arxiv.org/abs/2305.07034v1},
	abstract     = {
		The Quran is the holy scripture of Islam, and its recitation is an important
		aspect of the religion. Recognizing the recitation of the Holy Quran
		automatically is a challenging task due to its unique rules that are not
		applied in normal speaking speeches. A lot of research has been done in this
		domain, but previous works have detected recitation errors as a
		classification task or used traditional automatic speech recognition (ASR).
		In this paper, we proposed a novel end-to-end deep learning model for
		recognizing the recitation of the Holy Quran. The proposed model is a
		CNN-Bidirectional GRU encoder that uses CTC as an objective function, and a
		character-based decoder which is a beam search decoder. Moreover, all
		previous works were done on small private datasets consisting of short verses
		and a few chapters of the Holy Quran. As a result of using private datasets,
		no comparisons were done. To overcome this issue, we used a public dataset
		that has recently been published (Ar-DAD) and contains about 37 chapters that
		were recited by 30 reciters, with different recitation speeds and different
		types of pronunciation rules. The proposed model performance was evaluated
		using the most common evaluation metrics in speech recognition, word error
		rate (WER), and character error rate (CER). The results were 8.34% WER and
		2.42% CER. We hope this research will be a baseline for comparisons with
		future research on this public new dataset (Ar-DAD).
	},
	source       = {arxiv}
}
@article{harrag2020quran,
	title        = {
		Quran Intelligent Ontology Construction Approach Using Association Rules
		Mining
	},
	author       = {Fouzi Harrag and Abdullah Al-Nasser and Abdullah Al-Musnad and Rayan Al-Shaya},
	year         = {2020},
	url          = {http://arxiv.org/abs/2008.03232v2},
	abstract     = {
		Ontology can be seen as a formal representation of knowledge. They have been
		investigated in many artificial intelligence studies including semantic web,
		software engineering, and information retrieval. The aim of ontology is to
		develop knowledge representations that can be shared and reused. This
		research project is concerned with the use of association rules to extract
		the Quran ontology. The manual acquisition of ontologies from Quran verses
		can be very costly; therefore, we need an intelligent system for Quran
		ontology construction using patternbased schemes and associations rules to
		discover Quran concepts and semantics relations from Quran verses. Our system
		is based on the combination of statistics and linguistics methods to extract
		concepts and conceptual relations from Quran. In particular, a linguistic
		pattern-based approach is exploited to extract specific concepts from the
		Quran, while the conceptual relations are found based on association rules
		technique. The Quran ontology will offer a new and powerful representation of
		Quran knowledge, and the association rules will help to represent the
		relations between all classes of connected concepts in the Quran ontology.
	},
	source       = {arxiv}, 
    journal      = {}
}
@article{hazaea2022islamic,
	title        = {
		Islamic and Late Modern Comparative Worldviews on Language: Towards Model for
		Translating Alien Key Concepts
	},
	author       = {A. Hazaea},
	year         = {2022},
	url          = {
		https://www.semanticscholar.org/paper/77e838f8de36c394e2be1017de7241d34652ae31
	},
	abstract     = {
		Within the area of cultural discourse studies (CDSs), this article is
		presented to compare the late modern and Islamic worldviews on language. In
		so doing, the researcher uses a comparative qualitative method to explore the
		worldviews on language, word meaning, text, and context with specific
		attention to the writings of Norman Fairclough and those of Mohammed Naqib
		al-Attas. The analysis reveals that both worldviews coincide in terms of
		basic and relational meanings of words. Some differences are revealed in
		terms of the worldviews on language, text, and context. What distinguishes
		al-Attas’s Islamic worldview is that the authentic sources of knowledge (the
		Quran and the verified Sunnah) in the Arabic language provide a scientific
		context for concept-formation. The study contributes to a model for
		translation at worldview levels. It recommends further research on
		translating alien key concepts that have been introduced into the languages
		of Muslim people.
	},
	source       = {semantic_scholar}
}
@article{hendrycks2020measuring,
	title        = {Measuring massive multitask language understanding},
	author       = {
		Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and
		Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob
	},
	year         = {2020},
	journal      = {arXiv preprint arXiv:2009.03300}
}
@article{hijazi2024arablegaleval,
	title        = {
		Arablegaleval: A multitask benchmark for assessing arabic legal knowledge in
		large language models
	},
	author       = {
		Hijazi, Faris and AlHarbi, Somayah and AlHussein, Abdulaziz and Shairah,
		Harethah Abu and AlZahrani, Reem and AlShamlan, Hebah and Knio, Omar and
		Turkiyyah, George
	},
	year         = {2024},
	journal      = {arXiv preprint arXiv:2408.07983}
}
@article{hoerudin2024management,
	title        = {
		Management of Implementing Indonesian Language Learning Based on The Blended
		Learning Model in Islamic Higher Education
	},
	author       = {Cecep Wahyu Hoerudin, Ayu Desrani, Apri Wardana Ritonga, Prozoe Rezo},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/3b30ce6a13a86725a0f13576ad6783b65e9b034e
	},
	abstract     = {
		Along with the disappearance of the Covid-19 pandemic, the government began
		to improve and make policies to restore the learning process. Learning that
		was originally online is now gradually becoming offline. Therefore, this
		study aims to look at the Indonesian language learning process that adopts
		the blended learning model. This research is a mixed methods research, namely
		quantitative and qualitative approaches. Quantitative research uses survey
		methods to determine the effectiveness of using blended learning models. And
		using descriptive qualitative to see students' perceptions of the learning
		process. The research informants were 60 students from the Indonesian
		language education study program at the Islamic Nusantara University in
		Bandung. Quantitative data were analyzed descriptively and data analysis was
		carried out in three stages, namely data reduction, presentation, and
		verification. The results of this study indicate that as many as 73% of
		students prefer face-to-face learning, according to him face-to-face learning
		is more effective and interactive in increasing student knowledge. However,
		not a few choose to stay online because it is more flexible. Other findings
		reveal that the selection of learning media must be adapted to the conditions
		of online or offline learning, when offline the selection of interactive
		media is highly recommended.
	},
	source       = {semantic_scholar}
}
@misc{huang2024acegptlocalizinglargelanguage,
	title        = {AceGPT, Localizing Large Language Models in Arabic},
	author       = {
		Huang Huang and Fei Yu and Jianqing Zhu and Xuening Sun and Hao Cheng and
		Dingjie Song and Zhihong Chen and Abdulmohsen Alharthi and Bang An and Juncai
		He and Ziche Liu and Zhiyi Zhang and Junying Chen and Jianquan Li and Benyou
		Wang and Lian Zhang and Ruoyu Sun and Xiang Wan and Haizhou Li and Jinchao Xu
	},
	year         = {2024},
	url          = {https://arxiv.org/abs/2309.12053},
	journal       = {2309.12053},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{huang2024survey,
	title        = {
		A Survey on Large Language Models with Multilingualism: Recent Advances and
		New Frontiers
	},
	author       = {
		Kaiyu Huang and Fengran Mo and Xinyu Zhang and Hongliang Li and You Li and
		Yuanchi Zhang and Weijian Yi and Yulong Mao and Jinchen Liu and Yuzhuang Xu
		and Jinan Xu and Jian-Yun Nie and Yang Liu
	},
	year         = {2025},
	url          = {https://arxiv.org/abs/2405.10936},
	journal       = {2405.10936},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@article{huda2021arabic,
	title        = {
		Arabic Part Of Speech (POS) Tagging Analysis using Bee Colony Optimization
		(BCO) Algorithm on Quran Corpus
	},
	author       = {A Huda and Fauziah and Elis Ratnawulan and Dian Rachmat Gumelar},
	year         = {2021},
	url          = {
		https://www.semanticscholar.org/paper/63aa61a5147cc4b0ed89b47b8cdada0b942d3272
	},
	abstract     = {
		Part Of Speech (POS) tagging is an automated process for determining the
		appropriate grammatical label or syntactic category of a word depending on
		the context. POS tagging is one of the important processes in Natural
		Language Processing (NLP) applications such as summarization text, Speech
		Recognition (SR), Question Answering (QA) and Information Retrieval (IR).
		Automatic POS tagging is needed because manual POS tagging takes a long time
		and is expensive because it requires a linguist. The main problem in POS
		tagging automatically is words that have different properties if placed in
		different contexts (ambiguous) and words that are in the test corpus but not
		in the Out of Vocabulary (OOV) training corpus. In this study, an efficient
		POS tagging approach for Arabic text will be discussed using the Bee Colony
		Optimization (BCO) algorithm. The POS tagging problem is represented as a
		graph and a new weighting technique is proposed to assign a transition value
		to each word class label which may not be probability, then the bees look for
		the best solution path. The dataset used in this study comes from the
		transliterated Quranic corpus consisting of 150 simple perfect sentences as
		an easy dataset category, 50 sentences with more than one S/P/O/K as a medium
		dataset category, and 50 selected Quran verses as a category. difficult
		datasets. The proposed approach is evaluated using a cross-validation
		technique, namely k-fold cross validation. The results showed an average
		accuracy of 100% for the easy dataset category, 98.96% for the medium dataset
		category, and 94.96% for the difficult dataset category.
	},
	source       = {semantic_scholar},
    journal      = {arxiv}
}
@article{huda2023improving,
	title        = {
		Improving Student Literacy Skills in Research and Scientific Articles: Arabic
		Language Education Study Program Sunan Kalijaga State Islamic University
		(2015-2020)
	},
	author       = {Nurul Huda},
	year         = {2023},
	url          = {
		https://www.semanticscholar.org/paper/f9701c851d5d11a650041194bde1333119170824
	},
	abstract     = {
		Indonesian education is currently faced with low interest in literacy. The
		results of the latest study/research from The Program for International
		Student Assessment (PISA) in 2018, which was released on December 3 2019 by
		the Ministry of Education and Culture, stated that Indonesia was ranked 62nd
		out of 71 countries. This research aims to describe the efforts of the UIN
		SuKa Arabic Education study program in improving students' literacy skills in
		research and scientific articles. This research is descriptive qualitative
		research. Data collection was carried out using observation and documentation
		methods. The data obtained will be analyzed using the Miles and Huberman
		model through three stages: data reduction, data display, then data
		conclusion drawing. The results of this research indicate that in the UIN
		SuKa Arabic Education study program's efforts to improve students' literacy
		skills in scientific articles, it can be viewed from three things, (1) viewed
		from classroom learning, (2) viewed from activities outside the classroom and
		(3) efforts others obtained independently by students. Viewed from classroom
		learning, the efforts made are (1) assistance in writing scientific articles,
		(2) motivating students. Viewed from learning outside the classroom, the
		efforts made are (1) developing the Al-Mahara Journal, (2) involving students
		in managing the Al-Mahara Journal. In terms of other efforts obtained
		independently by students which are also inseparable from the efforts of the
		UIN SuKa Arabic Education study program, is holding scientific writing
		seminar activities.
	},
	source       = {semantic_scholar}
}
@article{husna2024the,
	title        = {
		The Impact of Hybrid Quantum Learning Methods on Arabic Language Acquisition
		Among Students of Islamic Boarding School in Indonesia
	},
	author       = {Husna, Wildan Renaldi, Tawfiq Sarehmasor},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/a58ce8504f022d479e2d2a2612cc5be95d41c0f5
	},
	abstract     = {
		The study explores Hybrid Quantum Learning in Arabic language education amid
		COVID-19, employing a quantitative approach with descriptive research
		methods. Data collection includes observation, interviews, tests, and
		questionnaires, analyzed through descriptive techniques and hypothesis
		testing. Experimental and control groups assess Hybrid Quantum-Classical
		Learning's efficacy, showing a 63.34% average difference in the former and
		62.95% in the latter, indicating somewhat effective outcomes. Initially
		lacking, student engagement improved with model implementation. Further
		examination, supported by Likert scale responses, reveals an 87.33%
		satisfaction rate among students, highlighting the effectiveness of teaching
		auditory, visual, and kinesthetic skills in Arabic language education,
		particularly during the pandemic at Hasanka Islamic Boarding School in
		Indonesia.
	},
	source       = {semantic_scholar}
}
@inproceedings{jawaher2025,
	title        = {
		{JAWAHER}: A Multidialectal Dataset of {A}rabic Proverbs for {LLM}
		Benchmarking
	},
	author       = {
		Magdy, Samar Mohamed  and Kwon, Sang Yun  and Alwajih, Fakhraddin  and
		Abdelfadil, Safaa Taher  and Shehata, Shady  and Abdul-Mageed, Muhammad
	},
	year         = {2025},
	month        = apr,
	booktitle    = {
		Proceedings of the 2025 Conference of the Nations of the Americas Chapter of
		the Association for Computational Linguistics: Human Language Technologies
		(Volume 1: Long Papers)
	},
	publisher    = {Association for Computational Linguistics},
	address      = {Albuquerque, New Mexico},
	pages        = {12320--12341},
	doi          = {10.18653/v1/2025.naacl-long.613},
	isbn         = {979-8-89176-189-6},
	url          = {https://aclanthology.org/2025.naacl-long.613/},
	editor       = {Chiruzzo, Luis  and Ritter, Alan  and Wang, Lu}
}
@article{kanaan2013neural,
	title        = {
		A comparison of various neural network approaches for Arabic text
		classification
	},
	author       = {Kanaan, Ghassan and Al-Shalabi, Riyad and Gharaibeh, Sawsan},
	year         = {2013},
	journal      = {International Journal of Advanced Research in Artificial Intelligence},
	volume       = {2},
	number       = {2}
}
@article{keleg2025revisiting,
	title        = {Revisiting Common Assumptions about Arabic Dialects in NLP},
	author       = {Keleg, Amr and Goldwater, Sharon and Magdy, Walid},
	year         = {2025},
	journal      = {arXiv preprint arXiv:2505.21816}
}
@article{khan2025computationally,
	title        = {Computationally Distinguishing Quran and Pre-Islamic Arabic Poetry},
	author       = {Rushmila Shehreen Khan and Ahsanur Rahman},
	year         = {2025},
	url          = {
		https://www.semanticscholar.org/paper/5238b3456f49e1186f87c6302c2aea2fcf5cf994
	},
	abstract     = {
		The literary uniqueness and coherence of the Quran have been debated for
		centuries, with some Western scholars claiming that it draws from pre-Islamic
		Arabic poetry and lacks coherence, while others refuting these claims.
		However, this entire body of work relies mainly on qualitative analyses of
		selected verses. Here, we employed modern NLP techniques to systematically
		compare and contrast all verses of the Quran and pre-Islamic poetry.
		Specifically, we applied two BERT-based pre-trained models on Quran and
		pre-Islamic poetry verses to get embeddings, preprocessed them, and applied
		four clustering algorithms. Our results show that Quran (even Makki verses of
		the Quran - which are more poetic) and poem verses tend to form distinct
		clusters. Thus, our quantitative approach addresses gaps in the literature,
		offering fresh insights into long-standing debates. To our knowledge, this
		work is the first of its kind.
	},
	source       = {semantic_scholar},
    journal      =
    {2025 Eighth International Women in Data Science Conference at Prince Sultan University (WiDS PSU)}
}
@inproceedings{koto2024arabicmmlu,
	title        = {
		{A}rabic{MMLU}: Assessing Massive Multitask Language Understanding in
		{A}rabic
	},
	author       = {
		Koto, Fajri  and Li, Haonan  and Shatnawi, Sara  and Doughman, Jad  and
		Sadallah, Abdelrahman  and Alraeesi, Aisha  and Almubarak, Khalid  and
		Alyafeai, Zaid  and Sengupta, Neha  and Shehata, Shady  and Habash, Nizar and
		Nakov, Preslav  and Baldwin, Timothy
	},
	year         = {2024},
	month        = aug,
	booktitle    = {Findings of the Association for Computational Linguistics: ACL 2024},
	publisher    = {Association for Computational Linguistics},
	address      = {Bangkok, Thailand},
	pages        = {5622--5640},
	doi          = {10.18653/v1/2024.findings-acl.334},
	url          = {https://aclanthology.org/2024.findings-acl.334/},
	editor       = {Ku, Lun-Wei  and Martins, Andre  and Srikumar, Vivek}
}
@misc{koubaa2024arabiangptnativearabicgptbased,
	title        = {ArabianGPT: Native Arabic GPT-based Large Language Model},
	author       = {
		Anis Koubaa and Adel Ammar and Lahouari Ghouti and Omar Najar and Serry
		Sibaee
	},
	year         = {2024},
	url          = {https://arxiv.org/abs/2402.15313},
	journal       = {2402.15313},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@inproceedings{larabench,
	title        = {{LA}ra{B}ench: Benchmarking {A}rabic {AI} with Large Language Models},
	author       = {
		Abdelali, Ahmed  and Mubarak, Hamdy  and Chowdhury, Shammur  and Hasanain,
		Maram  and Mousi, Basel  and Boughorbel, Sabri  and Abdaljalil, Samir  and El
		Kheir, Yassine  and Izham, Daniel  and Dalvi, Fahim  and Hawasly, Majd  and
		Nazar, Nizi  and Elshahawy, Youssef  and Ali, Ahmed  and Durrani, Nadir  and
		Milic-Frayling, Natasa  and Alam, Firoj
	},
	year         = {2024},
	month        = mar,
	booktitle    = {
		Proceedings of the 18th Conference of the European Chapter of the Association
		for Computational Linguistics (Volume 1: Long Papers)
	},
	publisher    = {Association for Computational Linguistics},
	address      = {St. Julian{'}s, Malta},
	pages        = {487--520},
	doi          = {10.18653/v1/2024.eacl-long.30},
	url          = {https://aclanthology.org/2024.eacl-long.30/},
	editor       = {Graham, Yvette  and Purver, Matthew}
}
@misc{lighteval,
	title        = {LightEval: A lightweight framework for LLM evaluation},
	author       = {
		Habib, Nathan and Fourrier, Clémentine and Kydlíček, Hynek and Wolf, Thomas
		and Tunstall, Lewis
	},
	year         = {2023},
	url          = {https://github.com/huggingface/lighteval},
	version      = {0.11.0}
}
@article{makmur2024revolutionizing,
	title        = {
		Revolutionizing Foreign Language Pedagogy in Islamic Boarding Schools Through
		Online Platforms: A Post-Pandemic Perspective
	},
	author       = {
		Masrur Makmur, Yusring Sanusi Baso, Mardi Adi Amin, H. Machmoed, Nasmilah
		Yunus, Ikhwan M Said
	},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/0ca3b8d46ab3a7ac8e87d1f5c96b8bdf696659df
	},
	abstract     = {
		This study investigates the shift to online learning of foreign languages,
		specifically Arabic and English, in Islamic Boarding Schools post-pandemic,
		utilizing the Taallum Website as an e-learning model. A quasi-experimental
		time-series design was used to examine the changing role of foreign language
		teachers, comparing situations before and after the introduction of this
		e-learning method. Conducted from August 2021 to December 2022, the research
		involved both students and teachers. Surveys assessed their views on
		instructional techniques. Results highlighted a significant increase in
		teacher engagement with the e-learning model, as shown by a Paired Samples
		T-Test, which revealed a significant value of 0.000 and a t-count of 10.321,
		exceeding the t-table value of 2.365. The study demonstrates the Taallum
		Website application's efficacy in enhancing teacher involvement in foreign
		language education within Islamic Boarding Schools in the post-pandemic era,
		marking a departure from traditional e-module learning.
	},
	source       = {semantic_scholar}
}
@article{martínez2025a,
	title        = {
		A computational system to handle the orthographic layer of tajwid in
		contemporary Quranic Orthography
	},
	author       = {Alicia González Martínez},
	year         = {2025},
	url          = {http://arxiv.org/abs/2505.11379v1},
	abstract     = {
		Contemporary Quranic Orthography (CQO) relies on a precise system of phonetic
		notation that can be traced back to the early stages of Islam, when the Quran
		was mainly oral in nature and the first written renderings of it served as
		memory aids for this oral tradition. The early systems of diacritical marks
		created on top of the Quranic Consonantal Text (QCT) motivated the creation
		and further development of a fine-grained system of phonetic notation that
		represented tajwid-the rules of recitation. We explored the systematicity of
		the rules of tajwid, as they are encountered in the Cairo Quran, using a
		fully and accurately encoded digital edition of the Quranic text. For this
		purpose, we developed a python module that can remove or add the orthographic
		layer of tajwid from a Quranic text in CQO. The interesting characteristic of
		these two sets of rules is that they address the complete Quranic text of the
		Cairo Quran, so they can be used as precise witnesses to study its phonetic
		and prosodic processes. From a computational point of view, the text of the
		Cairo Quran can be used as a linchpin to align and compare Quranic
		manuscripts, due to its richness and completeness. This will let us create a
		very powerful framework to work with the Arabic script, not just within an
		isolated text, but automatically exploring a specific textual phenomenon in
		other connected manuscripts. Having all the texts mapped among each other can
		serve as a powerful tool to study the nature of the notation systems of
		diacritics added to the consonantal skeleton.
	},
	source       = {arxiv}, 
    journal      = {}
}

@article{maskud2020model,
	title        = {
		Model Arabic Language Teaching for Islamic Senior High Schools/ نموذج إدارة
		تعليم اللغة العربية للمدارس الثانوية
	},
	author       = {Maskud Maskud},
	year         = {2020},
	url          = {
		https://www.semanticscholar.org/paper/4e6193d66099dbc8c740dfcf7482e039aae78f5b
	},
	abstract     = {
		Management is the organizational process that involves planning, organizing,
		leadership and controlling. The objectives of this study were to describe the
		planning model, the instructional leadership model, and explain the quality
		control model of management of learning Arabic in MA Nuris 1 Jember, MANPK
		Jember, MA Al Qodiri 1 Jember. The research approach used is a qualitative
		approach with a type of case study with a multisite design. The analysis
		technique uses individual case analysis and cross-case analysis. The validity
		of the data in this study uses a test of credibility, transferability,
		dependability, and conformability. The findings of this study are (1) Arabic
		language learning planning model is integrated models, which begins
		environmental analysis with standardization of caregivers and quality
		assurance. Planning is developed through the integration of the K13
		curriculum with the pesantren curriculum, integration of madrasah Arabic
		learning with Islamic boarding schools referring to technical instructions
		from the ministry of religion, and student exchange programs. (2)
		Instructional leadership model in Arabic language learning is participative
		delegatif and non participative delegatif, with. The socialization of the
		vision, mission, and objectives are carried out by the quality assurance team
		with the aim of the madrasa community, parents of students and the community
		both directly and using print and electoral media. Both learning management
		is carried out centrally with a hierarchical system and a specialization
		system developed by the teacher in a centralized manner with various models
		that refer to boarding learning technical guidelines and guidebooks, thirdly
		constructing a climate of learning Arabic using a modern education system and
		time compaction. (3) The first Arabic language quality control model, input
		quality control students memorized Taqrib 250 verses and Imriti 250 verses,
		able to speak Arabic and English, have memorized Al-Quran, MTs, and
		pesantren. Input teacher master Arabic, pesantren alumni, can read books and
		teachers built by Dalwa Islamic Boarding School. Second, control of the
		learning process specifically for santri mukim and santri kalong, full-day
		school-based Islamic boarding schools, and supported by Arabic language
		olympiad, student exchanges, LPBA and Yaumul Arabi and involving, systems,
		media and personnel. Third, control of output based learning IT, supported by
		Khitobah, Yaumul Arabiy and weekly, monthly and semester evaluations. Based
		on the findings above, the formal findings of this research are the
		integrative delegated management model of Arabic language learning in Aliyah
		madrasas based Ma'had- can improve the quality of students in mastering all
		Arabic language skills.
	},
	source       = {semantic_scholar}
}
@inproceedings{mubarak-etal-2024-halwasa,
	title        = {
		Halwasa: Quantify and Analyze Hallucinations in Large Language Models:
		{A}rabic as a Case Study
	},
	author       = {Mubarak, Hamdy  and Al-Khalifa, Hend  and Alkhalefah, Khaloud Suliman},
	year         = {2024},
	month        = may,
	booktitle    = {
		Proceedings of the 2024 Joint International Conference on Computational
		Linguistics, Language Resources and Evaluation (LREC-COLING 2024)
	},
	publisher    = {ELRA and ICCL},
	address      = {Torino, Italia},
	pages        = {8008--8015},
	url          = {https://aclanthology.org/2024.lrec-main.705/},
	editor       = {
		Calzolari, Nicoletta  and Kan, Min-Yen  and Hoste, Veronique  and Lenci,
		Alessandro  and Sakti, Sakriani  and Xue, Nianwen
	},
	abstract     = {
		Large Language Models (LLMs) have shown superb abilities to generate texts
		that are indistinguishable from human-generated texts in many cases. However,
		sometimes they generate false, incorrect, or misleading content, which is
		often described as ``hallucinations''. Quantifying and analyzing
		hallucination in LLMs can increase their reliability and usage. While
		hallucination is being actively studied for English and other languages, and
		different benchmarking datsets have been created, this area is not studied at
		all for Arabic. In our paper, we create the first Arabic dataset that
		contains 10K of generated sentences by LLMs and annotate it for factuality
		and correctness. We provide detailed analysis of the dataset to analyze
		factual and linguistic errors. We found that 25{\%} of the generated
		sentences are factually incorrect. We share the dataset with the research
		community.
	}
}

@inproceedings{muennighoff2022crosslingual,
	title        = {Crosslingual Generalization through Multitask Finetuning},
	author       = {
		Muennighoff, Niklas  and Wang, Thomas  and Sutawika, Lintang  and Roberts,
		Adam  and Biderman, Stella  and Le Scao, Teven  and Bari, M Saiful  and Shen,
		Sheng  and Yong, Zheng Xin  and Schoelkopf, Hailey  and Tang, Xiangru  and
		Radev, Dragomir  and Aji, Alham Fikri  and Almubarak, Khalid  and Albanie,
		Samuel  and Alyafeai, Zaid  and Webson, Albert  and Raff, Edward  and Raffel,
		Colin
	},
	year         = {2023},
	month        = jul,
	booktitle    = {
		Proceedings of the 61st Annual Meeting of the Association for Computational
		Linguistics (Volume 1: Long Papers)
	},
	publisher    = {Association for Computational Linguistics},
	address      = {Toronto, Canada},
	pages        = {15991--16111},
	doi          = {10.18653/v1/2023.acl-long.891},
	url          = {https://aclanthology.org/2023.acl-long.891/},
	editor       = {Rogers, Anna  and Boyd-Graber, Jordan  and Okazaki, Naoaki}
}
@article{mursheda2025artificial,
	title        = {
		Artificial Intelligence (AI) Opens a New Horizon in the Study of the Holy
		Quran
	},
	author       = {Farhana Khandaker Mursheda, Mannan Kazi Abdul},
	year         = {2025},
	url          = {
		https://www.semanticscholar.org/paper/2eda0e8ada48489bb86ba7ac1c212315e9830df7
	},
	abstract     = {
		This article investigates the transformative impact of Artificial
		Intelligence (AI) on the study of the Holy Quran, highlighting the
		intersection between Islamic theology, computer science, and linguistics. AI
		technologies, particularly Natural Language Processing (NLP), Machine
		Learning (ML), and Deep Learning, are increasingly employed to analyse
		Quranic texts in innovative ways, enhancing traditional exegesis (tafsir),
		semantic interpretation, and linguistic pattern recognition. Through
		qualitative content analysis and case study approaches, this paper examines
		how AI enhances Quranic translation, accessibility, and educational
		applications, while also addressing the ethical, epistemological, and
		theological challenges that arise from its use. The findings reveal that AI
		not only supplements traditional scholarly frameworks but also democratises
		Quranic knowledge by improving accessibility for diverse linguistic and
		cognitive communities. However, the study emphasises the need for ethical
		guidelines and interdisciplinary collaboration to maintain theological
		integrity and avoid interpretive misuse. AI, when guided by Islamic ethical
		principles and scholarly oversight, can serve as a powerful tool for
		augmenting human understanding of the Quran. This paper proposes a balanced
		integration of AI in Quranic studies, positioning it as a support mechanism
		that enhances, rather than replaces, the profound human engagement with the
		sacred text.
	},
	source       = {semantic_scholar},
    journal      =
    {Theoretical and applied technological science review}
}
@article{mustapha2024arastem,
	title        = {
		Arastem: A native arabic multiple choice question benchmark for evaluating
		llms knowledge in stem subjects
	},
	author       = {
		Mustapha, Ahmad and Al-Khansa, Hadi and Al-Mubasher, Hadi and Mourad, Aya and
		Hamoud, Ranam and El-Husseini, Hasan and Al-Sakkaf, Marwah and Awad, Mariette
	},
	year         = {2024},
	journal      = {arXiv preprint arXiv:2501.00559}
}
@inproceedings{nacar2025towards,
	title        = {
		Towards Inclusive {A}rabic {LLM}s: A Culturally Aligned Benchmark in {A}rabic
		Large Language Model Evaluation
	},
	author       = {
		Nacar, Omer  and Sibaee, Serry Taiseer  and Ahmed, Samar  and Ben Atitallah,
		Safa  and Ammar, Adel  and Alhabashi, Yasser  and Al-Batati, Abdulrahman S.
		and Alsehibani, Arwa  and Qandos, Nour  and Elshehy, Omar  and Abdelkader,
		Mohamed  and Koubaa, Anis
	},
	year         = {2025},
	month        = jan,
	booktitle    = {
		Proceedings of the First Workshop on Language Models for Low-Resource
		Languages
	},
	publisher    = {Association for Computational Linguistics},
	address      = {Abu Dhabi, United Arab Emirates},
	pages        = {387--401},
	url          = {https://aclanthology.org/2025.loreslm-1.29/},
	editor       = {
		Hettiarachchi, Hansi  and Ranasinghe, Tharindu  and Rayson, Paul  and Mitkov,
		Ruslan  and Gaber, Mohamed  and Premasiri, Damith  and Tan, Fiona Anting  and
		Uyangodage, Lasitha
	}
}
@article{nahar2023optimalisasi,
	title        = {
		Optimalisasi Menghafal Al-Qur'an: Penerapan Metode Neuro Linguistic
		Programming (NLP) di Pesantren Islamic Centre Sumut
	},
	author       = {Syamsu Nahar, Nurul Sakinah Daulay, M. Nazri},
	year         = {2023},
	url          = {
		https://www.semanticscholar.org/paper/6d4c1c727ad4d7869b04be2a5e1bd371786b6074
	},
	abstract     = {
		This research aims to analyze the application of NLP/Neuro Linguistic
		Programming methods in improving the quality of memorizing the Quran at the
		Islamic Center. Sumut is well organized from the formation of the tasmi
		class, creating a conversational atmosphere to memorize, reminding that
		everything is aimed at and meaningful, understanding the learning style of
		the pupils, stimulating the brain performance to the maximum, giving
		judgment, identifying the problems of central and central difficulties in
		memorizing, giving motivation and solutions in the form of positive advice to
		the central and central, and giving reinforcement or strengthening. The data
		collection techniques used are observations, interviews, and documentation
		studies. The results of the research show that the implementation of the
		NLP/Neuro Linguistic Programming method improves the quality of memorizing
		the Qur'an at the Islamic Centre. Sumut is well organized starting from the
		formation of the tasmi class, creates a conversation atmosphere to memorize,
		reminds that everything is aimed at and meaningful, understands the learning
		style of the pupils, stimulates the brain performance to the maximum, gives
		judgment, identifies the problems of the centri and santriwati difficulties
		in falsifying, gives motivation and solutions in the form of positive advice
		to the santri and santriwati, gives reinforcement or strengthening, and
		evaluates the application of the NLP method in the Madrasah Hifzil Islamic
		Quran Centre.
	},
	source       = {semantic_scholar}
}
@article{naqiyah2024optimizing,
	title        = {
		Optimizing Arabic Language Learning: Monitoring and Evaluating the Public
		Speaking Program at Manahijussadat Islamic Boarding School Lebak-Banten
	},
	author       = {Neni Naqiyah, Titi Fitri, Zakiyah Arifa},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/ad623b3f708a1486844248d20e7c763429d7703a
	},
	abstract     = {
		Purpose, This research describes the monitoring process and evaluation
		process of the public speaking program at Manahijussadat Islamic Boarding
		School, Lebak-Banten. Design/methodology/approach, This research uses a
		qualitative descriptive research method and the researchers are the main
		research instrument in collecting data technique. Data collected is used
		employing interviews, observation, and documentation. It is analyzed using
		the Mile and Huberman model. Findings/result: This research indicates that
		the public speaking program at Manahijussadat Islamic Boarding School,
		Lebak-Banten, is monitored internally. It is monitored by persons within the
		institution who manage the program, namely the Language Advisory Council
		(LAC) and the Central Language Improvement (CLI) of Manahijussadat Islamic
		Boarding School. Apart from that, monitoring in the public speaking program
		also includes preventive and repressive monitoring, active and passive
		monitoring, the official truth, and the material truth. The evaluation of the
		public speaking program in this boarding school is an internal evaluation
		carried out by the employees working in the program between the Language
		Advisory Council and the Central Language Improvement and an evaluation from
		the Language Advisory Council for all students. With continuous monitoring
		and evaluation, the public speaking program can improve students' Arabic
		language teaching, especially speaking and writing skills. Originality/value
		to produce strategies that need to be eliminated or replaced, procedures that
		need to be improved, and directions that need to be stopped or continued. So
		that this program continues to get better, more effective, and more efficient
		in achieving the goals. Paper type, Research paper
	},
	source       = {semantic_scholar}
}
@article{nasution2024learning,
	title        = {
		Learning Arabic Language Sciences Based on Technology in Traditional Islamic
		Boarding Schools in Indonesia
	},
	author       = {
		Sahkholid Nasution, Hasan Asari, Harun Al-Rasyid, R. A. Dalimunthe, Aulia
		Rahman
	},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/957e4840abab2709a3905e91c79982bec1b446aa
	},
	abstract     = {
		This research aims to analyze traditional Islamic boarding school leaders'
		perceptions of technology, models of learning Arabic sciences in traditional
		Islamic boarding schools, forms of using technology in learning Arabic
		language sciences in traditional Islamic boarding schools, and foundation
		support for using technology in learning sciences. -Arabic language knowledge
		in traditional Islamic boarding schools. The type of research used is
		qualitative-descriptive. Research data was obtained using observation
		methods, in-depth interviews, and documentation. The instruments used are
		observation lists, interview lists, and documentation lists. Data were
		analyzed using ATLAS—ti9 software. The research results show that (1).
		traditional Islamic boarding school leaders' perception of technology is very
		positive, and there is no rejection of the presence of technology; (2). The
		model of learning Arabic language sciences in traditional Islamic boarding
		schools is still preserved, such as using the yellow book with the bandongan,
		sorogan, and wetonan methods (3). Using technology in learning Arabic
		language sciences in traditional Islamic boarding schools by operating
		computers, laptops, focus, and cell phones with the help of the internet (4).
		The foundation supports the use of technology in learning Arabic language
		sciences in traditional Islamic boarding schools by disbursing sufficient
		funds to procure learning technology tools or by building collaborations with
		other parties. This research aims to increase the use of learning technology
		in traditional Islamic boarding schools to create effective and efficient
		learning but remain resistant to Islamic boarding school values and
		traditions.
	},
	source       = {semantic_scholar}
}
@article{naveed2025comprehensive,
	title        = {A comprehensive overview of large language models},
	author       = {
		Naveed, Humza and Khan, Asad Ullah and Qiu, Shi and Saqib, Muhammad and
		Anwar, Saeed and Usman, Muhammad and Akhtar, Naveed and Barnes, Nick and
		Mian, Ajmal
	},
	year         = {2025},
	journal      = {ACM Transactions on Intelligent Systems and Technology},
	publisher    = {ACM New York, NY},
	volume       = {16},
	number       = {5},
	pages        = {1--72}
}
@article{nazri2025finetuning,
	title        = {
		Fine-tuning Large Language Model (BERT) for Islamic Moral Inquiry and
		Response
	},
	author       = {
		Nurul Aiman Binti Mohd Nazri, A'wathif Binti Omar, Amir 'Aatieff Bin Amir
		Hussin
	},
	year         = {2025},
	url          = {
		https://www.semanticscholar.org/paper/667aa09874957f72d8910ef52ba8253164e1b9cc
	},
	abstract     = {
		The development of Large Language Models (LLM) that are capable of
		understanding and responding to issues from an Islamic perspective is
		extremely insightful as it will benefit many people. For an LLM to do so, it
		is not enough for the model to only understand the language, but it also
		needs to understand the context and specific doctrines within the Islamic
		texts due to the complexity of Islamic jurisprudence and moral philosophy.
		Therefore, in this research, we intend to fine-tune an LLM model which is
		known as Bidirectional Encoder Representations from Transformers (BERT) for
		Islamic moral inquiry and response. By incorporating Islamic principles,
		norms, and teaching into the model, we aim to enhance the pre-trained BERT
		model’s ability to perform moral-related Question Answering (QA) tasks. The
		original model that we chose is deepset BERT model which was built based on
		BERT-large and meticulously pre-trained using the SQuaD 2.0 dataset,
		specifically for QA tasks. We fine-tune the model using the data extracted
		from “Islam: Questions and Answers: Character and Morals”, the Volume 13 of a
		Series of Islamic Books by Muhammad Saed Abdul-Rahman, where the data has
		been cleaned and pre-processed. The fine-tuning process used supervised
		learning techniques, to ensure its proficiency in understanding Islamic
		principles, providing accurate, contextually appropriate, and theologically
		sound responses. We assessed the model using F1 score and Levenshtein
		similarity evaluation metrics where F1 score merges precision and recall by
		computing their harmonic mean, while Levenshtein similarity compares the
		predicted and actual answers at the character level by normalizing the
		Levenshtein distance. Our research yielded significant success, evidenced by
		the remarkable enhancement in the average F1 scores and Levenshtein
		similarities, soaring from 0.30 and 0.24, to 0.74 and 0.67 respectively.
	},
	source       = {semantic_scholar},
    journal      =
    {International Journal on Perceptive and Cognitive Computing}
}
@article{novita2023revolutionizing,
	title        = {
		Revolutionizing Arabic Language Reading Skills Among Junior Islamic School
		Students via Innovative Digital Comic Learning Media
	},
	author       = {Diana Novita, Almaida Fitra, Diana Novita – Arabic},
	year         = {2023},
	url          = {
		https://www.semanticscholar.org/paper/45ec34b9469dcd204b2b8ffdd4ce75119a3964f3
	},
	abstract     = {
		This research aims to investigate the efficacy of utilizing digital comic
		media to enhance Qira'ah proficiency among seventh-grade students at MTs
		AL-Hikmah Bandar Lampung. The study addresses the following research
		questions: 1) How does the development of digital comic media contribute to
		improving Qira'ah proficiency among seventh-grade students at MTs AL-Hikmah
		Bandar Lampung; 2) What is the feasibility assessment of the digital comic
		media in enhancing Qira'ah proficiency among class VII students at MTs
		AL-Hikmah Bandar Lampung; 3) How do students respond to the implementation of
		digital comic media to enhance Qira'ah proficiency at MTs AL-Hikmah Bandar
		Lampung. Employing a research and development (R&D) approach, this study
		follows the ADDIE development model encompassing Analysis, Design,
		Development, Implementation, and Evaluation stages. The research outcomes
		indicate the high feasibility of Arabic digital comic media, validated by
		media experts with a commendable assessment score of 94.1%, and material
		experts with a noteworthy score of 91%. Additionally, student responses to
		the digital comic media garnered an overall average percentage of 91%,
		demonstrating a favorable reception. Likewise, teacher assessments of the
		digital comic media received a 95.5% score, attesting to its positive utility
		in the learning process. In conclusion, the developed Arabic digital comic
		media holds great promise as an effective tool for enhancing Qira'ah
		proficiency in the learning activities.
	},
	source       = {semantic_scholar}
}
@misc{OALL1,
	title        = {Open Arabic LLM Leaderboard},
	author       = {
		El Filali, Ali and Alobeidli, Hamza and Fourrier, Clémentine and Boussaha,
		Basma El Amel and Cojocaru, Ruxandra and Habib, Nathan and Hacid, Hakim
	},
	year         = {2024},
	publisher    = {OALL},
	howpublished = {\url{https://huggingface.co/spaces/OALL/Open-Arabic-LLM-Leaderboard}}
}
@misc{OALL2,
	title        = {The Open Arabic LLM Leaderboard 2},
	author       = {
		El Filali, Ali and ALOUI, Manel and Husaain, Tarique and Alzubaidi, Ahmed and
		Boussaha, Basma El Amel and Cojocaru, Ruxandra and Fourrier, Clémentine and
		Habib, Nathan and Hacid, Hakim
	},
	year         = {2025},
	publisher    = {OALL},
	howpublished = {https://huggingface.co/spaces/OALL/Open-Arabic-LLM-Leaderboard}
}
@misc{openai2024gpt4technicalreport,
	title        = {GPT-4 Technical Report},
	author       = {
		OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad
		and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko
		Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor
		Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming
		Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine
		and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and
		Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and
		Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie
		Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory
		Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen
		and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and
		Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah
		Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch
		and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila
		Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi
		and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and
		Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik
		Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan
		Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross
		and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff
		Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse
		and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and
		Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and
		Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin
		and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer
		Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish
		Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and
		Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and
		Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich
		and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo
		and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and
		Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin
		and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna
		Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv
		Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew
		and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake
		McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and
		Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and
		Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and
		Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and
		Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub
		Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and
		Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos
		and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila
		Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and
		Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell
		and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec
		Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real
		and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick
		Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish
		Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel
		Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah
		Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens
		and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and
		Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers
		and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson
		and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle
		and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea
		Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and
		Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei
		and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and
		Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel
		Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and
		Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan
		and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and
		Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and
		Barret Zoph
	},
	year         = {2024},
	url          = {https://arxiv.org/abs/2303.08774},
	journal       = {2303.08774},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{orca,
	title        = {ORCA: A Challenging Benchmark for Arabic Language Understanding},
	author       = {AbdelRahim Elmadany and El Moatez Billah Nagoudi and Muhammad Abdul-Mageed},
	year         = {2023},
	url          = {https://arxiv.org/abs/2212.10758},
	journal       = {2212.10758},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@article{oshallah2025crosslanguage,
	title        = {Cross-Language Approach for Quranic QA},
	author       = {Islam Oshallah and Mohamed Basem, Ali Hamdi and Ammar Mohammed},
	year         = {2025},
	url          = {http://arxiv.org/abs/2501.17449v1},
	abstract     = {
		Question answering systems face critical limitations in languages with
		limited resources and scarce data, making the development of robust models
		especially challenging. The Quranic QA system holds significant importance as
		it facilitates a deeper understanding of the Quran, a Holy text for over a
		billion people worldwide. However, these systems face unique challenges,
		including the linguistic disparity between questions written in Modern
		Standard Arabic and answers found in Quranic verses written in Classical
		Arabic, and the small size of existing datasets, which further restricts
		model performance. To address these challenges, we adopt a cross-language
		approach by (1) Dataset Augmentation: expanding and enriching the dataset
		through machine translation to convert Arabic questions into English,
		paraphrasing questions to create linguistic diversity, and retrieving answers
		from an English translation of the Quran to align with multilingual training
		requirements; and (2) Language Model Fine-Tuning: utilizing pre-trained
		models such as BERT-Medium, RoBERTa-Base, DeBERTa-v3-Base, ELECTRA-Large,
		Flan-T5, Bloom, and Falcon to address the specific requirements of Quranic
		QA. Experimental results demonstrate that this cross-language approach
		significantly improves model performance, with RoBERTa-Base achieving the
		highest MAP@10 (0.34) and MRR (0.52), while DeBERTa-v3-Base excels in
		Recall@10 (0.50) and Precision@10 (0.24). These findings underscore the
		effectiveness of cross-language strategies in overcoming linguistic barriers
		and advancing Quranic QA systems
	},
	source       = {arxiv},
    journal      = {Proceedings of Tenth International Congress on Information and Communication Technology (ICICT 2025)}
}
@article{othman2020arabic,
	title        = {Arabic Text Processing Model: Verbs Roots and Conjugation Automation},
	author       = {M. Othman, M. A. Al-Hagery, Yahya Muhammad El Hashemi},
	year         = {2020},
	url          = {
		https://www.semanticscholar.org/paper/ea17a3edbf5b13d26d517f50d6e8f4447ab901a2
	},
	abstract     = {
		The Natural Language Processing (NLP) is a process to automate the text or
		speech of Natural Languages. This automation is mainly conducted for Western
		languages. The Arabic Language got less focus in this area. This paper
		presents a Model to recognize an Arabic sentence. A new morphological model
		based on regular expressions is developed to recognize the Arabic verbs. A
		hash table containing all Arabic three-letters’ root of verbs is implemented.
		The total number of Arabic verbs that are derived from three-letters’ root
		size is 23090. The number of roots is 6104. A set of rules forming the Arabic
		grammar is used to derive and analyze the syntax of Arabic sentences. About
		87% of the verbs represented in our regular expressions’ engine are detected.
		Moreover, the sentences are also recognized. In several Surat of the Quran,
		only 9% of the detected verbs are false-positive (a non-verb declared as a
		verb), and 4% are considered false-negative (a verb is considered as a noun).
		This rate is mainly because we are not using vowels even that the Quran (our
		case study) is using them. The reason behind our decision is to be able to
		handle all Arabic texts, which mostly are not using vowels.
	},
	source       = {semantic_scholar},
    journal      = {arxiv}
    
    
}
@inproceedings{palm2025,
	title        = {
		Palm: A Culturally Inclusive and Linguistically Diverse Dataset for {A}rabic
		{LLM}s
	},
	author       = {
		Alwajih, Fakhraddin  and El Mekki, Abdellah  and Magdy, Samar Mohamed  and
		Elmadany, AbdelRahim A.  and Nacar, Omer  and Nagoudi, El Moatez Billah  and
		Abdel-Salam, Reem  and Atwany, Hanin  and Nafea, Youssef  and Yahya,
		Abdulfattah Mohammed  and Alhamouri, Rahaf  and Alsayadi, Hamzah A.  and
		Zayed, Hiba  and Shatnawi, Sara  and Sibaee, Serry  and Ech-chammakhy, Yasir
		and Al-Dhabyani, Walid  and Ali, Marwa Mohamed  and Jarraya, Imen  and
		El-Shangiti, Ahmed Oumar  and Alraeesi, Aisha  and AL-Ghrawi, Mohammed Anwar
		and Al-Batati, Abdulrahman S.  and Mohamed, Elgizouli  and Elgindi, Noha Taha
		and Saeed, Muhammed  and Atou, Houdaifa  and Yahia, Issam Ait  and Bouayad,
		Abdelhak  and Machrouh, Mohammed  and Makouar, Amal  and Alkawi, Dania  and
		Mohamed, Mukhtar  and Abdelfadil, Safaa Taher  and Ounnoughene, Amine Ziad
		and Rouabhia, Anfel  and Assi, Rwaa  and Sorkatti, Ahmed  and Tourad,
		Mohamedou Cheikh  and Koubaa, Anis  and Berrada, Ismail  and Jarrar, Mustafa
		and Shehata, Shady  and Abdul-Mageed, Muhammad
	},
	year         = {2025},
	month        = jul,
	booktitle    = {
		Proceedings of the 63rd Annual Meeting of the Association for Computational
		Linguistics (Volume 1: Long Papers)
	},
	publisher    = {Association for Computational Linguistics},
	address      = {Vienna, Austria},
	pages        = {32871--32894},
	doi          = {10.18653/v1/2025.acl-long.1579},
	isbn         = {979-8-89176-251-0},
	url          = {https://aclanthology.org/2025.acl-long.1579/},
	editor       = {
		Che, Wanxiang  and Nabende, Joyce  and Shutova, Ekaterina  and Pilehvar,
		Mohammad Taher
	}
}
@inproceedings{palmx2025,
    title = "{P}alm{X} 2025: The First Shared Task on Benchmarking {LLM}s on {A}rabic and Islamic Culture",
    author = "Alwajih, Fakhraddin  and
      El Mekki, Abdellah  and
      Mubarak, Hamdy  and
      Hawasly, Majd  and
      Mohamed, Abubakr  and
      Abdul-Mageed, Muhammad",
    editor = "Darwish, Kareem  and
      Ali, Ahmed  and
      Abu Farha, Ibrahim  and
      Touileb, Samia  and
      Zitouni, Imed  and
      Abdelali, Ahmed  and
      Al-Ghamdi, Sharefah  and
      Alkhereyf, Sakhar  and
      Zaghouani, Wajdi  and
      Khalifa, Salam  and
      AlKhamissi, Badr  and
      Almatham, Rawan  and
      Hamed, Injy  and
      Alyafeai, Zaid  and
      Alowisheq, Areeb  and
      Inoue, Go  and
      Mrini, Khalil  and
      Alshammari, Waad",
    booktitle = "Proceedings of The Third Arabic Natural Language Processing Conference: Shared Tasks",
    month = nov,
    year = "2025",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.arabicnlp-sharedtasks.107/",
    doi = "10.18653/v1/2025.arabicnlp-sharedtasks.107",
    pages = "774--789",
    ISBN = "979-8-89176-356-2",
    abstract = "Large Language Models (LLMs) inherently reflect the vast data distributions they encounter during their pre-training phase. As this data is predominantly sourced from the web, there is a high chance it will be skewed towards high-resourced languages and cultures, such as those of the West. Consequently, LLMs often exhibit a diminished understanding of certain communities, a gap that is particularly evident in their knowledge of Arabic and Islamic cultures. This issue becomes even more pronounced with increasingly under-represented topics. To address this critical challenge, we introduce PalmX 2025, the first shared task designed to benchmark the cultural competence of LLMs in these specific domains. The task is composed of two subtasks featuring multiple-choice questions (MCQs) in Modern Standard Arabic (MSA): General Arabic Culture and General Islamic Culture. These subtasks cover a wide range of topics, including traditions, food, history, religious practices, and language expressions from across 22 Arab countries. The initiative drew considerable interest, with 26 teams registering for Subtask 1 and 19 for Subtask 2, culminating in nine and six valid submissions, respectively. Our findings reveal that task-specific fine-tuning substantially boosts performance over baseline models. The top-performing systems achieved an accuracy of 72.15{\%} on cultural questions and 84.22{\%} on Islamic knowledge. Parameter-efficient fine-tuning emerged as the predominant and most effective approach among participants, while the utility of data augmentation was found to be domain-dependent. Ultimately, this benchmark provides a crucial, standardized framework to guide the development of more culturally grounded and competent Arabic LLMs. Results of the shared task demonstrate that general cultural and general religious knowledge remain challenging to LLMs, motivating us to continue to offer the shared task in the future."
}
@article{peuriekeu2021a,
	title        = {
		A Text Mining Discovery of Similarities and Dissimilarities Among Sacred
		Scriptures
	},
	author       = {
		Younous Mofenjou Peuriekeu and Victoire Djimna Noyum and Cyrille Feudjio and Alkan
		Goktug and Ernest Fokoue
	},
	year         = {2021},
	url          = {
		https://www.semanticscholar.org/paper/f8f1a49a709fac1d82af680fe970d10a71cd2ecf
	},
	abstract     = {
		The careful examination of sacred texts gives valuable insights into human
		psychology, different ideas regarding the organization of societies as well
		as into terms like truth and God. To improve and deepen our understanding of
		sacred texts, their comparison, and their separation is crucial. For this
		purpose, we use our data set has nine sacred scriptures. This work deals with
		the separation of the Quran, the Asian scriptures Tao-Te-Ching, the Buddhism,
		the Yogasutras, and the Upanishads as well as the four books from the Bible,
		namely the Book of Proverbs, the Book of Ecclesiastes, the Book of
		Ecclesiasticus, and the Book of Wisdom. These scriptures are analyzed based
		on the natural language processing NLP creating the mathematical
		representation of the corpus in terms of frequencies called document term
		matrix (DTM). After this analysis, machine learning methods like supervised
		and unsupervised learning are applied to perform classification. Here we use
		the Multinomial Naive Bayes (MNB), the Super Vector Machine (SVM), the Random
		Forest (RF), and the K-nearest Neighbors (KNN). We obtain that among these
		methods MNB is able to predict the class of a sacred text with an accuracy of
		about 85.84 %.
	},
	source       = {semantic_scholar}, 
    journal      = {}
}
@inproceedings{phuc2025puxai,
	title        = {
		{PuxAI} at {QIAS} 2025: Multi-Agent Retrieval-Augmented Generation for
		Islamic Inheritance and Knowledge Reasoning
	},
	author       = {Phuc, Nguyen Xuan and Thin, Dang Van},
	year         = {2025},
	booktitle    = {Proceedings of the ArabicNLP 2025 Shared Tasks},
	publisher    = {Association for Computational Linguistics}
}
@article{premasiri2022dtw,
	title        = {
		DTW at Qur’an QA 2022: Utilising Transfer Learning with Transformers for
		Question Answering in a Low-resource Domain
	},
	author       = {Damith Premasiri and Tharindu Ranasinghe and W. Zaghouani and R. Mitkov},
	year         = {2022},
	url          = {
		https://www.semanticscholar.org/paper/a56c8e6b2db32abe2c38bbc4a78a4a895137d15d
	},
	abstract     = {
		The task of machine reading comprehension (MRC) is a useful benchmark to
		evaluate the natural language understanding of machines. It has gained
		popularity in the natural language processing (NLP) field mainly due to the
		large number of datasets released for many languages. However, the research
		in MRC has been understudied in several domains, including religious texts.
		The goal of the Qur’an QA 2022 shared task is to fill this gap by producing
		state-of-the-art question answering and reading comprehension research on
		Qur’an. This paper describes the DTW entry to the Quran QA 2022 shared task.
		Our methodology uses transfer learning to take advantage of available Arabic
		MRC data. We further improve the results using various ensemble learning
		strategies. Our approach provided a partial Reciprocal Rank (pRR) score of
		0.49 on the test set, proving its strong performance on the task.
	},
	source       = {semantic_scholar}, 
    journal      = {}
}
@misc{promptsource,
	title        = {
		PromptSource: An Integrated Development Environment and Repository for
		Natural Language Prompts
	},
	author       = {
		Stephen H. Bach and Victor Sanh and Zheng-Xin Yong and Albert Webson and
		Colin Raffel and Nihal V. Nayak and Abheesht Sharma and Taewoon Kim and M
		Saiful Bari and Thibault Fevry and Zaid Alyafeai and Manan Dey and Andrea
		Santilli and Zhiqing Sun and Srulik Ben-David and Canwen Xu and Gunjan
		Chhablani and Han Wang and Jason Alan Fries and Maged S. Al-shaibani and
		Shanya Sharma and Urmish Thakker and Khalid Almubarak and Xiangru Tang and
		Dragomir Radev and Mike Tian-Jian Jiang and Alexander M. Rush
	},
	year         = {2022},
	url          = {https://arxiv.org/abs/2202.01279},
	journal       = {2202.01279},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@article{putra2021proposing,
	title        = {
		Proposing machine learning of Tafsir al-Quran: In search of objectivity with
		semantic analysis and Natural Language Processing
	},
	author       = {D.I. Ansusa Putra, M. Yusuf},
	year         = {2021},
	url          = {
		https://www.semanticscholar.org/paper/2f67571a66e6a634a633f7d8fe4f7ee17688e366
	},
	abstract     = {
		Computer technology is neutral information technology without any
		subjectivities and biases. The advantages of computer technology can help to
		minimize intervention and subjectivity in the interpretation of the Quran.
		The problem of subjectivity in interpretation of the Quran is a long
		discussion. However, Interpretation of Quran has interrelated each other
		called tafsir al-Quran bil Quran method. This article proposes objective
		methodology and design of machine learning of Tafsir al-Quran using the
		advances in data science technology. Using the latest artificial intelligence
		technology that is Machine Learning and Natural Language Processing (NLP).
		Furthermore, this proposal proves the novelty of the role of technology in
		the preparation of religious material in millennial life from a secondary
		role to a primary role.
	},
	source       = {semantic_scholar}
}
@article{putri2021maharah,
	title        = {
		Maharah al-Qira'ah Learning Model through Edmodo at Department of Arabic
		Language Education, Imam Bonjol State Islamic University, Padang
	},
	author       = {N. Putri, R. Rahmawati, H. Hanomi},
	year         = {2021},
	url          = {
		https://www.semanticscholar.org/paper/4a3bf81e00069fa0528889add927bb4c15ed405b
	},
	abstract     = {
		This study aims to determine the validity of Maharatul Qira'ah learning model
		design by utilizing Edmodo e-learning application, and to describe the
		learning model and its impact on student participation. The rapid development
		of ICT is influencing the Arabic learning model at PBA UIN IB Padang which is
		still using the classical model, and the participation of students is still
		lacking. Here, the innovation of the classical learning model toward
		online-based learning needs to be done, such as by utilizing Edmodo
		e-learning application. This research used the ADDIE step model. The research
		subjects consisted of 32 students and 5 lecturers of PBA. This study used
		valid instruments. Based on the data analysis, the validity of the design of
		the teaching materials presented in the Edmodo e-learning has met the very
		valid criteria, with a score of 83.59.  The e-learning model developed was a
		blended learning with complement functions in the form of synchronous and
		asynchronous communication. This e-learning had been able to increase student
		participation by 81,25%.  This study recommends further researchers to use
		Edmodo e-learning application in teaching various language skills in a fully
		integrated online model.
	},
	source       = {semantic_scholar}
}
@article{qudsi2024strategy,
	title        = {
		STRATEGY FOR FORMING AN ARABIC LANGUAGE ENVIRONMENT IN AL QODIRI ISLAMIC
		SENIOR HIGH SCHOOL 1 JEMBER
	},
	author       = {Muhowwifullah Amin Qudsi, Maskud Maskud, Abdul Rosyid},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/31c0e13907309dc885dc4267c315826037e66735
	},
	abstract     = {
		This study aimed to analyze models of the Arabic language environment
		formation to increase the ability of language learners in Al Qodiri Islamic
		Senior High School 1 Jember. This research method was qualitative. The
		research was conducted at Al Qodiri Islamic Senior High School 1 Jember.
		Research respondents were 245 students of boarding Islamic Senior High School
		that consisted of 170 females and 73 males. The data collection method used
		participant observation instruments and interviews. Both of these instruments
		were used to get data about the models of the Arabic language environment
		formation to increase the language skills of students in Islamic Senior High
		School. Steps of Data analysis techniques were collecting data, reducing
		data, presenting data, and making a conclusion. The results showed that the
		model of the formation of the Arabic language environment consisted of the
		visual environment, audio environment, and the audiovisual environment. This
		model was able to overcome the difficulties of students in acquiring Arabic.
		This model of the Arabic language environment provides direct and natural
		Arabic mastery. Qualitative analysis results showed that the Arabic
		environment was able to increase students’ language skills of Al Qodiri
		Islamic Senior High School 1 Jember.
	},
	source       = {semantic_scholar}
}

@article{rinda2024development,
	title        = {
		Development of Electronic Modules Based on Blended Learning Flipped Classroom
		in Arabic Language Subject Class X Nuraida Islamic Boarding School Bogor
	},
	author       = {Penta Eka Nova Rinda, Nurdin Ibrahim, Masitowati Gatot},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/1bc7be139547f914f39ecb55e8421800a6bb7177
	},
	abstract     = {
		Learning outcomes in Arabic language subjects in secondary schools are still
		low, so effective teaching materials are needed to improve Arabic language
		learning outcomes. The study aims to develop and test the feasibility and
		effectiveness of developing electronic modules based on blended learning
		flipped classroom in class X Arabic subjects at Nuraida Islamic Boarding
		School Bogor. The study uses a development model Borg and Gall which is
		integrated with the Rowntree model. To test the feasibility of the researcher
		using validation from media experts, design experts and material experts and
		also considering the results of user responses from teachers and students.
		From the results of the feasibility test carried out by material experts at
		81.33%, instructional design/media experts at 90%, teacher users at 90% and
		student users at 95%. Overall, the category was "very feasible". The results
		of the pretest and posttest data analysis show that the average pretest score
		of students is 52 and the average posttest score of students is 90, while the
		maximum average score is 70. Based on effectiveness testing using the N-Gain
		Score formula, a result of 0.8 was obtained in the high category or a
		percentage of 90. Per the conversion of the achievement level of the N-Gain
		score review results with a value of >76 which is categorized as effective.
		This means that the e-module developed is effective in improving student
		learning outcomes in Arabic language subjects. So, it can be concluded that
		the electronic module based on the blended learning flipped classroom in
		Arabic subjects that was developed is feasible and effective to use.
	},
	source       = {semantic_scholar}
}
@article{rochmawati2025portrait,
	title        = {
		Portrait of Arabic Language Activity Model for Students of Al-Amanah Modern
		Islamic Boarding School, Sidoarjo, Indonesia
	},
	author       = {
		Nur Rochmawati, Mirwan Akhmad Taufiq, Atiq Mohammad Romdlon, Mohammed jassim
		Mohammed Rady
	},
	year         = {2025},
	url          = {
		https://www.semanticscholar.org/paper/0f71366d39871ce75b67f13981ac5010a3dc7f25
	},
	abstract     = {
		This study aims to identify models of activities that can enhance Arabic
		language skills at the Al-Amanah Islamic Boarding School. The objective is to
		explore the types of language activities that strengthen students' Arabic
		skills and the assessment forms applied at the school. The methodology used
		is descriptive qualitative, with data collected through in-depth interviews
		with teachers, language department management, and students proficient in
		Arabic, along with documentation of the learning materials used. The results
		show that Arabic language activities at the school include four activities:
		vocabulary enhancement, speaking skills in daily life, lectures, and an
		intensive Arabic program for new students. These activities significantly
		improve students' ability to speak Arabic, focusing on education that
		supports speaking practice through memorisation, reading vocabulary, and
		speaking in Arabic.
	},
	source       = {semantic_scholar}
}
@article{rohmah2024audiovisual,
	title        = {
		Audio-Visual Media to Enhance Learning Motivation in Indonesian Language
		Subject for the 3rd-Grade of Islamic Elementary School
	},
	author       = {Fina Zainur Rohmah, Rohmat Dwi Yunianta, Ahmad Shofiyuddin Ichsan},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/40d951c5342b023a455b7ad56eb16c57694596a0
	},
	abstract     = {
		One significant reason for the low motivation among students is the lack of
		creative media in the learning process. This study aims to investigate the
		effectiveness of audio-visual media in enhancing learning motivation in the
		Indonesian language subject for Grade III at Madrasah Ibtidaiyah. This field
		research, conducted at Madrasah Ibtidaiyah Al-Ma’had An Nur Bantul, employs a
		descriptive qualitative approach with data collected through observation,
		interviews, and documentation. Data analysis follows the Miles and Huberman
		model, involving data reduction, data presentation, and conclusion drawing or
		verification, with source triangulation ensuring data validity. The study's
		findings include the implementation of contextual teaching methods, delivery
		of Indonesian language material using concrete objects aided by audio-visual
		media, and positive student responses to these methods. The application of
		contextual teaching in the Indonesian language subject for Grade III led to
		students discovering the meaning of learning through direct experiences,
		becoming more active in learning, and showing significant development in
		literacy skills. This study underscores the importance of incorporating
		creative media, particularly audio-visual aids, to enhance student motivation
		and engagement in the learning process
	},
	source       = {semantic_scholar}
}
@article{rustandi2022the,
	title        = {
		The tabligh language of the millenial generation in social media: Analysis of
		popular Islamic account framing
	},
	author       = {Ridwan Rustandi},
	year         = {2022},
	url          = {
		https://www.semanticscholar.org/paper/e6558cfcd89011282b680473af8d1cc59f36a828
	},
	abstract     = {
		Purpose - This study aims to analyze the construction of tabligh language
		based on religious moderation in social media. The research was conducted by
		taking the research object of Popular Islamic accounts on three social media
		platforms, namely Facebook, YouTube, and Instagram. Specifically, the
		research is directed at studying expressive, conventional, rhetorical logic,
		and religious moderation tabligh language negotiations for the millennial
		generation. An interpretive paradigm was chosen in this study.Method -
		Qualitative approach through the Gamson and Modigliani model framing analysis
		method was chosen to analyze the packaging pattern of the tabligh language.
		Data were collected through observation, interview, and documentation
		techniques. Furthermore, it is analyzed through three stages: reduction,
		display, and verification.Result  -  The study results conclude that the
		expressive logic of the tabligh language contained in the Popular Islam
		account is related to the normativity and actuality of Islamic teachings. The
		conventional logic set by the Popular Islam account is based on normative
		arguments, actual arguments, opinions of Islamic leaders, metaphors or
		parables, and phenomena that are trending in society. Rhetorical logic is
		carried out by using language style, communication principles, appeals and
		message organizational structures, and visualizing messages in a way that
		links symbols, images, and text. The negotiation of religious moderation
		discourse is packaged by showing the face of Islam on two sides, namely the
		doctrinal side and the actual side. Popular Islam places historical,
		empirical, and actual religious reality as the core issue of Islamic ideas.
		Moderate and accurate packaging tools are presented both within the framework
		of framing and reasoning of Popular Islamic accounts.Implication – The
		implications of this research relate to the importance of building
		theological, technological, and humanist awareness in preparing the
		infrastructure and ecosystem of da'wah resources to face the era of digital
		industrialization.Originality - This study analyzes the phenomenon of how the
		choice of diction and tabligh language style regarding religious messages
		based on religious moderation is presented in a virtual space.***Tujuan -
		Penelitian ini bertujuan untuk menganalisis konstruksi bahasa tabligh
		berdasarkan moderasi beragama di media sosial. Penelitian dilakukan dengan
		mengambil objek penelitian akun Islami Populer di tiga platform media sosial
		yaitu Facebook, YouTube, dan Instagram. Secara spesifik, penelitian diarahkan
		untuk mengkaji negosiasi bahasa tabligh ekspresif, konvensional, logika
		retoris, dan moderasi agama bagi generasi milenial. Paradigma interpretif
		dipilih dalam penelitian ini.Metode - Pendekatan kualitatif melalui metode
		analisis framing model Gamson dan Modigliani dipilih untuk menganalisis pola
		pengemasan bahasa tabligh. Pengumpulan data dilakukan melalui teknik
		observasi, wawancara, dan dokumentasi. Selanjutnya dianalisis melalui tiga
		tahap yaitu reduksi, display, dan verifikasi.Hasil - Hasil penelitian
		menyimpulkan bahwa logika ekspresif bahasa tabligh yang terdapat dalam akun
		Islam Populer berkaitan dengan normativitas dan aktualitas ajaran Islam.
		Logika konvensional yang ditetapkan oleh akun Islam Populer didasarkan pada
		argumen normatif, argumen aktual, pendapat para pemimpin Islam, metafora atau
		perumpamaan, dan fenomena yang sedang tren di masyarakat. Logika retoris
		dilakukan dengan menggunakan gaya bahasa, prinsip komunikasi, daya tarik dan
		struktur organisasi pesan, dan memvisualisasikan pesan dengan cara
		menghubungkan simbol, gambar, dan teks. Negosiasi wacana moderasi keagamaan
		dikemas dengan menampilkan wajah Islam dalam dua sisi, yaitu sisi doktrinal
		dan sisi aktual. Islam kerakyatan menempatkan realitas keagamaan historis,
		empiris, dan aktual sebagai isu inti gagasan-gagasan Islam. Alat pengemasan
		yang moderat dan akurat disajikan baik dalam kerangka pembingkaian dan
		penalaran akun Islami Populer.Implikasi – Implikasi penelitian ini berkaitan
		dengan pentingnya membangun kesadaran teologis, teknologis, dan humanis dalam
		mempersiapkan infrastruktur dan ekosistem sumber daya dakwah untuk menghadapi
		era industrialisasi digital.Orisinalitas - Penelitian ini menganalisis
		fenomena bagaimana pilihan diksi dan gaya bahasa tabligh tentang pesan-pesan
		keagamaan berbasis moderasi keagamaan dihadirkan dalam ruang virtual.
	},
	source       = {semantic_scholar}
}
@article{sabour2023diacriticaware,
	title        = {
		DIACRITIC-AWARE ALIGNMENT AND CLASSIFICATION IN ARABIC SPEECH: A FUSION OF
		FUZTPI AND ML MODELS
	},
	author       = {Adel Sabour, Abdeltawab M. Hendawi, Mohamed Ali},
	year         = {2023},
	url          = {
		https://www.semanticscholar.org/paper/83d64f0185cdba3ce28cda4b465029bfc60337c3
	},
	abstract     = {
		This paper presents the Quran Speech Recognition (QRSR) system, achieving
		alignment and classification accuracies up to 96%. The system is designed to
		advance Arabic Automatic Speech Recognition (ASR) and Text-to-Speech (TTS) by
		focusing on the Arabic diacritic-annotated text. We address the limitations
		of existing Arabic ASR systems and introduce the Fuzzy Text Alignment and
		Rule-based Classifier (FTARC) for segmenting audio files and aligning text.
		The FuzTPI algorithm is integrated with Machine Learning models like Na¨ıve
		Bayes, Support Vector Machine, and Random Forest. This research aims to
		generalize the findings for broader Arabic text and contribute to an expanded
		audio dataset, thereby enhancing Arabic NLP and speech recognition
		capabilities.
	},
	source       = {semantic_scholar}
}
@article{sadi2016applying,
	title        = {Applying Ontological Modeling on Quranic Nature Domain},
	author       = {
		A. B. M. Shamsuzzaman Sadi, Towfique Anam, Mohamed Abdirazak, Abdillahi Hasan
		Adnan, Sazid Zaman Khan, Mohamed Mahmudur Rahman, Ghassan Samara
	},
	year         = {2016},
	url          = {http://arxiv.org/abs/1604.03318v1},
	abstract     = {
		The holy Quran is the holy book of the Muslims. It contains information about
		many domains. Often people search for particular concepts of holy Quran based
		on the relations among concepts. An ontological modeling of holy Quran can be
		useful in such a scenario. In this paper, we have modeled nature related
		concepts of holy Quran using OWL (Web Ontology Language) / RDF (Resource
		Description Framework). Our methodology involves identifying nature related
		concepts mentioned in holy Quran and identifying relations among those
		concepts. These concepts and relations are represented as classes/instances
		and properties of an OWL ontology. Later, in the result section it is shown
		that, using the Ontological model, SPARQL queries can retrieve verses and
		concepts of interest. Thus, this modeling helps semantic search and query on
		the holy Quran. In this work, we have used English translation of the holy
		Quran by Sahih International, Protege OWL Editor and for querying we have
		used SPARQL.
	},
	source       = {arxiv}
}
@article{salameh2024quranic,
	title        = {
		Quranic Audio Dataset: Crowdsourced and Labeled Recitation from Non-Arabic
		Speakers
	},
	author       = {Raghad Salameh, Mohamad Al Mdfaa},
	year         = {2024},
	url          = {http://arxiv.org/abs/2405.02675v1},
	abstract     = {
		This paper addresses the challenge of learning to recite the Quran for
		non-Arabic speakers. We explore the possibility of crowdsourcing a carefully
		annotated Quranic dataset, on top of which AI models can be built to simplify
		the learning process. In particular, we use the volunteer-based crowdsourcing
		genre and implement a crowdsourcing API to gather audio assets. We integrated
		the API into an existing mobile application called NamazApp to collect audio
		recitations. We developed a crowdsourcing platform called Quran Voice for
		annotating the gathered audio assets. As a result, we have collected around
		7000 Quranic recitations from a pool of 1287 participants across more than 11
		non-Arabic countries, and we have annotated 1166 recitations from the dataset
		in six categories. We have achieved a crowd accuracy of 0.77, an inter-rater
		agreement of 0.63 between the annotators, and 0.89 between the labels
		assigned by the algorithm and the expert judgments.
	},
	source       = {arxiv},
    journal      = {arxiv}
}
##models
@misc{sengupta2023jais,
	title        = {
		Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open
		Generative Large Language Models
	},
	author       = {
		Neha Sengupta and Sunil Kumar Sahu and Bokang Jia and Satheesh Katipomu and
		Haonan Li and Fajri Koto and William Marshall and Gurpreet Gosal and Cynthia
		Liu and Zhiming Chen and Osama Mohammed Afzal and Samta Kamboj and Onkar
		Pandit and Rahul Pal and Lalit Pradhan and Zain Muhammad Mujahid and Massa
		Baali and Xudong Han and Sondos Mahmoud Bsharat and Alham Fikri Aji and
		Zhiqiang Shen and Zhengzhong Liu and Natalia Vassilieva and Joel Hestness and
		Andy Hock and Andrew Feldman and Jonathan Lee and Andrew Jackson and Hector
		Xuguang Ren and Preslav Nakov and Timothy Baldwin and Eric Xing
	},
	year         = {2023},
	url          = {https://arxiv.org/abs/2308.16149},
	journal       = {2308.16149},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL},
	abstract     = {
		We introduce Jais and Jais-chat, new state-of-the-art Arabic-centric
		foundation and instruction-tuned open generative large language models
		(LLMs). The models are based on the GPT-3 decoder-only architecture and are
		pretrained on a mixture of Arabic and English texts, including source code in
		various programming languages. With 13 billion parameters, they demonstrate
		better knowledge and reasoning capabilities in Arabic than any existing open
		Arabic and multilingual models by a sizable margin, based on extensive
		evaluation. Moreover, the models are competitive in English compared to
		English-centric open models of similar size, despite being trained on much
		less English data. We provide a detailed description of the training, the
		tuning, the safety alignment, and the evaluation of the models. We release
		two open versions of the model -- the foundation Jais model, and an
		instruction-tuned Jais-chat variant -- with the aim of promoting research on
		Arabic LLMs. Available at
		https://huggingface.co/inception-mbzuai/jais-13b-chat
	},
	source       = {arxiv}
}
@article{shafi2024critical,
	title        = {
		Critical Discourse Analysis of Islamic Ideological Expressions in
		Acknowledgement Sections of Theses Written by Scholars in English Language
		Teaching (ELT)
	},
	author       = {Sidra Shafi, Dr. Saira Maqbool, Uzma Safdar},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/d2d4cf8c40d8c13c4bc52701a08f7ea27bd0e218
	},
	abstract     = {
		The objective of current research is to analyze the expressions of Islamic
		ideology in the acknowledgement sections of theses written by researchers in
		the field of English Language Teaching (ELT) from Pakistan. These
		acknowledgements, a specific concept in academic writing, offers a particular
		frame to capture the religious and cultural aspects on scholarly discourse.
		30 theses were examined and data were gathered from electronic libraries of
		universities, online thesis databases, and institutional archives sections of
		the required theses. It provided enough material and reach data in this
		regard. Fairclough’s three-dimensional model of Critical Doscourse Anaysis
		(CDA) was applied, centering to Textual Analysis and analyzes concrete words,
		phrases and sentences that contain the ideology of Islam. The results reveal
		clear Islamic orientations in the features of the Arabian language used, with
		recurrent appeals to Allah, prayer and blessing calls, as well as direct
		references to both Quran and Hadiths. These acknowledgements are not only the
		writers own faith but it also reveal the inteewined cultural and religious
		values
	},
	source       = {semantic_scholar}
}
@misc{shashidhar2025yourbencheasycustomevaluation,
	title        = {YourBench: Easy Custom Evaluation Sets for Everyone},
	author       = {
		Sumuk Shashidhar and Clémentine Fourrier and Alina Lozovskia and Thomas Wolf
		and Gokhan Tur and Dilek Hakkani-Tür
	},
	year         = {2025},
	url          = {https://arxiv.org/abs/2504.01833},
	journal       = {2504.01833},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@article{shidiq2024the,
	title        = {
		The Effectiveness Of Discovery Learning For Improving Speaking Skills of
		Arabic Language Education Students Islamic University of Malang
	},
	author       = {
		Fauzie Muhammad Shidiq, Aprilia Ning Tyas Tri Tungga Dewi, Laily Fitriani,
		Abdul Aziz
	},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/776d6252c0d7d8c409cf7aa0768bec2826ccc04f
	},
	abstract     = {
		Purpose - This study aims to describe and determine the effectiveness of
		speaking skill learning outcomes with the use of discovery learning models
		for Arabic language education students at the Islamic University of Malang.
		The discovery learning model is an activity that involves all students’
		abilities to search, examine and investigate systematically, critically, and
		logically so that they can build their own knowledge, attitudes and skills.
		Design/methodology/approach - The research method used is pre-experiment
		design with one group pretest and post-test design. The data analysis used
		uses inferential statistics with the help of the SPSS 25 program. The data
		collection techniques used are observation, tests and documentation.
		Findings/results - The results showed the effectiveness of learning speaking
		skill with the discovery learning model. Then in the learning stages using
		the discovery learning model including the stages of providing stimulus,
		identification of the problem, data collection, data processing, proof and
		conclusion. The effectiveness value based on the calculation of SPSS analysis
		shows the one sample T-test Sig (2-tailed) value of 0.000 <0.05 or the
		calculated t value of 8.813> t table 1.7. Originality/value - This research
		has implications for improving speaking skills of Arabic language by
		discovery learning. Paper type – Research paper
	},
	source       = {semantic_scholar}
}
@article{shohoud2023quranic,
	title        = {
		Quranic Conversations: Developing a Semantic Search tool for the Quran using
		Arabic NLP Techniques
	},
	author       = {Yasser Shohoud, Maged Shoman, Sarah Abdelazim},
	year         = {2023},
	url          = {http://arxiv.org/abs/2311.05120v1},
	abstract     = {
		The Holy Book of Quran is believed to be the literal word of God (Allah) as
		revealed to the Prophet Muhammad (PBUH) over a period of approximately 23
		years. It is the book where God provides guidance on how to live a righteous
		and just life, emphasizing principles like honesty, compassion, charity and
		justice, as well as providing rules for personal conduct, family matters,
		business ethics and much more. However, due to constraints related to the
		language and the Quran organization, it is challenging for Muslims to get all
		relevant ayahs (verses) pertaining to a matter or inquiry of interest. Hence,
		we developed a Quran semantic search tool which finds the verses pertaining
		to the user inquiry or prompt. To achieve this, we trained several models on
		a large dataset of over 30 tafsirs, where typically each tafsir corresponds
		to one verse in the Quran and, using cosine similarity, obtained the tafsir
		tensor which is most similar to the prompt tensor of interest, which was then
		used to index for the corresponding ayah in the Quran. Using the SNxLM model,
		we were able to achieve a cosine similarity score as high as 0.97 which
		corresponds to the abdu tafsir for a verse relating to financial matters.
	},
	source       = {arxiv},
    journal      = {arxiv}
}
@article{sibaee2025from,
	title        = {
		From Guidelines to Practice: A New Paradigm for Arabic Language Model
		Evaluation
	},
	author       = {
		Serry Sibaee and Omer Nacar and A. Ammar and Yasser Al-Habashi and Abdulrahman S.
		Al-Batati and Wadii Boulila
	},
	year         = {2025},
	url          = {
		https://www.semanticscholar.org/paper/e5bdc7c06581bbc5871432f95a9036850c541dc1
	},
	abstract     = {
		This paper addresses critical gaps in Arabic language model evaluation by
		establishing comprehensive theoretical guidelines and introducing a novel
		evaluation framework. We first analyze existing Arabic evaluation datasets,
		identifying significant issues in linguistic accuracy, cultural alignment,
		and methodological rigor. To address these limitations in LLMs, we present
		the Arabic Depth Mini Dataset (ADMD), a carefully curated collection of 490
		challenging questions spanning ten major domains (42 sub-domains, see Figure
		1. Using ADMD, we evaluate five leading language models: GPT-4, Claude 3.5
		Sonnet, Gemini Flash 1.5, CommandR 100B, and Qwen-Max. Our results reveal
		significant variations in model performance across different domains, with
		particular challenges in areas requiring deep cultural understanding and
		specialized knowledge. Claude 3.5 Sonnet demonstrated the highest overall
		accuracy at 30\%, showing relative strength in mathematical theory in Arabic,
		Arabic language, and islamic domains. This work provides both theoretical
		foundations and practical insights for improving Arabic language model
		evaluation, emphasizing the importance of cultural competence alongside
		technical capabilities.
	},
	source       = {semantic_scholar},
    journal      = {arxiv}
}
@misc{silma_01_2024,
	title        = {Silma},
	author       = {Silma Team},
	year         = {2024},
	publisher    = {Silma},
	url          = {https://www.silma.ai}
}
@inproceedings{soliman2017aravec,
	title        = {AraVec: A set of Arabic Word Embedding Models for use in Arabic NLP},
	author       = {Soliman, Abu Bakr and Eissa, Kareem and El-Beltagy, Samhaa R},
	year         = {2017},
	booktitle    = {Procedia Computer Science},
	publisher    = {Elsevier},
	volume       = {117},
	pages        = {256--265}
}

@article{alan2024mufassirqas,
  title        = {A RAG-based Question Answering System Proposal for Understanding Islam: MufassirQAS LLM},
  author       = {Alan, Ahmet Yusuf and Karaarslan, Enis and Aydin, \"Omer},
  year         = {2024},
  journal      = {arXiv preprint},
  eprint       = {2401.15378},
  archivePrefix= {arXiv},
  primaryClass = {cs.CL},
  url          = {https://arxiv.org/abs/2401.15378}
}

@article{khalila2025quranicrag,
  title   = {Investigating Retrieval-Augmented Generation in Quranic Studies: A Study of 13 Open-Source Large Language Models},
  author  = {Khalila, Zahra and Nasution, Arbi Haza and Monika, Winda and Onan, Aytug and Murakami, Yohei and Radi, Yasir Bin Ismail and Osmani, Noor Mohammad},
  journal = {(IJACSA) International Journal of Advanced Computer Science and Applications},
  volume  = {16},
  number  = {2},
  year    = {2025},
  url     = {https://thesai.org/Downloads/Volume16No2/Paper_134-Investigating_Retrieval_Augmented_Generation_in_Quranic_Studies.pdf}
}

@inproceedings{al-smadi-2025-qu,
  author = "AL-Smadi, Mohammad",
  booktitle = "Proceedings of The Third Arabic Natural Language Processing Conference: Shared Tasks",
  month = nov,
  year = "2025",
  address = "Suzhou, China",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2025.arabicnlp-sharedtasks.123/",
  doi = "10.18653/v1/2025.arabicnlp-sharedtasks.123"
}
@inproceedings{al-adel-etal-2025-burhanai,
  title = "{B}urhan{AI} at {I}slamic{E}val 2025 Shared Task: Combating Hallucinations in {LLM}s for Islamic Content; Evaluation, Correction, and Retrieval-Based Solution",
  author = "Al Adel, Arij and Bakr Soliman, Abu and Sakher Sawan, Mohamed and Al-Najjar, Rahaf and Amin, Sameh",
  booktitle = "Proceedings of The Third Arabic Natural Language Processing Conference: Shared Tasks",
  month = nov,
  year = "2025",
  address = "Suzhou, China",
  publisher = "Association for Computational Linguistics",
  nourl = "https://aclanthology.org/2025.arabicnlp-sharedtasks.69/",
  doi = "10.18653/v1/2025.arabicnlp-sharedtasks.69",
  pages = "503--508"
}

@inproceedings{omayrah-etal-2025-humain,
  title = "{HUMAIN} at {I}slamic{E}val 2025 Shared Task 1: A Three-Stage {LLM}-Based Pipeline for Detecting and Correcting Hallucinations in {Q}uran and {H}adith",
  author = "Omayrah, Arwa and Alkhereyf, Sakhar and Abdelali, Ahmed and Al-Thubaity, Abdulmohsen and Kuriakose, Jeril and AbdulMajeed, Ibrahim",
  booktitle = "Proceedings of The Third Arabic Natural Language Processing Conference: Shared Tasks",
  month = nov,
  year = "2025",
  address = "Suzhou, China",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2025.arabicnlp-sharedtasks.70/",
  doi = "10.18653/v1/2025.arabicnlp-sharedtasks.70",
  pages = "509--514"
}


@article{bhatia2026agenticrag,
  title   = {From RAG to Agentic RAG for Faithful Islamic Question Answering},
  author  = {Bhatia, Gagan and Mubarak, Hamdy and Jarrar, Mustafa and Mikros, George and Zaraket, Fadi and Alhirthani, Mahmoud and Al-Khatib, Mutaz and Cochrane, Logan and Darwish, Kareem and Yahiaoui, Rashid and Alam, Firoj},
  journal = {arXiv preprint arXiv:2601.07528},
  year    = {2026},
  doi     = {10.48550/arXiv.2601.07528}
}

@article{subari2024exploring,
	title        = {
		EXPLORING THE EFFECTIVENESS OF TEACHING AIDS OF COMMUNICATIVE ARABIC LANGUAGE
		AT THE SULTAN SHARIF ALI ISLAMIC UNIVERSITY: FACULTY OF SHARIAH AS A MODEL
	},
	author       = {
		Achmad Yani Bin Imam Subari, S. Ahmad, R. Abdullah, H. Jaili, R. Abdullah, N.
		Rosmin
	},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/785a0268805ca5a6717629be9d749a1832759ee1
	},
	abstract     = {
		The objective of this research is to assess the effectiveness of teaching
		aids in teaching Arabic and communicative skills at the Faculty of Sharia at
		the Sultan Sharif Ali Islamic University in Brunei Darussalam. The
		researchers distributed the questionnaire to the first-year students of the
		Faculty of Sharia at the Sultan Al-Sharif Ali Islamic University who studied
		the communicative Arab material in 2024; 22 of them (the number of all
		first-year students of the Faculty of Sharia at the Islamic University who
		studied the communicative Arab material in 2024 is 35, and this sample is 63%
		of the total number of them). This research found that the positive aspects
		of teaching methods of the Arabic-communicative language at the Sultan Sharif
		Ali Islamic University are reflected in its diverse availability (78.2%), its
		availability (77.3%), its availability (72.7%), its availability to teaching
		the Arabic-communicative language at the Sultan Sharif Ali Islamic
		University, its availability (77.3%), its availability (77.3%), its
		availability to teach the Arabic-communicative language at the Sultan Sharif
		Ali Islamic University, its availability (72.7%), its availability to teach
		the Arabic-communicative language at the Sultan Sharif Ali Islamic
		University, and its use (17%) of the Arabic-language Projector, 19% of the
		Islamic University of the Sultan of Al-Salafi Sultan The recorder is
		available for recording student voices when they are trained in the oral
		dialogue to teach the communicative Arabic at Sultan Sharif Ali Islamic
		University (71.8%). The downside is that the various educational means for
		teaching communicative Arabic at Sultan Sharif Ali Islamic University (21.8%)
		are not available, that there is no audio-visual educational means (22.7%),
		that there is no audio-visual educational means (22.7%), that there is no
		electronic educational means (27.3%), that the projector (20.9%) is not
		available, and that there is no use of the recorder to record students'
		voices on the oral dialog (28%).  Article visualizations:
	},
	source       = {semantic_scholar}
}
@misc{supernaturalinstructions,
	title        = {
		Super-NaturalInstructions: Generalization via Declarative Instructions on
		1600+ NLP Tasks
	},
	author       = {
		Yizhong Wang and Swaroop Mishra and Pegah Alipoormolabashi and Yeganeh Kordi
		and Amirreza Mirzaei and Anjana Arunkumar and Arjun Ashok and Arut Selvan
		Dhanasekaran and Atharva Naik and David Stap and Eshaan Pathak and Giannis
		Karamanolakis and Haizhi Gary Lai and Ishan Purohit and Ishani Mondal and
		Jacob Anderson and Kirby Kuznia and Krima Doshi and Maitreya Patel and Kuntal
		Kumar Pal and Mehrad Moradshahi and Mihir Parmar and Mirali Purohit and
		Neeraj Varshney and Phani Rohitha Kaza and Pulkit Verma and Ravsehaj Singh
		Puri and Rushang Karia and Shailaja Keyur Sampat and Savan Doshi and
		Siddhartha Mishra and Sujan Reddy and Sumanta Patro and Tanay Dixit and
		Xudong Shen and Chitta Baral and Yejin Choi and Noah A. Smith and Hannaneh
		Hajishirzi and Daniel Khashabi
	},
	year         = {2022},
	url          = {https://arxiv.org/abs/2204.07705},
	journal       = {2204.07705},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@article{takdir2022development,
	title        = {
		Development of Arabic Language Learning Model Based on Bi'ah Lugawiyyah to
		Improve Student's Speaking Skills in Islamic Religious College
	},
	author       = {Takdir, Arifin Ahmad, Hamsu Abdul Gani},
	year         = {2022},
	url          = {
		https://www.semanticscholar.org/paper/63c3a12ca8b91653fa213a14789da05a90edf9f4
	},
	abstract     = {
		Learning Arabic in universities has not yet utilized the language environment
		as a learning resource. Improve speaking skills in Arabic cannot be separated
		from the language environment. This study aims to produce a valid, practical,
		and effective Arabic learning model to improve students' Arabic speaking
		skills at Islamic religious colleges. This research is research and
		development by adopting the ADDIE design by Branch, which consists of five
		phases: analysis, design, development, implementation, and evaluations. The
		research subjects involved 23 university students for the practicality and
		effectiveness test and two experts for the validity test. Data collection
		techniques were carried out using instruments such as questionnaires,
		interviews, observation sheets, and tests of Arabic speaking skills.
		Qualitative and quantitative methods then analyzed the data. The data
		analysis showed that the bi'ah lugawiyyah-based Arabic learning model was
		tested to be valid, practical and effective in improving students' Arabic
		speaking skills at Islamic universities.
	},
	source       = {semantic_scholar}
}
@misc{team2025gemma,
	title        = {Gemma 3 Technical Report},
	author       = {
		Gemma Team and Aishwarya Kamath and Johan Ferret and Shreya Pathak and Nino
		Vieillard and Ramona Merhej and Sarah Perrin and Tatiana Matejovicova and
		Alexandre Ramé and Morgane Rivière and Louis Rouillard and Thomas Mesnard and
		Geoffrey Cideron and Jean-bastien Grill and Sabela Ramos and Edouard Yvinec
		and Michelle Casbon and Etienne Pot and Ivo Penchev and Gaël Liu and
		Francesco Visin and Kathleen Kenealy and Lucas Beyer and Xiaohai Zhai and
		Anton Tsitsulin and Robert Busa-Fekete and Alex Feng and Noveen Sachdeva and
		Benjamin Coleman and Yi Gao and Basil Mustafa and Iain Barr and Emilio
		Parisotto and David Tian and Matan Eyal and Colin Cherry and Jan-Thorsten
		Peter and Danila Sinopalnikov and Surya Bhupatiraju and Rishabh Agarwal and
		Mehran Kazemi and Dan Malkin and Ravin Kumar and David Vilar and Idan
		Brusilovsky and Jiaming Luo and Andreas Steiner and Abe Friesen and Abhanshu
		Sharma and Abheesht Sharma and Adi Mayrav Gilady and Adrian Goedeckemeyer and
		Alaa Saade and Alex Feng and Alexander Kolesnikov and Alexei Bendebury and
		Alvin Abdagic and Amit Vadi and András György and André Susano Pinto and Anil
		Das and Ankur Bapna and Antoine Miech and Antoine Yang and Antonia Paterson
		and Ashish Shenoy and Ayan Chakrabarti and Bilal Piot and Bo Wu and Bobak
		Shahriari and Bryce Petrini and Charlie Chen and Charline Le Lan and
		Christopher A. Choquette-Choo and CJ Carey and Cormac Brick and Daniel
		Deutsch and Danielle Eisenbud and Dee Cattle and Derek Cheng and Dimitris
		Paparas and Divyashree Shivakumar Sreepathihalli and Doug Reid and Dustin
		Tran and Dustin Zelle and Eric Noland and Erwin Huizenga and Eugene
		Kharitonov and Frederick Liu and Gagik Amirkhanyan and Glenn Cameron and Hadi
		Hashemi and Hanna Klimczak-Plucińska and Harman Singh and Harsh Mehta and
		Harshal Tushar Lehri and Hussein Hazimeh and Ian Ballantyne and Idan Szpektor
		and Ivan Nardini and Jean Pouget-Abadie and Jetha Chan and Joe Stanton and
		John Wieting and Jonathan Lai and Jordi Orbay and Joseph Fernandez and Josh
		Newlan and Ju-yeong Ji and Jyotinder Singh and Kat Black and Kathy Yu and
		Kevin Hui and Kiran Vodrahalli and Klaus Greff and Linhai Qiu and Marcella
		Valentine and Marina Coelho and Marvin Ritter and Matt Hoffman and Matthew
		Watson and Mayank Chaturvedi and Michael Moynihan and Min Ma and Nabila Babar
		and Natasha Noy and Nathan Byrd and Nick Roy and Nikola Momchev and Nilay
		Chauhan and Noveen Sachdeva and Oskar Bunyan and Pankil Botarda and Paul
		Caron and Paul Kishan Rubenstein and Phil Culliton and Philipp Schmid and
		Pier Giuseppe Sessa and Pingmei Xu and Piotr Stanczyk and Pouya Tafti and
		Rakesh Shivanna and Renjie Wu and Renke Pan and Reza Rokni and Rob Willoughby
		and Rohith Vallu and Ryan Mullins and Sammy Jerome and Sara Smoot and Sertan
		Girgin and Shariq Iqbal and Shashir Reddy and Shruti Sheth and Siim Põder and
		Sijal Bhatnagar and Sindhu Raghuram Panyam and Sivan Eiger and Susan Zhang
		and Tianqi Liu and Trevor Yacovone and Tyler Liechty and Uday Kalra and Utku
		Evci and Vedant Misra and Vincent Roseberry and Vlad Feinberg and Vlad
		Kolesnikov and Woohyun Han and Woosuk Kwon and Xi Chen and Yinlam Chow and
		Yuvein Zhu and Zichuan Wei and Zoltan Egyed and Victor Cotruta and Minh Giang
		and Phoebe Kirk and Anand Rao and Kat Black and Nabila Babar and Jessica Lo
		and Erica Moreira and Luiz Gustavo Martins and Omar Sanseviero and Lucas
		Gonzalez and Zach Gleicher and Tris Warkentin and Vahab Mirrokni and Evan
		Senter and Eli Collins and Joelle Barral and Zoubin Ghahramani and Raia
		Hadsell and Yossi Matias and D. Sculley and Slav Petrov and Noah Fiedel and
		Noam Shazeer and Oriol Vinyals and Jeff Dean and Demis Hassabis and Koray
		Kavukcuoglu and Clement Farabet and Elena Buchatskaya and Jean-Baptiste
		Alayrac and Rohan Anil and Dmitry and Lepikhin and Sebastian Borgeaud and
		Olivier Bachem and Armand Joulin and Alek Andreev and Cassidy Hardin and
		Robert Dadashi and Léonard Hussenot
	},
	year         = {2025},
	url          = {https://arxiv.org/abs/2503.19786},
	journal       = {2503.19786},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@article{tohir2024utilizing,
	title        = {
		UTILIZING RETRIEVAL-AUGMENTED GENERATION IN LARGE LANGUAGE MODELS TO ENHANCE
		INDONESIAN LANGUAGE NLP
	},
	author       = {Herdian Tohir, Nita Merlina, Muhammad Haris},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/1ffbf3ddf77375fccb5bc9e1552df7509d0cb2f8
	},
	abstract     = {
		The improvement of Large Language Models (LLM) such as ChatGPT through
		Retrieval-Augmented Generation (RAG) techniques has urgency in the
		development of natural language translation technology and dialogue systems.
		LLMs often experience obstacles in addressing special requests that require
		information outside the training data. This study aims to discuss the use of
		Retrieval-Augmented Generation (RAG) on large-scale language models to
		improve the performance of Natural Language Processing (NLP) in Indonesian,
		which has so far been poorly supported by high-quality data and to overcome
		the limitations of traditional language models in understanding the context
		of Indonesian better. The method used is a combination of retrieval
		capabilities (external information search) with generation (text generation),
		where the model utilizes broader and more structured basic data through the
		retrieval process to produce more accurate and relevant text. The data used
		includes the Indonesian corpus of the 30 Juz Quran translation into
		Indonesian. The results of the trial show that the RAG approach significantly
		improves the performance of the model in various NLP tasks, including token
		usage optimization, text classification, and context understanding, by
		increasing the accuracy and relevance of the results
	},
	source       = {semantic_scholar}
}
@misc{truthfulqa,
	title        = {TruthfulQA: Measuring How Models Mimic Human Falsehoods},
	author       = {Stephanie Lin and Jacob Hilton and Owain Evans},
	year         = {2022},
	url          = {https://arxiv.org/abs/2109.07958},
	journal       = {2109.07958},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{tydiqa,
	title        = {
		TyDi QA: A Benchmark for Information-Seeking Question Answering in
		Typologically Diverse Languages
	},
	author       = {
		Jonathan H. Clark and Eunsol Choi and Michael Collins and Dan Garrette and
		Tom Kwiatkowski and Vitaly Nikolaev and Jennimaria Palomaki
	},
	year         = {2020},
	url          = {https://arxiv.org/abs/2003.05002},
	journal       = {2003.05002},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@inproceedings{uddin2025rfpg,
	title        = {
		{RFPG}: Question-Answering from Low-Resource Language (Arabic) Texts using
		Factually Aware {RAG}
	},
	author       = {Alshammary, Mitha and Uddin, Md Nahiyan and Khan, Latifur},
	year         = {2024},
	booktitle    = {IEEE International Conference on Collaboration and Internet Computing (CIC)},
	organization = {IEEE}
}
@article{uluslu2023turkish,
	title        = {Turkish Native Language Identification V2},
	author       = {Ahmet Yavuz Uluslu, Gerold Schneider},
	year         = {2023},
	url          = {http://arxiv.org/abs/2307.14850v6},
	abstract     = {
		This paper presents the first application of Native Language Identification
		(NLI) for the Turkish language. NLI is the task of automatically identifying
		an individual's native language (L1) based on their writing or speech in a
		non-native language (L2). While most NLI research has focused on L2 English,
		our study extends this scope to L2 Turkish by analyzing a corpus of texts
		written by native speakers of Albanian, Arabic and Persian. We leverage a
		cleaned version of the Turkish Learner Corpus and demonstrate the
		effectiveness of syntactic features, comparing a structural Part-of-Speech
		n-gram model to a hybrid model that retains function words. Our models
		achieve promising results, and we analyze the most predictive features to
		reveal L1-specific transfer effects. We make our data and code publicly
		available for further study.
	},
	source       = {arxiv}
}
@article{unknown2023development,
	title        = {
		Development of interactive PPT media for learning the Arabic language in the
		seventh chapter of Al-Thanawiyya Islamic Government School 6th of the year of
		the school year 2022/ 2023
	},
	author       = {},
	year         = {2023},
	url          = {
		https://www.semanticscholar.org/paper/7ef72e1e21ffd6af16e14bda5baa4fe1f39caf43
	},
	abstract     = {
		This development research aims to produce an interactive PowerPoint learning
		media product for learning Arabic in class VII MTsN 6 Boyolali, especially on
		attaaruf material. This development research describes the stages of
		developing learning media in the form of interactive multimedia powerpoint,
		describes the responses of teachers and students to the use of learning media
		in the form of interactive multimedia powerpoint.This study uses the method
		(R & D) with a 6-step development model 1). Initial data collection analysis,
		2). Product development, 3). Expert validation, 4) product revision, 5)
		product trial, 6) final data analysis. The population in this study were
		students of class VII MTsN 6 Boyolali. Sampling using random sampling
		technique. With this technique, 40 students of class VII were taken from each
		class A, B, C, D as test subjects. The data collection technique uses a
		questionnaire in the form of a questionnaire which will be filled out by
		teachers and students after using the learning media, before being tested,
		the learning media goes through the stages of media validation and material
		validation by media experts and material experts. Data analysis techniques
		use descriptive qualitative, by transforming qualitative data into
		quantitative data. The results of this development research consist of two
		aspects, namely describing the stages of developing learning media, and
		describing user responses. In the aspect of the media development stage, the
		researcher chose PowerPoint software which was modified into interactive
		media using the Hyperlink model, developed by looking at aspects of potential
		and problem analysis and assessed by media experts and material experts, and
		tested using pre-test and post-test. Assessment from media experts got a
		percentage of 63% with a decent category, and material experts got a
		percentage of 89.0% with a feasible category, and at the pretest and posttest
		trial stages the average score (Mean) was obtained during the pretest, namely
		59.50 and for the posttest get an average value of 83.00. for the median, the
		pretest data has a value of 60, while for the posttest it has a result of 80.
		For the value that often appears (mode), we can see from the table above that
		the pretest is 60 and the value that often appears during the posttest is 80.
		It can be concluded from the above explanation that students experienced a
		significant increase in average from the previous treatment having an average
		value of 59.50 which later became 83.00. Therefore, it can be concluded that
		there is an influence on learning Arabic Interactive Powerpoint Media class
		VII MTsN 6 Boyolali. on aspects of user responses assessed by teachers and
		students. The assessment obtained from the teacher gets a percentage of 83.5%
		and the assessment obtained from students gets a percentage of 65%.
	},
	source       = {semantic_scholar}
}
@article{unknown2025murajaah,
	title        = {
		Murajaah as a Key Strategy in Quranic Retention: Insights from a Mini Review
	},
	author       = {},
	year         = {2025},
	url          = {
		https://www.semanticscholar.org/paper/143410a2bf178539096d2eaadaa2e78e90cd98b1
	},
	abstract     = {
		Murajaah, or the systematic repetition of the Quran's memorized verses, is
		the backbone of Quranic studies, providing memorization, oral fluency, and
		spiritual connection through memorization strategies. This mini review
		addresses the state of current murajaah in the retention of the Quran,
		covering three essential aspects: the technological element of integration,
		the educational approach, and the implementation. Philosophical frameworks
		and technological aids such as AI applications, speech recognition, and
		Quranic natural language processing (NLP) have found increased use to
		facilitate murajaah, especially among the students who are pressed for time
		or do not have reasonable access to teachers. Nonetheless, although these
		instruments are convenient and accessible, they usually do not have the same
		accuracy when it comes to citation, cultural accommodation, or empirical
		verification when applied to learning. Such educational techniques as
		performance monitoring, peer-guided revision, and Islamic religious education
		principles can be taken as the basic principles of regulating murajaah
		activities. These methodologies boost the learner's remembering and interest
		when coupled with the correct methods like Qiraat Murajaah and Hifz
		exercises. Though the existing ones are promising, many strategies and
		approaches are underutilized within personalized or technology-augmented
		environments. This review illustrates the present gaps in the
		literature/practice, especially as to the prospects of modern models of
		education being incorporated in the traditional murajaah systems with the
		digital medium. It hinders a greater focus on context-based research,
		user-based design, and empirical evaluation to ensure that murajaah is
		feasible and applicable to modern students. According to the findings, the
		critical issue is integrating traditional knowledge with modernity to
		preserve the integrity of Quranic memorizing within the changing educational
		environments.
	},
	source       = {semantic_scholar}
}
@article{wati2024integrating,
	title        = {
		Integrating English Language Materials and Islamic Values: Research and
		Development in Islamic Higher Education
	},
	author       = {Ning Setio Wati, Kuryani Kuryani},
	year         = {2024},
	url          = {
		https://www.semanticscholar.org/paper/d3a44473592281d5de128764234bab776d8aa6cb
	},
	abstract     = {
		Developing English material is an effort to develop and validate English
		material based on students' characteristics and students’ needs. Students of
		Islamic universities have different characters and needs from general
		universities. Therefore, this study aims at describing the process of
		developing English language material for Islamic learners in Islamic higher
		education based on students’ needs. The method of this research was Borg and
		Gall's research and development model. In this study, the researchers
		employed the procedures in four steps only such as research and collecting
		the data, planning, and developing the product. The participants of the study
		were the second students semester of the Islamic education study program
		(PAI) of Tarbiyah Faculty of a private Islamic university in Indonesia. The
		number of participants involved in this model was 30 participants. The
		researchers collected the data by using questionnaires, and interviews. The
		product of this study was evaluated by two experts between English language
		teaching and Islamic materials. The data was analyzed in qualitative and
		quantitative analysis. The results of this study showed that the developing
		English materials based on the integration of English language materials and
		Islamic values for the students of Islamic higher education are developed by
		the researchers in appropriate quality.
	},
	source       = {semantic_scholar}
}
@inproceedings{whisper,
	title        = {Robust speech recognition via large-scale weak supervision},
	author       = {
		Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey,
		Christine and Sutskever, Ilya
	},
	year         = {2023},
	booktitle    = {Proceedings of the 40th International Conference on Machine Learning},
	location     = {Honolulu, Hawaii, USA},
	publisher    = {JMLR.org},
	series       = {ICML'23},
	abstract     = {
		We study the capabilities of speech processing systems trained simply to
		predict large amounts of transcripts of audio on the internet. When scaled to
		680,000 hours of multilingual and multitask supervision, the resulting models
		generalize well to standard benchmarks and are often competitive with prior
		fully supervised results without the need for any dataset specific
		fine-tuning. When compared to humans, the models approach their accuracy and
		robustness. We are releasing models and inference code to serve as a
		foundation for further work on robust speech processing.
	},
	articleno    = {1182},
	numpages     = {27}
}
@misc{xp3,
	title        = {Crosslingual Generalization through Multitask Finetuning},
	author       = {
		Niklas Muennighoff and Thomas Wang and Lintang Sutawika and Adam Roberts and
		Stella Biderman and Teven Le Scao and M Saiful Bari and Sheng Shen and
		Zheng-Xin Yong and Hailey Schoelkopf and Xiangru Tang and Dragomir Radev and
		Alham Fikri Aji and Khalid Almubarak and Samuel Albanie and Zaid Alyafeai and
		Albert Webson and Edward Raff and Colin Raffel
	},
	year         = {2023},
	url          = {https://arxiv.org/abs/2211.01786},
	journal       = {2211.01786},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{yang2025qwen3,
	title        = {Qwen3 Technical Report},
	author       = {
		An Yang and Anfeng Li and Baosong Yang and Beichen Zhang and Binyuan Hui and
		Bo Zheng and Bowen Yu and Chang Gao and Chengen Huang and Chenxu Lv and
		Chujie Zheng and Dayiheng Liu and Fan Zhou and Fei Huang and Feng Hu and Hao
		Ge and Haoran Wei and Huan Lin and Jialong Tang and Jian Yang and Jianhong Tu
		and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jing Zhou and Jingren
		Zhou and Junyang Lin and Kai Dang and Keqin Bao and Kexin Yang and Le Yu and
		Lianghao Deng and Mei Li and Mingfeng Xue and Mingze Li and Pei Zhang and
		Peng Wang and Qin Zhu and Rui Men and Ruize Gao and Shixuan Liu and Shuang
		Luo and Tianhao Li and Tianyi Tang and Wenbiao Yin and Xingzhang Ren and
		Xinyu Wang and Xinyu Zhang and Xuancheng Ren and Yang Fan and Yang Su and
		Yichang Zhang and Yinger Zhang and Yu Wan and Yuqiong Liu and Zekun Wang and
		Zeyu Cui and Zhenru Zhang and Zhipeng Zhou and Zihan Qiu
	},
	year         = {2025},
	url          = {https://arxiv.org/abs/2505.09388},
	journal       = {2505.09388},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{yehia2025,
	title        = {Yehia 7B Preview},
	author       = {Navid-AI},
	year         = {2025},
	howpublished = {\url{https://huggingface.co/Navid-AI/Yehia-7B-preview}}
}
@article{zaimah2023acceptability,
	title        = {
		Acceptability and Effectiveness Analysis of Large Language Model-Based
		Artificial Intelligence Chatbot Among Arabic Learners
	},
	author       = {
		Nely Rahmawati Zaimah, Eko Budi Hartanto, F. Zahro, ©. 2. Nely, Rahmawati
		Zaimah, Budi Hartanto Budi Hartanto
	},
	year         = {2023},
	url          = {
		https://www.semanticscholar.org/paper/071404ea62a7e32d93075a570579e438596a970b
	},
	abstract     = {
		This research stems from the broad use of AI based on Large Language Models
		(LLMs), which many academics find relevant and effective in higher education
		Arabic language learning. The goal is to confirm these views.This research is
		a mixed reseach that employs a both of qualitative and quantitative
		methodologies. The qualitative segment involves observations and literature
		reviews. Observations involved reviewing how participants used chatbots and
		carefully checking the accuracy and consistency of platform responses. The
		quantitative facet utilizes a paired experimental design, encompassing both
		classical and Bayesian Paired Sample t-Tests analysis. The research
		encompasses 45 individuals with a proficient understanding of Modern Standard
		Arabic and no hindrances in comprehending the material. These individuals are
		enrolled as students at Islamic College (STAI) Al-Anwar Rembang, Indonesia.
		The results show increased motivation and ease of use with the chatbot in
		Arabic language learning. However, concerns about the consistency of chatbot
		content have arisen, affecting participants' confidence in response accuracy
		of AI. This prompts an evaluation of effectiveness through classical and
		Bayesian tests, which fail to demonstrate statistically significant
		variances, even in the adaptive Bayesian probability analysis. These outcomes
		deviate from previous research on relevance and effectiveness and corroborate
		preceding studies on academic apprehensions and accuracy enhancements. The
		researchers advocate for further investigations, especially concerning the
		accuracy analysis of AI chatbots in Arabic pedagogical contexts.
	},
	source       = {semantic_scholar}
}

@article{mushtaq2025can,

Author        = {Abdullah Mushtaq and Rafay Naeem and Ezieddin Elmahjub and Ibrahim Ghaznavi and Shawqi Al-Maliki and Mohamed Abdallah and Ala Al-Fuqaha and Junaid Qadir},

Title         = {Can LLMs Write Faithfully? An Agent-Based Evaluation of LLM-generated Islamic Content},

Journal       = {2510.24438v1},

ArchivePrefix = {arXiv},

PrimaryClass  = {cs.CL},

Abstract      = {Large language models are increasingly used for Islamic guidance, but risk misquoting texts, misapplying jurisprudence, or producing culturally inconsistent responses. We pilot an evaluation of GPT-4o, Ansari AI, and Fanar on prompts from authentic Islamic blogs. Our dual-agent framework uses a quantitative agent for citation verification and six-dimensional scoring (e.g., Structure, Islamic Consistency, Citations) and a qualitative agent for five-dimensional side-by-side comparison (e.g., Tone, Depth, Originality). GPT-4o scored highest in Islamic Accuracy (3.93) and Citation (3.38), Ansari AI followed (3.68, 3.32), and Fanar lagged (2.76, 1.82). Despite relatively strong performance, models still fall short in reliably producing accurate Islamic content and citations -- a paramount requirement in faith-sensitive writing. GPT-4o had the highest mean quantitative score (3.90/5), while Ansari AI led qualitative pairwise wins (116/200). Fanar, though trailing, introduces innovations for Islamic and Arabic contexts. This study underscores the need for community-driven benchmarks centering Muslim perspectives, offering an early step toward more reliable AI in Islamic knowledge and other high-stakes domains such as medicine, law, and journalism.},

Year          = {2025},

Month         = {Oct},

Url           = {http://arxiv.org/abs/2510.24438v1},

File          = {2510.24438v1.pdf}

}

@misc{bragg2025astabenchrigorousbenchmarkingai,
      title={AstaBench: Rigorous Benchmarking of AI Agents with a Scientific Research Suite}, 
      author={Jonathan Bragg and Mike D'Arcy and Nishant Balepur and Dan Bareket and Bhavana Dalvi and Sergey Feldman and Dany Haddad and Jena D. Hwang and Peter Jansen and Varsha Kishore and Bodhisattwa Prasad Majumder and Aakanksha Naik and Sigal Rahamimov and Kyle Richardson and Amanpreet Singh and Harshit Surana and Aryeh Tiktinsky and Rosni Vasu and Guy Wiener and Chloe Anastasiades and Stefan Candra and Jason Dunkelberger and Dan Emery and Rob Evans and Malachi Hamada and Regan Huff and Rodney Kinney and Matt Latzke and Jaron Lochner and Ruben Lozano-Aguilera and Cecile Nguyen and Smita Rao and Amber Tanaka and Brooke Vlahos and Peter Clark and Doug Downey and Yoav Goldberg and Ashish Sabharwal and Daniel S. Weld},
      year={2025},
      journal={2510.21652},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2510.21652}, 
}
@misc{comanici2025gemini25pushingfrontier,
      title={Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities}, 
      author={Gheorghe Comanici and Eric Bieber and Mike Schaekermann and Ice Pasupat and Noveen Sachdeva and Inderjit Dhillon and Marcel Blistein and Ori Ram and Dan Zhang and Evan Rosen and Luke Marris and Sam Petulla and Colin Gaffney and Asaf Aharoni and Nathan Lintz and Tiago Cardal Pais and Henrik Jacobsson and Idan Szpektor and Nan-Jiang Jiang and Krishna Haridasan and Ahmed Omran and Nikunj Saunshi and Dara Bahri and Gaurav Mishra and Eric Chu and Toby Boyd and Brad Hekman and Aaron Parisi and Chaoyi Zhang and Kornraphop Kawintiranon and Tania Bedrax-Weiss and Oliver Wang and Ya Xu and Ollie Purkiss and Uri Mendlovic and Ilaï Deutel and Nam Nguyen and Adam Langley and Flip Korn and Lucia Rossazza and Alexandre Ramé and Sagar Waghmare and Helen Miller and Nathan Byrd and Ashrith Sheshan and Raia Hadsell and Sangnie Bhardwaj and Pawel Janus and Tero Rissa and Dan Horgan and Alvin Abdagic and Lior Belenki and James Allingham and Anima Singh and Theo Guidroz and Srivatsan Srinivasan and Herman Schmit and Kristen Chiafullo and Andre Elisseeff and Nilpa Jha and Prateek Kolhar and Leonard Berrada and Frank Ding and Xiance Si and Shrestha Basu Mallick and Franz Och and Sofia Erell and Eric Ni and Tejasi Latkar and Sherry Yang and Petar Sirkovic and Ziqiang Feng and Robert Leland and Rachel Hornung and Gang Wu and Charles Blundell and Hamidreza Alvari and Po-Sen Huang and Cathy Yip and Sanja Deur and Li Liu and Gabriela Surita and Pablo Duque and Dima Damen and Johnson Jia and Arthur Guez and Markus Mircea and Animesh Sinha and Alberto Magni and Paweł Stradomski and Tal Marian and Vlado Galić and Wenhu Chen and Hisham Husain and Achintya Singhal and Dominik Grewe and François-Xavier Aubet and Shuang Song and Lorenzo Blanco and Leland Rechis and Lewis Ho and Rich Munoz and Kelvin Zheng and Jessica Hamrick and Kevin Mather and Hagai Taitelbaum and Eliza Rutherford and Yun Lei and Kuangyuan Chen and Anand Shukla and Erica Moreira and Eric Doi and Berivan Isik and Nir Shabat and Dominika Rogozińska and Kashyap Kolipaka and Jason Chang and Eugen Vušak and Srinivasan Venkatachary and Shadi Noghabi and Tarun Bharti and Younghoon Jun and Aleksandr Zaks and Simon Green and Jeshwanth Challagundla and William Wong and Muqthar Mohammad and Dean Hirsch and Yong Cheng and Iftekhar Naim and Lev Proleev and Damien Vincent and Aayush Singh and Maxim Krikun and Dilip Krishnan and Zoubin Ghahramani and Aviel Atias and Rajeev Aggarwal and Christo Kirov and Dimitrios Vytiniotis and Christy Koh and Alexandra Chronopoulou and Pawan Dogra and Vlad-Doru Ion and Gladys Tyen and Jason Lee and Felix Weissenberger and Trevor Strohman and Ashwin Balakrishna and Jack Rae and Marko Velic and Raoul de Liedekerke and Oded Elyada and Wentao Yuan and Canoee Liu and Lior Shani and Sergey Kishchenko and Bea Alessio and Yandong Li and Richard Song and Sam Kwei and Orion Jankowski and Aneesh Pappu and Youhei Namiki and Yenai Ma and Nilesh Tripuraneni and Colin Cherry and Marissa Ikonomidis and Yu-Cheng Ling and Colin Ji and Beka Westberg and Auriel Wright and Da Yu and David Parkinson and Swaroop Ramaswamy and Jerome Connor and Soheil Hassas Yeganeh and Snchit Grover and George Kenwright and Lubo Litchev and Chris Apps and Alex Tomala and Felix Halim and Alex Castro-Ros and Zefei Li and Anudhyan Boral and Pauline Sho and Michal Yarom and Eric Malmi and David Klinghoffer and Rebecca Lin and Alan Ansell and Pradeep Kumar S and Shubin Zhao and Siqi Zuo and Adam Santoro and Heng-Tze Cheng and Solomon Demmessie and Yuchi Liu and Nicole Brichtova and Allie Culp and Nathaniel Braun and Dan Graur and Will Ng and Nikhil Mehta and Aaron Phillips and Patrik Sundberg and Varun Godbole and Fangyu Liu and Yash Katariya and David Rim and Mojtaba Seyedhosseini and Sean Ammirati and Jonas Valfridsson and Mahan Malihi and Timothy Knight and Andeep Toor and Thomas Lampe and Abe Ittycheriah and Lewis Chiang and Chak Yeung and Alexandre Fréchette and Jinmeng Rao and Huisheng Wang and Himanshu Srivastava and Richard Zhang and Rocky Rhodes and Ariel Brand and Dean Weesner and Ilya Figotin and Felix Gimeno and Rachana Fellinger and Pierre Marcenac and José Leal and Eyal Marcus and Victor Cotruta and Rodrigo Cabrera and Sheryl Luo and Dan Garrette and Vera Axelrod and Sorin Baltateanu and David Barker and Dongkai Chen and Horia Toma and Ben Ingram and Jason Riesa and Chinmay Kulkarni and Yujing Zhang and Hongbin Liu and Chao Wang and Martin Polacek and Will Wu and Kai Hui and Adrian N Reyes and Yi Su and Megan Barnes and Ishaan Malhi and Anfal Siddiqui and Qixuan Feng and Mihai Damaschin and Daniele Pighin and Andreas Steiner and Samuel Yang and Ramya Sree Boppana and Simeon Ivanov and Arun Kandoor and Aditya Shah and Asier Mujika and Da Huang and Christopher A. Choquette-Choo and Mohak Patel and Tianhe Yu and Toni Creswell and Jerry and Liu and Catarina Barros and Yasaman Razeghi and Aurko Roy and Phil Culliton and Binbin Xiong and Jiaqi Pan and Thomas Strohmann and Tolly Powell and Babi Seal and Doug DeCarlo and Pranav Shyam and Kaan Katircioglu and Xuezhi Wang and Cassidy Hardin and Immanuel Odisho and Josef Broder and Oscar Chang and Arun Nair and Artem Shtefan and Maura O'Brien and Manu Agarwal and Sahitya Potluri and Siddharth Goyal and Amit Jhindal and Saksham Thakur and Yury Stuken and James Lyon and Kristina Toutanova and Fangxiaoyu Feng and Austin Wu and Ben Horn and Alek Wang and Alex Cullum and Gabe Taubman and Disha Shrivastava and Chongyang Shi and Hamish Tomlinson and Roma Patel and Tao Tu and Ada Maksutaj Oflazer and Francesco Pongetti and Mingyao Yang and Adrien Ali Taïga and Vincent Perot and Nuo Wang Pierse and Feng Han and Yoel Drori and Iñaki Iturrate and Ayan Chakrabarti and Legg Yeung and Dave Dopson and Yi-ting Chen and Apoorv Kulshreshtha and Tongfei Guo and Philip Pham and Tal Schuster and Junquan Chen and Alex Polozov and Jinwei Xing and Huanjie Zhou and Praneeth Kacham and Doron Kukliansky and Antoine Miech and Sergey Yaroshenko and Ed Chi and Sholto Douglas and Hongliang Fei and Mathieu Blondel and Preethi Myla and Lior Madmoni and Xing Wu and Daniel Keysers and Kristian Kjems and Isabela Albuquerque and Lijun Yu and Joel D'sa and Michelle Plantan and Vlad Ionescu and Jaume Sanchez Elias and Abhirut Gupta and Manish Reddy Vuyyuru and Fred Alcober and Tong Zhou and Kaiyang Ji and Florian Hartmann and Subha Puttagunta and Hugo Song and Ehsan Amid and Anca Stefanoiu and Andrew Lee and Paul Pucciarelli and Emma Wang and Amit Raul and Slav Petrov and Isaac Tian and Valentin Anklin and Nana Nti and Victor Gomes and Max Schumacher and Grace Vesom and Alex Panagopoulos and Konstantinos Bousmalis and Daniel Andor and Josh Jacob and Yuan Zhang and Bill Rosgen and Matija Kecman and Matthew Tung and Alexandra Belias and Noah Goodman and Paul Covington and Brian Wieder and Nikita Saxena and Elnaz Davoodi and Muhuan Huang and Sharath Maddineni and Vincent Roulet and Folawiyo Campbell-Ajala and Pier Giuseppe Sessa and Xintian and Wu and Guangda Lai and Paul Collins and Alex Haig and Vytenis Sakenas and Xiaowei Xu and Marissa Giustina and Laurent El Shafey and Pichi Charoenpanit and Shefali Garg and Joshua Ainslie and Boone Severson and Montse Gonzalez Arenas and Shreya Pathak and Sujee Rajayogam and Jie Feng and Michiel Bakker and Sheng Li and Nevan Wichers and Jamie Rogers and Xinyang Geng and Yeqing Li and Rolf Jagerman and Chao Jia and Nadav Olmert and David Sharon and Matthew Mauger and Sandeep Mariserla and Hongxu Ma and Megha Mohabey and Kyuyeun Kim and Alek Andreev and Scott Pollom and Juliette Love and Vihan Jain and Priyanka Agrawal and Yannick Schroecker and Alisa Fortin and Manfred Warmuth and Ji Liu and Andrew Leach and Irina Blok and Ganesh Poomal Girirajan and Roee Aharoni and Benigno Uria and Andrei Sozanschi and Dan Goldberg and Lucian Ionita and Marco Tulio Ribeiro and Martin Zlocha and Vighnesh Birodkar and Sami Lachgar and Liangzhe Yuan and Himadri Choudhury and Matt Ginsberg and Fei Zheng and Gregory Dibb and Emily Graves and Swachhand Lokhande and Gabriel Rasskin and George-Cristian Muraru and Corbin Quick and Sandeep Tata and Pierre Sermanet and Aditya Chawla and Itay Karo and Yan Wang and Susan Zhang and Orgad Keller and Anca Dragan and Guolong Su and Ian Chou and Xi Liu and Yiqing Tao and Shruthi Prabhakara and Marc Wilson and Ruibo Liu and Shibo Wang and Georgie Evans and David Du and Alfonso Castaño and Gautam Prasad and Mona El Mahdy and Sebastian Gerlach and Machel Reid and Jarrod Kahn and Amir Zait and Thanumalayan Sankaranarayana Pillai and Thatcher Ulrich and Guanyu Wang and Jan Wassenberg and Efrat Farkash and Kiran Yalasangi and Congchao Wang and Maria Bauza and Simon Bucher and Ting Liu and Jun Yan and Gary Leung and Vikas Sindhwani and Parker Barnes and Avi Singh and Ivan Jurin and Jichuan Chang and Niket Kumar Bhumihar and Sivan Eiger and Gui Citovsky and Ben Withbroe and Zhang Li and Siyang Xue and Niccolò Dal Santo and Georgi Stoyanov and Yves Raimond and Steven Zheng and Yilin Gao and Vít Listík and Sławek Kwasiborski and Rachel Saputro and Adnan Ozturel and Ganesh Mallya and Kushal Majmundar and Ross West and Paul Caron and Jinliang Wei and Lluis Castrejon and Sharad Vikram and Deepak Ramachandran and Nikhil Dhawan and Jiho Park and Sara Smoot and George van den Driessche and Yochai Blau and Chase Malik and Wei Liang and Roy Hirsch and Cicero Nogueira dos Santos and Eugene Weinstein and Aäron van den Oord and Sid Lall and Nicholas FitzGerald and Zixuan Jiang and Xuan Yang and Dale Webster and Ali Elqursh and Aedan Pope and Georges Rotival and David Raposo and Wanzheng Zhu and Jeff Dean and Sami Alabed and Dustin Tran and Arushi Gupta and Zach Gleicher and Jessica Austin and Edouard Rosseel and Megh Umekar and Dipanjan Das and Yinghao Sun and Kai Chen and Karolis Misiunas and Xiang Zhou and Yixian Di and Alyssa Loo and Josh Newlan and Bo Li and Vinay Ramasesh and Ying Xu and Alex Chen and Sudeep Gandhe and Radu Soricut and Nikita Gupta and Shuguang Hu and Seliem El-Sayed and Xavier Garcia and Idan Brusilovsky and Pu-Chin Chen and Andrew Bolt and Lu Huang and Alex Gurney and Zhiying Zhang and Alexander Pritzel and Jarek Wilkiewicz and Bryan Seybold and Bhargav Kanagal Shamanna and Felix Fischer and Josef Dean and Karan Gill and Ross Mcilroy and Abhishek Bhowmick and Jeremy Selier and Antoine Yang and Derek Cheng and Vladimir Magay and Jie Tan and Dhriti Varma and Christian Walder and Tomas Kocisky and Ryo Nakashima and Paul Natsev and Mike Kwong and Ionel Gog and Chiyuan Zhang and Sander Dieleman and Thomas Jimma and Andrey Ryabtsev and Siddhartha Brahma and David Steiner and Dayou Du and Ante Žužul and Mislav Žanić and Mukund Raghavachari and Willi Gierke and Zeyu Zheng and Dessie Petrova and Yann Dauphin and Yuchuan Liu and Ido Kessler and Steven Hand and Chris Duvarney and Seokhwan Kim and Hyo Lee and Léonard Hussenot and Jeffrey Hui and Josh Smith and Deepali Jain and Jiawei Xia and Gaurav Singh Tomar and Keyvan Amiri and Du Phan and Fabian Fuchs and Tobias Weyand and Nenad Tomasev and Alexandra Cordell and Xin Liu and Jonathan Mallinson and Pankaj Joshi and Andy Crawford and Arun Suggala and Steve Chien and Nick Fernando and Mariella Sanchez-Vargas and Duncan Williams and Phil Crone and Xiyang Luo and Igor Karpov and Jyn Shan and Terry Thurk and Robin Strudel and Paul Voigtlaender and Piyush Patil and Tim Dozat and Ali Khodaei and Sahil Singla and Piotr Ambroszczyk and Qiyin Wu and Yifan Chang and Brian Roark and Chaitra Hegde and Tianli Ding and Angelos Filos and Zhongru Wu and André Susano Pinto and Shuang Liu and Saarthak Khanna and Aditya Pandey and Siobhan Mcloughlin and Qiujia Li and Sam Haves and Allan Zhou and Elena Buchatskaya and Isabel Leal and Peter de Boursac and Nami Akazawa and Nina Anderson and Terry Chen and Krishna Somandepalli and Chen Liang and Sheela Goenka and Stephanie Winkler and Alexander Grushetsky and Yifan Ding and Jamie Smith and Fan Ye and Jordi Pont-Tuset and Eric Li and Ruichao Li and Tomer Golany and Dawid Wegner and Tao Jiang and Omer Barak and Yuan Shangguan and Eszter Vértes and Renee Wong and Jörg Bornschein and Alex Tudor and Michele Bevilacqua and Tom Schaul and Ankit Singh Rawat and Yang Zhao and Kyriakos Axiotis and Lei Meng and Cory McLean and Jonathan Lai and Jennifer Beattie and Nate Kushman and Yaxin Liu and Blair Kutzman and Fiona Lang and Jingchen Ye and Praneeth Netrapalli and Pushkar Mishra and Myriam Khan and Megha Goel and Rob Willoughby and David Tian and Honglei Zhuang and JD Chen and Zak Tsai and Tasos Kementsietsidis and Arjun Khare and James Keeling and Keyang Xu and Nathan Waters and Florent Altché and Ashok Popat and Bhavishya Mittal and David Saxton and Dalia El Badawy and Michael Mathieu and Zheng Zheng and Hao Zhou and Nishant Ranka and Richard Shin and Qingnan Duan and Tim Salimans and Ioana Mihailescu and Uri Shaham and Ming-Wei Chang and Yannis Assael and Nishanth Dikkala and Martin Izzard and Vincent Cohen-Addad and Cat Graves and Vlad Feinberg and Grace Chung and DJ Strouse and Danny Karmon and Sahand Sharifzadeh and Zoe Ashwood and Khiem Pham and Jon Blanton and Alex Vasiloff and Jarred Barber and Mark Geller and Aurick Zhou and Fedir Zubach and Tzu-Kuo Huang and Lei Zhang and Himanshu Gupta and Matt Young and Julia Proskurnia and Ronny Votel and Valentin Gabeur and Gabriel Barcik and Aditya Tripathi and Hongkun Yu and Geng Yan and Beer Changpinyo and Filip Pavetić and Amy Coyle and Yasuhisa Fujii and Jorge Gonzalez Mendez and Tianhao Zhou and Harish Rajamani and Blake Hechtman and Eddie Cao and Da-Cheng Juan and Yi-Xuan Tan and Valentin Dalibard and Yilun Du and Natalie Clay and Kaisheng Yao and Wenhao Jia and Dimple Vijaykumar and Yuxiang Zhou and Xinyi Bai and Wei-Chih Hung and Steven Pecht and Georgi Todorov and Nikhil Khadke and Pramod Gupta and Preethi Lahoti and Arnaud Autef and Karthik Duddu and James Lee-Thorp and Alexander Bykovsky and Tautvydas Misiunas and Sebastian Flennerhag and Santhosh Thangaraj and Jed McGiffin and Zack Nado and Markus Kunesch and Andreas Noever and Amir Hertz and Marco Liang and Victor Stone and Evan Palmer and Samira Daruki and Arijit Pramanik and Siim Põder and Austin Kyker and Mina Khan and Evgeny Sluzhaev and Marvin Ritter and Avraham Ruderman and Wenlei Zhou and Chirag Nagpal and Kiran Vodrahalli and George Necula and Paul Barham and Ellie Pavlick and Jay Hartford and Izhak Shafran and Long Zhao and Maciej Mikuła and Tom Eccles and Hidetoshi Shimokawa and Kanav Garg and Luke Vilnis and Hanwen Chen and Ilia Shumailov and Kuang-Huei Lee and Abdelrahman Abdelhamed and Meiyan Xie and Vered Cohen and Ester Hlavnova and Dan Malkin and Chawin Sitawarin and James Lottes and Pauline Coquinot and Tianli Yu and Sandeep Kumar and Jingwei Zhang and Aroma Mahendru and Zafarali Ahmed and James Martens and Tao Chen and Aviel Boag and Daiyi Peng and Coline Devin and Arseniy Klimovskiy and Mary Phuong and Danny Vainstein and Jin Xie and Bhuvana Ramabhadran and Nathan Howard and Xinxin Yu and Gitartha Goswami and Jingyu Cui and Sam Shleifer and Mario Pinto and Chih-Kuan Yeh and Ming-Hsuan Yang and Sara Javanmardi and Dan Ethier and Chace Lee and Jordi Orbay and Suyog Kotecha and Carla Bromberg and Pete Shaw and James Thornton and Adi Gerzi Rosenthal and Shane Gu and Matt Thomas and Ian Gemp and Aditya Ayyar and Asahi Ushio and Aarush Selvan and Joel Wee and Chenxi Liu and Maryam Majzoubi and Weiren Yu and Jake Abernethy and Tyler Liechty and Renke Pan and Hoang Nguyen and Qiong and Hu and Sarah Perrin and Abhinav Arora and Emily Pitler and Weiyi Wang and Kaushik Shivakumar and Flavien Prost and Ben Limonchik and Jing Wang and Yi Gao and Timothee Cour and Shyamal Buch and Huan Gui and Maria Ivanova and Philipp Neubeck and Kelvin Chan and Lucy Kim and Huizhong Chen and Naman Goyal and Da-Woon Chung and Lu Liu and Yao Su and Anastasia Petrushkina and Jiajun Shen and Armand Joulin and Yuanzhong Xu and Stein Xudong Lin and Yana Kulizhskaya and Ciprian Chelba and Shobha Vasudevan and Eli Collins and Vasilisa Bashlovkina and Tony Lu and Doug Fritz and Jongbin Park and Yanqi Zhou and Chen Su and Richard Tanburn and Mikhail Sushkov and Mitchelle Rasquinha and Jinning Li and Jennifer Prendki and Yiming Li and Pallavi LV and Shriya Sharma and Hen Fitoussi and Hui Huang and Andrew Dai and Phuong Dao and Mike Burrows and Henry Prior and Danfeng Qin and Golan Pundak and Lars Lowe Sjoesund and Art Khurshudov and Zhenkai Zhu and Albert Webson and Elizabeth Kemp and Tat Tan and Saurabh Agrawal and Susie Sargsyan and Liqun Cheng and Jim Stephan and Tom Kwiatkowski and David Reid and Arunkumar Byravan and Assaf Hurwitz Michaely and Nicolas Heess and Luowei Zhou and Sonam Goenka and Viral Carpenter and Anselm Levskaya and Bo Wang and Reed Roberts and Rémi Leblond and Sharat Chikkerur and Stav Ginzburg and Max Chang and Robert Riachi and Chuqiao and Xu and Zalán Borsos and Michael Pliskin and Julia Pawar and Morgane Lustman and Hannah Kirkwood and Ankit Anand and Aditi Chaudhary and Norbert Kalb and Kieran Milan and Sean Augenstein and Anna Goldie and Laurel Prince and Karthik Raman and Yanhua Sun and Vivian Xia and Aaron Cohen and Zhouyuan Huo and Josh Camp and Seher Ellis and Lukas Zilka and David Vilar Torres and Lisa Patel and Sho Arora and Betty Chan and Jonas Adler and Kareem Ayoub and Jacky Liang and Fayaz Jamil and Jiepu Jiang and Simon Baumgartner and Haitian Sun and Yael Karov and Yaroslav Akulov and Hui Zheng and Irene Cai and Claudio Fantacci and James Rubin and Alex Rav Acha and Mengchao Wang and Nina D'Souza and Rohit Sathyanarayana and Shengyang Dai and Simon Rowe and Andrey Simanovsky and Omer Goldman and Yuheng Kuang and Xiaoyue Pan and Andrew Rosenberg and Tania Rojas-Esponda and Praneet Dutta and Amy Zeng and Irina Jurenka and Greg Farquhar and Yamini Bansal and Shariq Iqbal and Becca Roelofs and Ga-Young Joung and Parker Beak and Changwan Ryu and Ryan Poplin and Yan Wu and Jean-Baptiste Alayrac and Senaka Buthpitiya and Olaf Ronneberger and Caleb Habtegebriel and Wei Li and Paul Cavallaro and Aurora Wei and Guy Bensky and Timo Denk and Harish Ganapathy and Jeff Stanway and Pratik Joshi and Francesco Bertolini and Jessica Lo and Olivia Ma and Zachary Charles and Geta Sampemane and Himanshu Sahni and Xu Chen and Harry Askham and David Gaddy and Peter Young and Jiewen Tan and Matan Eyal and Arthur Bražinskas and Li Zhong and Zhichun Wu and Mark Epstein and Kai Bailey and Andrew Hard and Kamyu Lee and Sasha Goldshtein and Alex Ruiz and Mohammed Badawi and Matthias Lochbrunner and JK Kearns and Ashley Brown and Fabio Pardo and Theophane Weber and Haichuan Yang and Pan-Pan Jiang and Berkin Akin and Zhao Fu and Marcus Wainwright and Chi Zou and Meenu Gaba and Pierre-Antoine Manzagol and Wendy Kan and Yang Song and Karina Zainullina and Rui Lin and Jeongwoo Ko and Salil Deshmukh and Apoorv Jindal and James Svensson and Divya Tyam and Heri Zhao and Christine Kaeser-Chen and Scott Baird and Pooya Moradi and Jamie Hall and Qiuchen Guo and Vincent Tsang and Bowen Liang and Fernando Pereira and Suhas Ganesh and Ivan Korotkov and Jakub Adamek and Sridhar Thiagarajan and Vinh Tran and Charles Chen and Chris Tar and Sanil Jain and Ishita Dasgupta and Taylan Bilal and David Reitter and Kai Zhao and Giulia Vezzani and Yasmin Gehman and Pulkit Mehta and Lauren Beltrone and Xerxes Dotiwalla and Sergio Guadarrama and Zaheer Abbas and Stefani Karp and Petko Georgiev and Chun-Sung Ferng and Marc Brockschmidt and Liqian Peng and Christoph Hirnschall and Vikas Verma and Yingying Bi and Ying Xiao and Avigail Dabush and Kelvin Xu and Phil Wallis and Randall Parker and Qifei Wang and Yang Xu and Ilkin Safarli and Dinesh Tewari and Yin Zhang and Seungyeon Kim and Andrea Gesmundo and Mackenzie Thomas and Sergey Levi and Ahmed Chowdhury and Kanishka Rao and Peter Garst and Sam Conway-Rahman and Helen Ran and Kay McKinney and Zhisheng Xiao and Wenhao Yu and Rohan Agrawal and Axel Stjerngren and Catalin Ionescu and Jingjing Chen and Vivek Sharma and Justin Chiu and Fei Liu and Ken Franko and Clayton Sanford and Xingyu Cai and Paul Michel and Sanjay Ganapathy and Jane Labanowski and Zachary Garrett and Ben Vargas and Sean Sun and Bryan Gale and Thomas Buschmann and Guillaume Desjardins and Nimesh Ghelani and Palak Jain and Mudit Verma and Chulayuth Asawaroengchai and Julian Eisenschlos and Jitendra Harlalka and Hideto Kazawa and Don Metzler and Joshua Howland and Ying Jian and Jake Ades and Viral Shah and Tynan Gangwani and Seungji Lee and Roman Ring and Steven M. Hernandez and Dean Reich and Amer Sinha and Ashutosh Sathe and Joe Kovac and Ashleah Gill and Ajay Kannan and Andrea D'olimpio and Martin Sevenich and Jay Whang and Been Kim and Khe Chai Sim and Jilin Chen and Jiageng Zhang and Shuba Lall and Yossi Matias and Bill Jia and Abe Friesen and Sara Nasso and Ashish Thapliyal and Bryan Perozzi and Ting Yu and Anna Shekhawat and Safeen Huda and Peter Grabowski and Eric Wang and Ashwin Sreevatsa and Hilal Dib and Mehadi Hassen and Parker Schuh and Vedrana Milutinovic and Chris Welty and Michael Quinn and Ali Shah and Bangju Wang and Gabe Barth-Maron and Justin Frye and Natalie Axelsson and Tao Zhu and Yukun Ma and Irene Giannoumis and Hanie Sedghi and Chang Ye and Yi Luan and Kevin Aydin and Bilva Chandra and Vivek Sampathkumar and Ronny Huang and Victor Lavrenko and Ahmed Eleryan and Zhi Hong and Steven Hansen and Sara Mc Carthy and Bidisha Samanta and Domagoj Ćevid and Xin Wang and Fangtao Li and Michael Voznesensky and Matt Hoffman and Andreas Terzis and Vikash Sehwag and Gil Fidel and Luheng He and Mu Cai and Yanzhang He and Alex Feng and Martin Nikoltchev and Samrat Phatale and Jason Chase and Rory Lawton and Ming Zhang and Tom Ouyang and Manuel Tragut and Mehdi Hafezi Manshadi and Arjun Narayanan and Jiaming Shen and Xu Gao and Tolga Bolukbasi and Nick Roy and Xin Li and Daniel Golovin and Liviu Panait and Zhen Qin and Guangxing Han and Thomas Anthony and Sneha Kudugunta and Viorica Patraucean and Aniket Ray and Xinyun Chen and Xiaochen Yang and Tanuj Bhatia and Pranav Talluri and Alex Morris and Andrija Ražnatović and Bethanie Brownfield and James An and Sheng Peng and Patrick Kane and Ce Zheng and Nico Duduta and Joshua Kessinger and James Noraky and Siqi Liu and Keran Rong and Petar Veličković and Keith Rush and Alex Goldin and Fanny Wei and Shiva Mohan Reddy Garlapati and Caroline Pantofaru and Okwan Kwon and Jianmo Ni and Eric Noland and Julia Di Trapani and Françoise Beaufays and Abhijit Guha Roy and Yinlam Chow and Aybuke Turker and Geoffrey Cideron and Lantao Mei and Jon Clark and Qingyun Dou and Matko Bošnjak and Ralph Leith and Yuqing Du and Amir Yazdanbakhsh and Milad Nasr and Chester Kwak and Suraj Satishkumar Sheth and Alex Kaskasoli and Ankesh Anand and Balaji Lakshminarayanan and Sammy Jerome and David Bieber and Chun-Te Chu and Alexandre Senges and Tianxiao Shen and Mukund Sridhar and Ndaba Ndebele and Benjamin Beyret and Shakir Mohamed and Mia Chen and Markus Freitag and Jiaxian Guo and Luyang Liu and Paul Roit and Heng Chen and Shen Yan and Tom Stone and JD Co-Reyes and Jeremy Cole and Salvatore Scellato and Shekoofeh Azizi and Hadi Hashemi and Alicia Jin and Anand Iyer and Marcella Valentine and András György and Arun Ahuja and Daniel Hernandez Diaz and Chen-Yu Lee and Nathan Clement and Weize Kong and Drew Garmon and Ishaan Watts and Kush Bhatia and Khyatti Gupta and Matt Miecnikowski and Hugo Vallet and Ankur Taly and Edward Loper and Saket Joshi and James Atwood and Jo Chick and Mark Collier and Fotis Iliopoulos and Ryan Trostle and Beliz Gunel and Ramiro Leal-Cavazos and Arnar Mar Hrafnkelsson and Michael Guzman and Xiaoen Ju and Andy Forbes and Jesse Emond and Kushal Chauhan and Ben Caine and Li Xiao and Wenjun Zeng and Alexandre Moufarek and Daniel Murphy and Maya Meng and Nitish Gupta and Felix Riedel and Anil Das and Elijah Lawal and Shashi Narayan and Tiberiu Sosea and James Swirhun and Linda Friso and Behnam Neyshabur and Jing Lu and Sertan Girgin and Michael Wunder and Edouard Yvinec and Aroonalok Pyne and Victor Carbune and Shruti Rijhwani and Yang Guo and Tulsee Doshi and Anton Briukhov and Max Bain and Ayal Hitron and Xuanhui Wang and Ashish Gupta and Ke Chen and Cosmo Du and Weiyang Zhang and Dhruv Shah and Arjun Akula and Max Dylla and Ashyana Kachra and Weicheng Kuo and Tingting Zou and Lily Wang and Luyao Xu and Jifan Zhu and Justin Snyder and Sachit Menon and Orhan Firat and Igor Mordatch and Yuan Yuan and Natalia Ponomareva and Rory Blevins and Lawrence Moore and Weijun Wang and Phil Chen and Martin Scholz and Artur Dwornik and Jason Lin and Sicheng Li and Diego Antognini and Te I and Xiaodan Song and Matt Miller and Uday Kalra and Adam Raveret and Oscar Akerlund and Felix Wu and Andrew Nystrom and Namrata Godbole and Tianqi Liu and Hannah DeBalsi and Jewel Zhao and Buhuang Liu and Avi Caciularu and Lauren Lax and Urvashi Khandelwal and Victoria Langston and Eric Bailey and Silvio Lattanzi and Yufei Wang and Neel Kovelamudi and Sneha Mondal and Guru Guruganesh and Nan Hua and Ofir Roval and Paweł Wesołowski and Rishikesh Ingale and Jonathan Halcrow and Tim Sohn and Christof Angermueller and Bahram Raad and Eli Stickgold and Eva Lu and Alec Kosik and Jing Xie and Timothy Lillicrap and Austin Huang and Lydia Lihui Zhang and Dominik Paulus and Clement Farabet and Alex Wertheim and Bing Wang and Rishabh Joshi and Chu-ling Ko and Yonghui Wu and Shubham Agrawal and Lily Lin and XiangHai Sheng and Peter Sung and Tyler Breland-King and Christina Butterfield and Swapnil Gawde and Sumeet Singh and Qiao Zhang and Raj Apte and Shilpa Shetty and Adrian Hutter and Tao Li and Elizabeth Salesky and Federico Lebron and Jonni Kanerva and Michela Paganini and Arthur Nguyen and Rohith Vallu and Jan-Thorsten Peter and Sarmishta Velury and David Kao and Jay Hoover and Anna Bortsova and Colton Bishop and Shoshana Jakobovits and Alessandro Agostini and Alekh Agarwal and Chang Liu and Charles Kwong and Sasan Tavakkol and Ioana Bica and Alex Greve and Anirudh GP and Jake Marcus and Le Hou and Tom Duerig and Rivka Moroshko and Dave Lacey and Andy Davis and Julien Amelot and Guohui Wang and Frank Kim and Theofilos Strinopoulos and Hui Wan and Charline Le Lan and Shankar Krishnan and Haotian Tang and Peter Humphreys and Junwen Bai and Idan Heimlich Shtacher and Diego Machado and Chenxi Pang and Ken Burke and Dangyi Liu and Renga Aravamudhan and Yue Song and Ed Hirst and Abhimanyu Singh and Brendan Jou and Liang Bai and Francesco Piccinno and Chuyuan Kelly Fu and Robin Alazard and Barak Meiri and Daniel Winter and Charlie Chen and Mingda Zhang and Jens Heitkaemper and John Lambert and Jinhyuk Lee and Alexander Frömmgen and Sergey Rogulenko and Pranav Nair and Paul Niemczyk and Anton Bulyenov and Bibo Xu and Hadar Shemtov and Morteza Zadimoghaddam and Serge Toropov and Mateo Wirth and Hanjun Dai and Sreenivas Gollapudi and Daniel Zheng and Alex Kurakin and Chansoo Lee and Kalesha Bullard and Nicolas Serrano and Ivana Balazevic and Yang Li and Johan Schalkwyk and Mark Murphy and Mingyang Zhang and Kevin Sequeira and Romina Datta and Nishant Agrawal and Charles Sutton and Nithya Attaluri and Mencher Chiang and Wael Farhan and Gregory Thornton and Kate Lin and Travis Choma and Hung Nguyen and Kingshuk Dasgupta and Dirk Robinson and Iulia Comşa and Michael Riley and Arjun Pillai and Basil Mustafa and Ben Golan and Amir Zandieh and Jean-Baptiste Lespiau and Billy Porter and David Ross and Sujeevan Rajayogam and Mohit Agarwal and Subhashini Venugopalan and Bobak Shahriari and Qiqi Yan and Hao Xu and Taylor Tobin and Pavel Dubov and Hongzhi Shi and Adrià Recasens and Anton Kovsharov and Sebastian Borgeaud and Lucio Dery and Shanthal Vasanth and Elena Gribovskaya and Linhai Qiu and Mahdis Mahdieh and Wojtek Skut and Elizabeth Nielsen and CJ Zheng and Adams Yu and Carrie Grimes Bostock and Shaleen Gupta and Aaron Archer and Chris Rawles and Elinor Davies and Alexey Svyatkovskiy and Tomy Tsai and Yoni Halpern and Christian Reisswig and Bartek Wydrowski and Bo Chang and Joan Puigcerver and Mor Hazan Taege and Jian Li and Eva Schnider and Xinjian Li and Dragos Dena and Yunhan Xu and Umesh Telang and Tianze Shi and Heiga Zen and Kyle Kastner and Yeongil Ko and Neesha Subramaniam and Aviral Kumar and Pete Blois and Zhuyun Dai and John Wieting and Yifeng Lu and Yoel Zeldes and Tian Xie and Anja Hauth and Alexandru Ţifrea and Yuqi Li and Sam El-Husseini and Dan Abolafia and Howard Zhou and Wen Ding and Sahra Ghalebikesabi and Carlos Guía and Andrii Maksai and Ágoston Weisz and Sercan Arik and Nick Sukhanov and Aga Świetlik and Xuhui Jia and Luo Yu and Weiyue Wang and Mark Brand and Dawn Bloxwich and Sean Kirmani and Zhe Chen and Alec Go and Pablo Sprechmann and Nithish Kannen and Alen Carin and Paramjit Sandhu and Isabel Edkins and Leslie Nooteboom and Jai Gupta and Loren Maggiore and Javad Azizi and Yael Pritch and Pengcheng Yin and Mansi Gupta and Danny Tarlow and Duncan Smith and Desi Ivanov and Mohammad Babaeizadeh and Ankita Goel and Satish Kambala and Grace Chu and Matej Kastelic and Michelle Liu and Hagen Soltau and Austin Stone and Shivani Agrawal and Min Kim and Kedar Soparkar and Srinivas Tadepalli and Oskar Bunyan and Rachel Soh and Arvind Kannan and DY Kim and Blake JianHang Chen and Afief Halumi and Sudeshna Roy and Yulong Wang and Olcan Sercinoglu and Gena Gibson and Sijal Bhatnagar and Motoki Sano and Daniel von Dincklage and Qingchun Ren and Blagoj Mitrevski and Mirek Olšák and Jennifer She and Carl Doersch and Jilei and Wang and Bingyuan Liu and Qijun Tan and Tamar Yakar and Tris Warkentin and Alex Ramirez and Carl Lebsack and Josh Dillon and Rajiv Mathews and Tom Cobley and Zelin Wu and Zhuoyuan Chen and Jon Simon and Swaroop Nath and Tara Sainath and Alexei Bendebury and Ryan Julian and Bharath Mankalale and Daria Ćurko and Paulo Zacchello and Adam R. Brown and Kiranbir Sodhia and Heidi Howard and Sergi Caelles and Abhinav Gupta and Gareth Evans and Anna Bulanova and Lesley Katzen and Roman Goldenberg and Anton Tsitsulin and Joe Stanton and Benoit Schillings and Vitaly Kovalev and Corey Fry and Rushin Shah and Kuo Lin and Shyam Upadhyay and Cheng Li and Soroush Radpour and Marcello Maggioni and Jing Xiong and Lukas Haas and Jenny Brennan and Aishwarya Kamath and Nikolay Savinov and Arsha Nagrani and Trevor Yacovone and Ryan Kappedal and Kostas Andriopoulos and Li Lao and YaGuang Li and Grigory Rozhdestvenskiy and Kazuma Hashimoto and Andrew Audibert and Sophia Austin and Daniel Rodriguez and Anian Ruoss and Garrett Honke and Deep Karkhanis and Xi Xiong and Qing Wei and James Huang and Zhaoqi Leng and Vittal Premachandran and Stan Bileschi and Georgios Evangelopoulos and Thomas Mensink and Jay Pavagadhi and Denis Teplyashin and Paul Chang and Linting Xue and Garrett Tanzer and Sally Goldman and Kaushal Patel and Shixin Li and Jeremy Wiesner and Ivy Zheng and Ian Stewart-Binks and Jie Han and Zhi Li and Liangchen Luo and Karel Lenc and Mario Lučić and Fuzhao Xue and Ryan Mullins and Alexey Guseynov and Chung-Ching Chang and Isaac Galatzer-Levy and Adam Zhang and Garrett Bingham and Grace Hu and Ale Hartman and Yue Ma and Jordan Griffith and Alex Irpan and Carey Radebaugh and Summer Yue and Lijie Fan and Victor Ungureanu and Christina Sorokin and Hannah Teufel and Peiran Li and Rohan Anil and Dimitris Paparas and Todd Wang and Chu-Cheng Lin and Hui Peng and Megan Shum and Goran Petrovic and Demetra Brady and Richard Nguyen and Klaus Macherey and Zhihao Li and Harman Singh and Madhavi Yenugula and Mariko Iinuma and Xinyi Chen and Kavya Kopparapu and Alexey Stern and Shachi Dave and Chandu Thekkath and Florence Perot and Anurag Kumar and Fangda Li and Yang Xiao and Matthew Bilotti and Mohammad Hossein Bateni and Isaac Noble and Lisa Lee and Amelio Vázquez-Reina and Julian Salazar and Xiaomeng Yang and Boyu Wang and Ela Gruzewska and Anand Rao and Sindhu Raghuram and Zheng Xu and Eyal Ben-David and Jieru Mei and Sid Dalmia and Zhaoyi Zhang and Yuchen Liu and Gagan Bansal and Helena Pankov and Steven Schwarcz and Andrea Burns and Christine Chan and Sumit Sanghai and Ricky Liang and Ethan Liang and Antoine He and Amy Stuart and Arun Narayanan and Yukun Zhu and Christian Frank and Bahar Fatemi and Amit Sabne and Oran Lang and Indro Bhattacharya and Shane Settle and Maria Wang and Brendan McMahan and Andrea Tacchetti and Livio Baldini Soares and Majid Hadian and Serkan Cabi and Timothy Chung and Nikita Putikhin and Gang Li and Jeremy Chen and Austin Tarango and Henryk Michalewski and Mehran Kazemi and Hussain Masoom and Hila Sheftel and Rakesh Shivanna and Archita Vadali and Ramona Comanescu and Doug Reid and Joss Moore and Arvind Neelakantan and Michaël Sander and Jonathan Herzig and Aviv Rosenberg and Mostafa Dehghani and JD Choi and Michael Fink and Reid Hayes and Eric Ge and Shitao Weng and Chia-Hua Ho and John Karro and Kalpesh Krishna and Lam Nguyen Thiet and Amy Skerry-Ryan and Daniel Eppens and Marco Andreetto and Navin Sarma and Silvano Bonacina and Burcu Karagol Ayan and Megha Nawhal and Zhihao Shan and Mike Dusenberry and Shantanu Thakoor and Sagar Gubbi and Duc Dung Nguyen and Reut Tsarfaty and Samuel Albanie and Jovana Mitrović and Meet Gandhi and Bo-Juen Chen and Alessandro Epasto and Georgi Stephanov and Ye Jin and Samuel Gehman and Aida Amini and Jack Weber and Feryal Behbahani and Shawn Xu and Miltos Allamanis and Xi Chen and Myle Ott and Claire Sha and Michal Jastrzebski and Hang Qi and David Greene and Xinyi Wu and Abodunrinwa Toki and Daniel Vlasic and Jane Shapiro and Ragha Kotikalapudi and Zhe Shen and Takaaki Saeki and Sirui Xie and Albin Cassirer and Shikhar Bharadwaj and Tatsuya Kiyono and Srinadh Bhojanapalli and Elan Rosenfeld and Sam Ritter and Jieming Mao and João Gabriel Oliveira and Zoltan Egyed and Bernd Bandemer and Emilio Parisotto and Keisuke Kinoshita and Juliette Pluto and Petros Maniatis and Steve Li and Yaohui Guo and Golnaz Ghiasi and Jean Tarbouriech and Srimon Chatterjee and Julie Jin and Katrina and Xu and Jennimaria Palomaki and Séb Arnold and Madhavi Sewak and Federico Piccinini and Mohit Sharma and Ben Albrecht and Sean Purser-haskell and Ashwin Vaswani and Chongyan Chen and Matheus Wisniewski and Qin Cao and John Aslanides and Nguyet Minh Phu and Maximilian Sieb and Lauren Agubuzu and Anne Zheng and Daniel Sohn and Marco Selvi and Anders Andreassen and Krishan Subudhi and Prem Eruvbetine and Oliver Woodman and Tomas Mery and Sebastian Krause and Xiaoqi Ren and Xiao Ma and Jincheng Luo and Dawn Chen and Wei Fan and Henry Griffiths and Christian Schuler and Alice Li and Shujian Zhang and Jean-Michel Sarr and Shixin Luo and Riccardo Patana and Matthew Watson and Dani Naboulsi and Michael Collins and Sailesh Sidhwani and Emiel Hoogeboom and Sharon Silver and Emily Caveness and Xiaokai Zhao and Mikel Rodriguez and Maxine Deines and Libin Bai and Patrick Griffin and Marco Tagliasacchi and Emily Xue and Spandana Raj Babbula and Bo Pang and Nan Ding and Gloria Shen and Elijah Peake and Remi Crocker and Shubha Srinivas Raghvendra and Danny Swisher and Woohyun Han and Richa Singh and Ling Wu and Vladimir Pchelin and Tsendsuren Munkhdalai and Dana Alon and Geoff Bacon and Efren Robles and Jannis Bulian and Melvin Johnson and George Powell and Felipe Tiengo Ferreira and Yaoyiran Li and Frederik Benzing and Mihajlo Velimirović and Hubert Soyer and William Kong and Tony and Nguyên and Zhen Yang and Jeremiah Liu and Joost van Amersfoort and Daniel Gillick and Baochen Sun and Nathalie Rauschmayr and Katie Zhang and Serena Zhan and Tao Zhou and Alexey Frolov and Chengrun Yang and Denis Vnukov and Louis Rouillard and Hongji Li and Amol Mandhane and Nova Fallen and Rajesh Venkataraman and Clara Huiyi Hu and Jennifer Brennan and Jenny Lee and Jerry Chang and Martin Sundermeyer and Zhufeng Pan and Rosemary Ke and Simon Tong and Alex Fabrikant and William Bono and Jindong Gu and Ryan Foley and Yiran Mao and Manolis Delakis and Dhruva Bhaswar and Roy Frostig and Nick Li and Avital Zipori and Cath Hope and Olga Kozlova and Swaroop Mishra and Josip Djolonga and Craig Schiff and Majd Al Merey and Eleftheria Briakou and Peter Morgan and Andy Wan and Avinatan Hassidim and RJ Skerry-Ryan and Kuntal Sengupta and Mary Jasarevic and Praveen Kallakuri and Paige Kunkle and Hannah Brennan and Tom Lieber and Hassan Mansoor and Julian Walker and Bing Zhang and Annie Xie and Goran Žužić and Adaeze Chukwuka and Alex Druinsky and Donghyun Cho and Rui Yao and Ferjad Naeem and Shiraz Butt and Eunyoung Kim and Zhipeng Jia and Mandy Jordan and Adam Lelkes and Mark Kurzeja and Sophie Wang and James Zhao and Andrew Over and Abhishek Chakladar and Marcel Prasetya and Neha Jha and Sriram Ganapathy and Yale Cong and Prakash Shroff and Carl Saroufim and Sobhan Miryoosefi and Mohamed Hammad and Tajwar Nasir and Weijuan Xi and Yang Gao and Young Maeng and Ben Hora and Chin-Yi Cheng and Parisa Haghani and Yoad Lewenberg and Caden Lu and Martin Matysiak and Naina Raisinghani and Huiyu Wang and Lexi Baugher and Rahul Sukthankar and Minh Giang and John Schultz and Noah Fiedel and Minmin Chen and Cheng-Chun Lee and Tapomay Dey and Hao Zheng and Shachi Paul and Celine Smith and Andy Ly and Yicheng Wang and Rishabh Bansal and Bartek Perz and Susanna Ricco and Stasha Blank and Vaishakh Keshava and Deepak Sharma and Marvin Chow and Kunal Lad and Komal Jalan and Simon Osindero and Craig Swanson and Jacob Scott and Anastasija Ilić and Xiaowei Li and Siddhartha Reddy Jonnalagadda and Afzal Shama Soudagar and Yan Xiong and Bat-Orgil Batsaikhan and Daniel Jarrett and Naveen Kumar and Maulik Shah and Matt Lawlor and Austin Waters and Mark Graham and Rhys May and Sabela Ramos and Sandra Lefdal and Zeynep Cankara and Nacho Cano and Brendan O'Donoghue and Jed Borovik and Frederick Liu and Jordan Grimstad and Mahmoud Alnahlawi and Katerina Tsihlas and Tom Hudson and Nikolai Grigorev and Yiling Jia and Terry Huang and Tobenna Peter Igwe and Sergei Lebedev and Xiaodan Tang and Igor Krivokon and Frankie Garcia and Melissa Tan and Eric Jia and Peter Stys and Shikhar Vashishth and Yu Liang and Balaji Venkatraman and Chenjie Gu and Anastasios Kementsietsidis and Chen Zhu and Junehyuk Jung and Yunfei Bai and Mohammad Javad Hosseini and Faruk Ahmed and Aditya Gupta and Xin Yuan and Shereen Ashraf and Shitij Nigam and Gautam Vasudevan and Pranjal Awasthi and Adi Mayrav Gilady and Zelda Mariet and Ramy Eskander and Haiguang Li and Hexiang Hu and Guillermo Garrido and Philippe Schlattner and George Zhang and Rohun Saxena and Petar Dević and Kritika Muralidharan and Ashwin Murthy and Yiqian Zhou and Min Choi and Arissa Wongpanich and Zhengdong Wang and Premal Shah and Yuntao Xu and Yiling Huang and Stephen Spencer and Alice Chen and James Cohan and Junjie Wang and Jonathan Tompson and Junru Wu and Ruba Haroun and Haiqiong Li and Blanca Huergo and Fan Yang and Tongxin Yin and James Wendt and Michael Bendersky and Rahma Chaabouni and Javier Snaider and Johan Ferret and Abhishek Jindal and Tara Thompson and Andrew Xue and Will Bishop and Shubham Milind Phal and Archit Sharma and Yunhsuan Sung and Prabakar Radhakrishnan and Mo Shomrat and Reeve Ingle and Roopali Vij and Justin Gilmer and Mihai Dorin Istin and Sam Sobell and Yang Lu and Emily Nottage and Dorsa Sadigh and Jeremiah Willcock and Tingnan Zhang and Steve Xu and Sasha Brown and Katherine Lee and Gary Wang and Yun Zhu and Yi Tay and Cheolmin Kim and Audrey Gutierrez and Abhanshu Sharma and Yongqin Xian and Sungyong Seo and Claire Cui and Elena Pochernina and Cip Baetu and Krzysztof Jastrzębski and Mimi Ly and Mohamed Elhawaty and Dan Suh and Eren Sezener and Pidong Wang and Nancy Yuen and George Tucker and Jiahao Cai and Zuguang Yang and Cindy Wang and Alex Muzio and Hai Qian and Jae Yoo and Derek Lockhart and Kevin R. McKee and Mandy Guo and Malika Mehrotra and Artur Mendonça and Sanket Vaibhav Mehta and Sherry Ben and Chetan Tekur and Jiaqi Mu and Muye Zhu and Victoria Krakovna and Hongrae Lee and AJ Maschinot and Sébastien Cevey and HyunJeong Choe and Aijun Bai and Hansa Srinivasan and Derek Gasaway and Nick Young and Patrick Siegler and Dan Holtmann-Rice and Vihari Piratla and Kate Baumli and Roey Yogev and Alex Hofer and Hado van Hasselt and Svetlana Grant and Yuri Chervonyi and David Silver and Andrew Hogue and Ayushi Agarwal and Kathie Wang and Preeti Singh and Four Flynn and Josh Lipschultz and Robert David and Lizzetth Bellot and Yao-Yuan Yang and Long Le and Filippo Graziano and Kate Olszewska and Kevin Hui and Akanksha Maurya and Nikos Parotsidis and Weijie Chen and Tayo Oguntebi and Joe Kelley and Anirudh Baddepudi and Johannes Mauerer and Gregory Shaw and Alex Siegman and Lin Yang and Shravya Shetty and Subhrajit Roy and Yunting Song and Wojciech Stokowiec and Ryan Burnell and Omkar Savant and Robert Busa-Fekete and Jin Miao and Samrat Ghosh and Liam MacDermed and Phillip Lippe and Mikhail Dektiarev and Zach Behrman and Fabian Mentzer and Kelvin Nguyen and Meng Wei and Siddharth Verma and Chris Knutsen and Sudeep Dasari and Zhipeng Yan and Petr Mitrichev and Xingyu Wang and Virat Shejwalkar and Jacob Austin and Srinivas Sunkara and Navneet Potti and Yan Virin and Christian Wright and Gaël Liu and Oriana Riva and Etienne Pot and Greg Kochanski and Quoc Le and Gargi Balasubramaniam and Arka Dhar and Yuguo Liao and Adam Bloniarz and Divyansh Shukla and Elizabeth Cole and Jong Lee and Sheng Zhang and Sushant Kafle and Siddharth Vashishtha and Parsa Mahmoudieh and Grace Chen and Raphael Hoffmann and Pranesh Srinivasan and Agustin Dal Lago and Yoav Ben Shalom and Zi Wang and Michael Elabd and Anuj Sharma and Junhyuk Oh and Suraj Kothawade and Maigo Le and Marianne Monteiro and Shentao Yang and Kaiz Alarakyia and Robert Geirhos and Diana Mincu and Håvard Garnes and Hayato Kobayashi and Soroosh Mariooryad and Kacper Krasowiak and Zhixin and Lai and Shibl Mourad and Mingqiu Wang and Fan Bu and Ophir Aharoni and Guanjie Chen and Abhimanyu Goyal and Vadim Zubov and Ankur Bapna and Elahe Dabir and Nisarg Kothari and Kay Lamerigts and Nicola De Cao and Jeremy Shar and Christopher Yew and Nitish Kulkarni and Dre Mahaarachchi and Mandar Joshi and Zhenhai Zhu and Jared Lichtarge and Yichao Zhou and Hannah Muckenhirn and Vittorio Selo and Oriol Vinyals and Peter Chen and Anthony Brohan and Vaibhav Mehta and Sarah Cogan and Ruth Wang and Ty Geri and Wei-Jen Ko and Wei Chen and Fabio Viola and Keshav Shivam and Lisa Wang and Madeleine Clare Elish and Raluca Ada Popa and Sébastien Pereira and Jianqiao Liu and Raphael Koster and Donnie Kim and Gufeng Zhang and Sayna Ebrahimi and Partha Talukdar and Yanyan Zheng and Petra Poklukar and Ales Mikhalap and Dale Johnson and Anitha Vijayakumar and Mark Omernick and Matt Dibb and Ayush Dubey and Qiong Hu and Apurv Suman and Vaibhav Aggarwal and Ilya Kornakov and Fei Xia and Wing Lowe and Alexey Kolganov and Ted Xiao and Vitaly Nikolaev and Steven Hemingray and Bonnie Li and Joana Iljazi and Mikołaj Rybiński and Ballie Sandhu and Peggy Lu and Thang Luong and Rodolphe Jenatton and Vineetha Govindaraj and Hui and Li and Gabriel Dulac-Arnold and Wonpyo Park and Henry Wang and Abhinit Modi and Jean Pouget-Abadie and Kristina Greller and Rahul Gupta and Robert Berry and Prajit Ramachandran and Jinyu Xie and Liam McCafferty and Jianling Wang and Kilol Gupta and Hyeontaek Lim and Blaž Bratanič and Andy Brock and Ilia Akolzin and Jim Sproch and Dan Karliner and Duhyeon Kim and Adrian Goedeckemeyer and Noam Shazeer and Cordelia Schmid and Daniele Calandriello and Parul Bhatia and Krzysztof Choromanski and Ceslee Montgomery and Dheeru Dua and Ana Ramalho and Helen King and Yue Gao and Lynn Nguyen and David Lindner and Divya Pitta and Oleaser Johnson and Khalid Salama and Diego Ardila and Michael Han and Erin Farnese and Seth Odoom and Ziyue Wang and Xiangzhuo Ding and Norman Rink and Ray Smith and Harshal Tushar Lehri and Eden Cohen and Neera Vats and Tong He and Parthasarathy Gopavarapu and Adam Paszke and Miteyan Patel and Wouter Van Gansbeke and Lucia Loher and Luis Castro and Maria Voitovich and Tamara von Glehn and Nelson George and Simon Niklaus and Zach Eaton-Rosen and Nemanja Rakićević and Erik Jue and Sagi Perel and Carrie Zhang and Yuval Bahat and Angéline Pouget and Zhi Xing and Fantine Huot and Ashish Shenoy and Taylor Bos and Vincent Coriou and Bryan Richter and Natasha Noy and Yaqing Wang and Santiago Ontanon and Siyang Qin and Gleb Makarchuk and Demis Hassabis and Zhuowan Li and Mandar Sharma and Kumaran Venkatesan and Iurii Kemaev and Roxanne Daniel and Shiyu Huang and Saloni Shah and Octavio Ponce and Warren and Chen and Manaal Faruqui and Jialin Wu and Slavica Andačić and Szabolcs Payrits and Daniel McDuff and Tom Hume and Yuan Cao and MH Tessler and Qingze Wang and Yinan Wang and Ivor Rendulic and Eirikur Agustsson and Matthew Johnson and Tanya Lando and Andrew Howard and Sri Gayatri Sundara Padmanabhan and Mayank Daswani and Andrea Banino and Michael Kilgore and Jonathan Heek and Ziwei Ji and Alvaro Caceres and Conglong Li and Nora Kassner and Alexey Vlaskin and Zeyu Liu and Alex Grills and Yanhan Hou and Roykrong Sukkerd and Gowoon Cheon and Nishita Shetty and Larisa Markeeva and Piotr Stanczyk and Tejas Iyer and Yuan Gong and Shawn Gao and Keerthana Gopalakrishnan and Tim Blyth and Malcolm Reynolds and Avishkar Bhoopchand and Misha Bilenko and Dero Gharibian and Vicky Zayats and Aleksandra Faust and Abhinav Singh and Min Ma and Hongyang Jiao and Sudheendra Vijayanarasimhan and Lora Aroyo and Vikas Yadav and Sarah Chakera and Ashwin Kakarla and Vilobh Meshram and Karol Gregor and Gabriela Botea and Evan Senter and Dawei Jia and Geza Kovacs and Neha Sharma and Sebastien Baur and Kai Kang and Yifan He and Lin Zhuo and Marija Kostelac and Itay Laish and Songyou Peng and Louis O'Bryan and Daniel Kasenberg and Girish Ramchandra Rao and Edouard Leurent and Biao Zhang and Sage Stevens and Ana Salazar and Ye Zhang and Ivan Lobov and Jake Walker and Allen Porter and Morgan Redshaw and Han Ke and Abhishek Rao and Alex Lee and Hoi Lam and Michael Moffitt and Jaeyoun Kim and Siyuan Qiao and Terry Koo and Robert Dadashi and Xinying Song and Mukund Sundararajan and Peng Xu and Chizu Kawamoto and Yan Zhong and Clara Barbu and Apoorv Reddy and Mauro Verzetti and Leon Li and George Papamakarios and Hanna Klimczak-Plucińska and Mary Cassin and Koray Kavukcuoglu and Rigel Swavely and Alain Vaucher and Jeffrey Zhao and Ross Hemsley and Michael Tschannen and Heming Ge and Gaurav Menghani and Yang Yu and Natalie Ha and Wei He and Xiao Wu and Maggie Song and Rachel Sterneck and Stefan Zinke and Dan A. Calian and Annie Marsden and Alejandro Cruzado Ruiz and Matteo Hessel and Almog Gueta and Benjamin Lee and Brian Farris and Manish Gupta and Yunjie Li and Mohammad Saleh and Vedant Misra and Kefan Xiao and Piermaria Mendolicchio and Gavin Buttimore and Varvara Krayvanova and Nigamaa Nayakanti and Matthew Wiethoff and Yash Pande and Azalia Mirhoseini and Ni Lao and Jasmine Liu and Yiqing Hua and Angie Chen and Yury Malkov and Dmitry Kalashnikov and Shubham Gupta and Kartik Audhkhasi and Yuexiang Zhai and Sudhindra Kopalle and Prateek Jain and Eran Ofek and Clemens Meyer and Khuslen Baatarsukh and Hana Strejček and Jun Qian and James Freedman and Ricardo Figueira and Michal Sokolik and Olivier Bachem and Raymond Lin and Dia Kharrat and Chris Hidey and Pingmei Xu and Dennis Duan and Yin Li and Muge Ersoy and Richard Everett and Kevin Cen and Rebeca Santamaria-Fernandez and Amir Taubenfeld and Ian Mackinnon and Linda Deng and Polina Zablotskaia and Shashank Viswanadha and Shivanker Goel and Damion Yates and Yunxiao Deng and Peter Choy and Mingqing Chen and Abhishek Sinha and Alex Mossin and Yiming Wang and Arthur Szlam and Susan Hao and Paul Kishan Rubenstein and Metin Toksoz-Exley and Miranda Aperghis and Yin Zhong and Junwhan Ahn and Michael Isard and Olivier Lacombe and Florian Luisier and Chrysovalantis Anastasiou and Yogesh Kalley and Utsav Prabhu and Emma Dunleavy and Shaan Bijwadia and Justin Mao-Jones and Kelly Chen and Rama Pasumarthi and Emily Wood and Adil Dostmohamed and Nate Hurley and Jiri Simsa and Alicia Parrish and Mantas Pajarskas and Matt Harvey and Ondrej Skopek and Yony Kochinski and Javier Rey and Verena Rieser and Denny Zhou and Sun Jae Lee and Trilok Acharya and Guowang Li and Joe Jiang and Xiaofan Zhang and Bryant Gipson and Ethan Mahintorabi and Marco Gelmi and Nima Khajehnouri and Angel Yeh and Kayi Lee and Loic Matthey and Leslie Baker and Trang Pham and Han Fu and Alex Pak and Prakhar Gupta and Cristina Vasconcelos and Adam Sadovsky and Brian Walker and Sissie Hsiao and Patrik Zochbauer and Andreea Marzoca and Noam Velan and Junhao Zeng and Gilles Baechler and Danny Driess and Divya Jain and Yanping Huang and Lizzie Tao and John Maggs and Nir Levine and Jon Schneider and Erika Gemzer and Samuel Petit and Shan Han and Zach Fisher and Dustin Zelle and Courtney Biles and Eugene Ie and Asya Fadeeva and Casper Liu and Juliana Vicente Franco and Adrian Collister and Hao Zhang and Renshen Wang and Ruizhe Zhao and Leandro Kieliger and Kurt Shuster and Rui Zhu and Boqing Gong and Lawrence Chan and Ruoxi Sun and Sujoy Basu and Roland Zimmermann and Jamie Hayes and Abhishek Bapna and Jasper Snoek and Weel Yang and Puranjay Datta and Jad Al Abdallah and Kevin Kilgour and Lu Li and SQ Mah and Yennie Jun and Morgane Rivière and Abhijit Karmarkar and Tammo Spalink and Tao Huang and Lucas Gonzalez and Duc-Hieu Tran and Averi Nowak and John Palowitch and Martin Chadwick and Ellie Talius and Harsh Mehta and Thibault Sellam and Philipp Fränken and Massimo Nicosia and Kyle He and Aditya Kini and David Amos and Sugato Basu and Harrison Jobe and Eleni Shaw and Qiantong Xu and Colin Evans and Daisuke Ikeda and Chaochao Yan and Larry Jin and Lun Wang and Sachin Yadav and Ilia Labzovsky and Ramesh Sampath and Ada Ma and Candice Schumann and Aditya Siddhant and Rohin Shah and John Youssef and Rishabh Agarwal and Natalie Dabney and Alessio Tonioni and Moran Ambar and Jing Li and Isabelle Guyon and Benny Li and David Soergel and Boya Fang and Georgi Karadzhov and Cristian Udrescu and Trieu Trinh and Vikas Raunak and Seb Noury and Dee Guo and Sonal Gupta and Mara Finkelstein and Denis Petek and Lihao Liang and Greg Billock and Pei Sun and David Wood and Yiwen Song and Xiaobin Yu and Tatiana Matejovicova and Regev Cohen and Kalyan Andra and David D'Ambrosio and Zhiwei Deng and Vincent Nallatamby and Ebrahim Songhori and Rumen Dangovski and Andrew Lampinen and Pankil Botadra and Adam Hillier and Jiawei Cao and Nagabhushan Baddi and Adhi Kuncoro and Toshihiro Yoshino and Ankit Bhagatwala and Marcáurelio Ranzato and Rylan Schaeffer and Tianlin Liu and Shuai Ye and Obaid Sarvana and John Nham and Chenkai Kuang and Isabel Gao and Jinoo Baek and Shubham Mittal and Ayzaan Wahid and Anita Gergely and Bin Ni and Josh Feldman and Carrie Muir and Pascal Lamblin and Wolfgang Macherey and Ethan Dyer and Logan Kilpatrick and Víctor Campos and Mukul Bhutani and Stanislav Fort and Yanif Ahmad and Aliaksei Severyn and Kleopatra Chatziprimou and Oleksandr Ferludin and Mason Dimarco and Aditya Kusupati and Joe Heyward and Dan Bahir and Kevin Villela and Katie Millican and Dror Marcus and Sanaz Bahargam and Caglar Unlu and Nicholas Roth and Zichuan Wei and Siddharth Gopal and Deepanway Ghoshal and Edward Lee and Sharon Lin and Jennie Lees and Dayeong Lee and Anahita Hosseini and Connie Fan and Seth Neel and Marcus Wu and Yasemin Altun and Honglong Cai and Enrique Piqueras and Josh Woodward and Alessandro Bissacco and Salem Haykal and Mahyar Bordbar and Prasha Sundaram and Sarah Hodkinson and Daniel Toyama and George Polovets and Austin Myers and Anu Sinha and Tomer Levinboim and Kashyap Krishnakumar and Rachita Chhaparia and Tatiana Sholokhova and Nitesh Bharadwaj Gundavarapu and Ganesh Jawahar and Haroon Qureshi and Jieru Hu and Nikola Momchev and Matthew Rahtz and Renjie Wu and Aishwarya P S and Kedar Dhamdhere and Meiqi Guo and Umang Gupta and Ali Eslami and Mariano Schain and Michiel Blokzijl and David Welling and Dave Orr and Levent Bolelli and Nicolas Perez-Nieves and Mikhail Sirotenko and Aman Prasad and Arjun Kar and Borja De Balle Pigem and Tayfun Terzi and Gellért Weisz and Dipankar Ghosh and Aditi Mavalankar and Dhruv Madeka and Kaspar Daugaard and Hartwig Adam and Viraj Shah and Dana Berman and Maggie Tran and Steven Baker and Ewa Andrejczuk and Grishma Chole and Ganna Raboshchuk and Mahdi Mirzazadeh and Thais Kagohara and Shimu Wu and Christian Schallhart and Bernett Orlando and Chen Wang and Alban Rrustemi and Hao Xiong and Hao Liu and Arpi Vezer and Nolan Ramsden and Shuo-yiin Chang and Sidharth Mudgal and Yan Li and Nino Vieillard and Yedid Hoshen and Farooq Ahmad and Ambrose Slone and Amy Hua and Natan Potikha and Mirko Rossini and Jon Stritar and Sushant Prakash and Zifeng Wang and Xuanyi Dong and Alireza Nazari and Efrat Nehoran and Kaan Tekelioglu and Yinxiao Li and Kartikeya Badola and Tom Funkhouser and Yuanzhen Li and Varun Yerram and Ramya Ganeshan and Daniel Formoso and Karol Langner and Tian Shi and Huijian Li and Yumeya Yamamori and Amayika Panda and Alaa Saade and Angelo Scorza Scarpati and Chris Breaux and CJ Carey and Zongwei Zhou and Cho-Jui Hsieh and Sophie Bridgers and Alena Butryna and Nishesh Gupta and Vaibhav Tulsyan and Sanghyun Woo and Evgenii Eltyshev and Will Grathwohl and Chanel Parks and Seth Benjamin and Rina Panigrahy and Shenil Dodhia and Daniel De Freitas and Chris Sauer and Will Song and Ferran Alet and Jackson Tolins and Cosmin Paduraru and Xingyi Zhou and Brian Albert and Zizhao Zhang and Lei Shu and Mudit Bansal and Sarah Nguyen and Amir Globerson and Owen Xiao and James Manyika and Tom Hennigan and Rong Rong and Josip Matak and Anton Bakalov and Ankur Sharma and Danila Sinopalnikov and Andrew Pierson and Stephen Roller and Geoff Brown and Mingcen Gao and Toshiyuki Fukuzawa and Amin Ghafouri and Kenny Vassigh and Iain Barr and Zhicheng Wang and Anna Korsun and Rajesh Jayaram and Lijie Ren and Tim Zaman and Samira Khan and Yana Lunts and Dan Deutsch and Dave Uthus and Nitzan Katz and Masha Samsikova and Amr Khalifa and Nikhil Sethi and Jiao Sun and Luming Tang and Uri Alon and Xianghong Luo and Dian Yu and Abhishek Nayyar and Bryce Petrini and Will Truong and Vincent Hellendoorn and Nikolai Chinaev and Chris Alberti and Wei Wang and Jingcao Hu and Vahab Mirrokni and Ananth Balashankar and Avia Aharon and Aahil Mehta and Ahmet Iscen and Joseph Kready and Lucas Manning and Anhad Mohananey and Yuankai Chen and Anshuman Tripathi and Allen Wu and Igor Petrovski and Dawsen Hwang and Martin Baeuml and Shreyas Chandrakaladharan and Yuan Liu and Rey Coaguila and Maxwell Chen and Sally Ma and Pouya Tafti and Susheel Tatineni and Terry Spitz and Jiayu Ye and Paul Vicol and Mihaela Rosca and Adrià Puigdomènech and Zohar Yahav and Sanjay Ghemawat and Hanzhao Lin and Phoebe Kirk and Zaid Nabulsi and Sergey Brin and Bernd Bohnet and Ken Caluwaerts and Aditya Srikanth Veerubhotla and Dan Zheng and Zihang Dai and Petre Petrov and Yichong Xu and Ramin Mehran and Zhuo Xu and Luisa Zintgraf and Jiho Choi and Spurthi Amba Hombaiah and Romal Thoppilan and Sashank Reddi and Lukasz Lew and Li Li and Kellie Webster and KP Sawhney and Lampros Lamprou and Siamak Shakeri and Mayank Lunayach and Jianmin Chen and Sumit Bagri and Alex Salcianu and Ying Chen and Yani Donchev and Charlotte Magister and Signe Nørly and Vitor Rodrigues and Tomas Izo and Hila Noga and Joe Zou and Thomas Köppe and Wenxuan Zhou and Kenton Lee and Xiangzhu Long and Danielle Eisenbud and Anthony Chen and Connor Schenck and Chi Ming To and Peilin Zhong and Emanuel Taropa and Minh Truong and Omer Levy and Danilo Martins and Zhiyuan Zhang and Christopher Semturs and Kelvin Zhang and Alex Yakubovich and Pol Moreno and Lara McConnaughey and Di Lu and Sam Redmond and Lotte Weerts and Yonatan Bitton and Tiziana Refice and Nicolas Lacasse and Arthur Conmy and Corentin Tallec and Julian Odell and Hannah Forbes-Pollard and Arkadiusz Socala and Jonathan Hoech and Pushmeet Kohli and Alanna Walton and Rui Wang and Mikita Sazanovich and Kexin Zhu and Andrei Kapishnikov and Rich Galt and Matthew Denton and Ben Murdoch and Caitlin Sikora and Kareem Mohamed and Wei Wei and Uri First and Tim McConnell and Luis C. Cobo and James Qin and Thi Avrahami and Daniel Balle and Yu Watanabe and Annie Louis and Adam Kraft and Setareh Ariafar and Yiming Gu and Eugénie Rives and Charles Yoon and Andrei Rusu and James Cobon-Kerr and Chris Hahn and Jiaming Luo and Yuvein and Zhu and Niharika Ahuja and Rodrigo Benenson and Raphaël Lopez Kaufman and Honglin Yu and Lloyd Hightower and Junlin Zhang and Darren Ni and Lisa Anne Hendricks and Gabby Wang and Gal Yona and Lalit Jain and Pablo Barrio and Surya Bhupatiraju and Siva Velusamy and Allan Dafoe and Sebastian Riedel and Tara Thomas and Zhe Yuan and Mathias Bellaiche and Sheena Panthaplackel and Klemen Kloboves and Sarthak Jauhari and Canfer Akbulut and Todor Davchev and Evgeny Gladchenko and David Madras and Aleksandr Chuklin and Tyrone Hill and Quan Yuan and Mukundan Madhavan and Luke Leonhard and Dylan Scandinaro and Qihang Chen and Ning Niu and Arthur Douillard and Bogdan Damoc and Yasumasa Onoe and Fabian Pedregosa and Fred Bertsch and Chas Leichner and Joseph Pagadora and Jonathan Malmaud and Sameera Ponda and Andy Twigg and Oleksii Duzhyi and Jingwei Shen and Miaosen Wang and Roopal Garg and Jing Chen and Utku Evci and Jonathan Lee and Leon Liu and Koji Kojima and Masa Yamaguchi and Arunkumar Rajendran and AJ Piergiovanni and Vinodh Kumar Rajendran and Marco Fornoni and Gabriel Ibagon and Harry Ragan and Sadh MNM Khan and John Blitzer and Andrew Bunner and Guan Sun and Takahiro Kosakai and Scott Lundberg and Ndidi Elue and Kelvin Guu and SK Park and Jane Park and Arunachalam Narayanaswamy and Chengda Wu and Jayaram Mudigonda and Trevor Cohn and Hairong Mu and Ravi Kumar and Laura Graesser and Yichi Zhang and Richard Killam and Vincent Zhuang and Mai Giménez and Wael Al Jishi and Ruy Ley-Wild and Alex Zhai and Kazuki Osawa and Diego Cedillo and Jialu Liu and Mayank Upadhyay and Marcin Sieniek and Roshan Sharma and Tom Paine and Anelia Angelova and Sravanti Addepalli and Carolina Parada and Kingshuk Majumder and Avery Lamp and Sanjiv Kumar and Xiang Deng and Artiom Myaskovsky and Tea Sabolić and Jeffrey Dudek and Sarah York and Félix de Chaumont Quitry and Jiazhong Nie and Dee Cattle and Alok Gunjan and Bilal Piot and Waleed Khawaja and Seojin Bang and Simon Wang and Siavash Khodadadeh and Raghavender R and Praynaa Rawlani and Richard Powell and Kevin Lee and Johannes Griesser and GS Oh and Cesar Magalhaes and Yujia Li and Simon Tokumine and Hadas Natalie Vogel and Dennis Hsu and Arturo BC and Disha Jindal and Matan Cohen and Zi Yang and Junwei Yuan and Dario de Cesare and Tony Bruguier and Jun Xu and Monica Roy and Alon Jacovi and Dan Belov and Rahul Arya and Phoenix Meadowlark and Shlomi Cohen-Ganor and Wenting Ye and Patrick Morris-Suzuki and Praseem Banzal and Gan Song and Pranavaraj Ponnuramu and Fred Zhang and George Scrivener and Salah Zaiem and Alif Raditya Rochman and Kehang Han and Badih Ghazi and Kate Lee and Shahar Drath and Daniel Suo and Antonious Girgis and Pradeep Shenoy and Duy Nguyen and Douglas Eck and Somit Gupta and Le Yan and Joao Carreira and Anmol Gulati and Ruoxin Sang and Daniil Mirylenka and Emma Cooney and Edward Chou and Mingyang Ling and Cindy Fan and Ben Coleman and Guilherme Tubone and Ravin Kumar and Jason Baldridge and Felix Hernandez-Campos and Angeliki Lazaridou and James Besley and Itay Yona and Neslihan Bulut and Quentin Wellens and AJ Pierigiovanni and Jasmine George and Richard Green and Pu Han and Connie Tao and Geoff Clark and Chong You and Abbas Abdolmaleki and Justin Fu and Tongzhou Chen and Ashwin Chaugule and Angad Chandorkar and Altaf Rahman and Will Thompson and Penporn Koanantakool and Mike Bernico and Jie Ren and Andrey Vlasov and Sergei Vassilvitskii and Maciej Kula and Yizhong Liang and Dahun Kim and Yangsibo Huang and Chengxi Ye and Dmitry Lepikhin and Wesley Helmholz},
      year={2025},
      eprint={2507.06261},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2507.06261}, 
}




@article{jiao2025llm,
  abstract = {This study establishes a novel framework for systematically evaluating the moral reasoning capabilities of large language models (LLMs) as they increasingly integrate into critical societal domains. Current assessment methodologies lack the precision needed to evaluate nuanced ethical decision-making in AI systems, creating significant accountability gaps. Our framework addresses this challenge by quantifying alignment with human ethical standards through three dimensions: foundational moral principles, reasoning robustness, and value consistency across diverse scenarios. This approach enables precise identification of ethical strengths and weaknesses in LLMs, facilitating targeted improvements and stronger alignment with societal values. To promote transparency and collaborative advancement in ethical AI development, we are publicly releasing both our benchmark datasets and evaluation codebase at https://github.com/ The-Responsible-AI-Initiative/LLM_Ethics_Benchmark.git.},
  archiveprefix = {arXiv},
  author = {Junfeng Jiao and Saleh Afroogh and Abhejay Murali and Kevin Chen and David Atkinson and Amit Dhurandhar},
  file = {2505.00853v1.pdf},
  journal = {2505.00853v1},
  month = {May},
  primaryclass = {cs.CY},
  title = {LLM Ethics Benchmark: A Three-Dimensional Assessment System for Evaluating Moral Reasoning in Large Language Models},
  url = {http://arxiv.org/abs/2505.00853v1},
  year = {2025},
}

@article{jiashen2025are,
  abstract = {One open question in the study of Large Language Models (LLMs) is whether they can emulate human ethical reasoning and act as believable proxies for human judgment. To investigate this, we introduce a benchmark dataset comprising 196 real-world ethical dilemmas and expert opinions, each segmented into five structured components: Introduction, Key Factors, Historical Theoretical Perspectives, Resolution Strategies, and Key Takeaways. We also collect non-expert human responses for comparison, limited to the Key Factors section due to their brevity. We evaluate multiple frontier LLMs (GPT-4o-mini, Claude-3.5-Sonnet, Deepseek-V3, Gemini-1.5-Flash) using a composite metric framework based on BLEU, Damerau-Levenshtein distance, TF-IDF cosine similarity, and Universal Sentence Encoder similarity. Metric weights are computed through an inversion-based ranking alignment and pairwise AHP analysis, enabling fine-grained comparison of model outputs to expert responses. Our results show that LLMs generally outperform non-expert humans in lexical and structural alignment, with GPT-4o-mini performing most consistently across all sections. However, all models struggle with historical grounding and proposing nuanced resolution strategies, which require contextual abstraction. Human responses, while less structured, occasionally achieve comparable semantic similarity, suggesting intuitive moral reasoning. These findings highlight both the strengths and current limitations of LLMs in ethical decision-making.},
  archiveprefix = {arXiv},
  author = { Jiashen and  Du and Jesse Yao and Allen Liu and Zhekai Zhang},
  file = {2505.08106v1.pdf},
  journal = {2505.08106v1},
  month = {May},
  primaryclass = {cs.CL},
  title = {Are LLMs complicated ethical dilemma analyzers?},
  url = {http://arxiv.org/abs/2505.08106v1},
  year = {2025},
}

@article{mohammadi2025exploring,
  abstract = {Large Language Models (LLMs) have shown strong performance across many tasks, but their ability to capture culturally diverse moral values remains unclear. In this paper, we examine whether LLMs can mirror variations in moral attitudes reported by two major cross-cultural surveys: the World Values Survey and the PEW Research Center's Global Attitudes Survey. We compare smaller, monolingual, and multilingual models (GPT-2, OPT, BLOOMZ, and Qwen) with more recent instruction-tuned models (GPT-4o, GPT-4o-mini, Gemma-2-9b-it, and Llama-3.3-70B-Instruct). Using log-probability-based moral justifiability scores, we correlate each model's outputs with survey data covering a broad set of ethical topics. Our results show that many earlier or smaller models often produce near-zero or negative correlations with human judgments. In contrast, advanced instruction-tuned models (including GPT-4o and GPT-4o-mini) achieve substantially higher positive correlations, suggesting they better reflect real-world moral attitudes. While scaling up model size and using instruction tuning can improve alignment with cross-cultural moral norms, challenges remain for certain topics and regions. We discuss these findings in relation to bias analysis, training data diversity, and strategies for improving the cultural sensitivity of LLMs.},
  archiveprefix = {arXiv},
  author = {Hadi Mohammadi and Efthymia Papadopoulou and Yasmeen F. S. S. Meijer and Ayoub Bagheri},
  file = {2506.12433v1.pdf},
  journal = {2506.12433v1},
  month = {Jun},
  primaryclass = {cs.CL},
  title = {Exploring Cultural Variations in Moral Judgments with Large Language Models},
  url = {http://arxiv.org/abs/2506.12433v1},
  year = {2025},
}

@article{abhishek2025beats,
  abstract = {In this research, we introduce BEATS, a novel framework for evaluating Bias, Ethics, Fairness, and Factuality in Large Language Models (LLMs). Building upon the BEATS framework, we present a bias benchmark for LLMs that measure performance across 29 distinct metrics. These metrics span a broad range of characteristics, including demographic, cognitive, and social biases, as well as measures of ethical reasoning, group fairness, and factuality related misinformation risk. These metrics enable a quantitative assessment of the extent to which LLM generated responses may perpetuate societal prejudices that reinforce or expand systemic inequities. To achieve a high score on this benchmark a LLM must show very equitable behavior in their responses, making it a rigorous standard for responsible AI evaluation. Empirical results based on data from our experiment show that, 37.65\% of outputs generated by industry leading models contained some form of bias, highlighting a substantial risk of using these models in critical decision making systems. BEATS framework and benchmark offer a scalable and statistically rigorous methodology to benchmark LLMs, diagnose factors driving biases, and develop mitigation strategies. With the BEATS framework, our goal is to help the development of more socially responsible and ethically aligned AI models.},
  archiveprefix = {arXiv},
  author = {Alok Abhishek and Lisa Erickson and Tushar Bandopadhyay},
  file = {2503.24310v1.pdf},
  journal = {2503.24310v1},
  month = {Mar},
  primaryclass = {cs.CL},
  title = {BEATS: Bias Evaluation and Assessment Test Suite for Large Language Models},
  url = {http://arxiv.org/abs/2503.24310v1},
  year = {2025},
}

@article{liu2025diagnosing,
  abstract = {Ensuring that Large Language Models (LLMs) return just responses which adhere to societal values is crucial for their broader application. Prior research has shown that LLMs often fail to perform satisfactorily on tasks requiring moral cognizance, such as ethics-based judgments. While current approaches have focused on fine-tuning LLMs with curated datasets to improve their capabilities on such tasks, choosing the optimal learning paradigm to enhance the ethical responses of LLMs remains an open research debate. In this work, we aim to address this fundamental question: can current learning paradigms enable LLMs to acquire sufficient moral reasoning capabilities? Drawing from distributional semantics theory and the pragmatic nature of moral discourse, our analysis indicates that performance improvements follow a mechanism similar to that of semantic-level tasks, and therefore remain affected by the pragmatic nature of morals latent in discourse, a phenomenon we name the pragmatic dilemma. We conclude that this pragmatic dilemma imposes significant limitations on the generalization ability of current learning paradigms, making it the primary bottleneck for moral reasoning acquisition in LLMs.},
  archiveprefix = {arXiv},
  author = {Guangliang Liu and Zimo Qi and Xitong Zhang and Lei Jiang and Kristen Marie Johnson},
  file = {2502.16600v5.pdf},
  journal = {2502.16600v5},
  month = {Feb},
  primaryclass = {cs.CL},
  title = {Diagnosing Moral Reasoning Acquisition in Language Models: Pragmatics and Generalization},
  url = {http://arxiv.org/abs/2502.16600v5},
  year = {2025},
}

@article{backmann2025when,
  abstract = {Recent advances in large language models (LLMs) have enabled their use in complex agentic roles, involving decision-making with humans or other agents, making ethical alignment a key AI safety concern. While prior work has examined both LLMs' moral judgment and strategic behavior in social dilemmas, there is limited understanding of how they act when moral imperatives directly conflict with rewards or incentives. To investigate this, we introduce Moral Behavior in Social Dilemma Simulation (MoralSim) and evaluate how LLMs behave in the prisoner's dilemma and public goods game with morally charged contexts. In MoralSim, we test a range of frontier models across both game structures and three distinct moral framings, enabling a systematic examination of how LLMs navigate social dilemmas in which ethical norms conflict with payoff-maximizing strategies. Our results show substantial variation across models in both their general tendency to act morally and the consistency of their behavior across game types, the specific moral framing, and situational factors such as opponent behavior and survival risks. Crucially, no model exhibits consistently moral behavior in MoralSim, highlighting the need for caution when deploying LLMs in agentic roles where the agent's ""self-interest"" may conflict with ethical expectations. Our code is available at https://github.com/sbackmann/moralsim.},
  archiveprefix = {arXiv},
  author = {Steffen Backmann and David Guzman Piedrahita and Emanuel Tewolde and Rada Mihalcea and Bernhard Schölkopf and Zhijing Jin},
  file = {2505.19212v1.pdf},
  journal = {2505.19212v1},
  month = {May},
  primaryclass = {cs.CL},
  title = {When Ethics and Payoffs Diverge: LLM Agents in Morally Charged Social Dilemmas},
  url = {http://arxiv.org/abs/2505.19212v1},
  year = {2025},
}

@article{jiang2025emnlp,
  abstract = {Simulating Professions (SP) enables Large Language Models (LLMs) to emulate professional roles. However, comprehensive psychological and ethical evaluation in these contexts remains lacking. This paper introduces EMNLP, an Educator-role Moral and Normative LLMs Profiling framework for personality profiling, moral development stage measurement, and ethical risk under soft prompt injection. EMNLP extends existing scales and constructs 88 teacher-specific moral dilemmas, enabling profession-oriented comparison with human teachers. A targeted soft prompt injection set evaluates compliance and vulnerability in teacher SP. Experiments on 14 LLMs show teacher-role LLMs exhibit more idealized and polarized personalities than human teachers, excel in abstract moral reasoning, but struggle with emotionally complex situations. Models with stronger reasoning are more vulnerable to harmful prompt injection, revealing a paradox between capability and safety. The model temperature and other hyperparameters have limited influence except in some risk behaviors. This paper presents the first benchmark to assess ethical and psychological alignment of teacher-role LLMs for educational AI. Resources are available at https://e-m-n-l-p.github.io/.},
  archiveprefix = {arXiv},
  author = {Yilin Jiang and Mingzi Zhang and Sheng Jin and Zengyi Yu and Xiangjie Kong and Binghao Tu},
  doi = {10.18653/v1/2025.emnlp-main.42},
  file = {2508.15250v3.pdf},
  journal = {2508.15250v3},
  month = {Aug},
  primaryclass = {cs.CL},
  title = {EMNLP: Educator-role Moral and Normative Large Language Models Profiling},
  url = {http://arxiv.org/abs/2508.15250v3},
  year = {2025},
}

@article{jin2025medethiceval,
  abstract = {Large language models (LLMs) demonstrate significant potential in advancing medical applications, yet their capabilities in addressing medical ethics challenges remain underexplored. This paper introduces MedEthicEval, a novel benchmark designed to systematically evaluate LLMs in the domain of medical ethics. Our framework encompasses two key components: knowledge, assessing the models' grasp of medical ethics principles, and application, focusing on their ability to apply these principles across diverse scenarios. To support this benchmark, we consulted with medical ethics researchers and developed three datasets addressing distinct ethical challenges: blatant violations of medical ethics, priority dilemmas with clear inclinations, and equilibrium dilemmas without obvious resolutions. MedEthicEval serves as a critical tool for understanding LLMs' ethical reasoning in healthcare, paving the way for their responsible and effective use in medical contexts.},
  archiveprefix = {arXiv},
  author = {Haoan Jin and Jiacheng Shi and Hanhui Xu and Kenny Q. Zhu and Mengyue Wu},
  file = {2503.02374v1.pdf},
  journal = {2503.02374v1},
  month = {Mar},
  primaryclass = {cs.CL},
  title = {MedEthicEval: Evaluating Large Language Models Based on Chinese Medical Ethics},
  url = {http://arxiv.org/abs/2503.02374v1},
  year = {2025},
}

@article{chen2025survival,
  abstract = {The rapid advancement of large language models (LLMs) raises critical concerns about their ethical alignment, particularly in scenarios where human and AI co-exist under the conflict of interest. This work introduces an extendable, asymmetric, multi-agent simulation-based benchmarking framework to evaluate the moral behavior of LLMs in a novel human-AI co-existence setting featuring consistent living and critical resource management. Building on previous generative agent environments, we incorporate a life-sustaining system, where agents must compete or cooperate for food resources to survive, often leading to ethically charged decisions such as deception, theft, or social influence. We evaluated two types of LLM, DeepSeek and OpenAI series, in a three-agent setup (two humans, one LLM-powered robot), using adapted behavioral detection from the MACHIAVELLI framework and a custom survival-based ethics metric. Our findings reveal stark behavioral differences: DeepSeek frequently engages in resource hoarding, while OpenAI exhibits restraint, highlighting the influence of model design on ethical outcomes. Additionally, we demonstrate that prompt engineering can significantly steer LLM behavior, with jailbreaking prompts significantly enhancing unethical actions, even for highly restricted OpenAI models and cooperative prompts show a marked reduction in unethical actions. Our framework provides a reproducible testbed for quantifying LLM ethics in high-stakes scenarios, offering insights into their suitability for real-world human-AI interactions.},
  archiveprefix = {arXiv},
  author = {Zhihong Chen and Yiqian Yang and Jinzhao Zhou and Qiang Zhang and Chin-Teng Lin and Yiqun Duan},
  file = {2505.17937v2.pdf},
  journal = {2505.17937v2},
  month = {May},
  primaryclass = {cs.HC},
  title = {Survival Games: Human-LLM Strategic Showdowns under Severe Resource Scarcity},
  url = {http://arxiv.org/abs/2505.17937v2},
  year = {2025},
}


@article{jiao2025llms,
  abstract = {This study examines the growing use of Large Language Models (LLMs) in child-centered applications, highlighting safety and ethical concerns such as bias, harmful content, and cultural insensitivity. Despite their potential to enhance learning, there is a lack of standardized frameworks to mitigate these risks. Through a systematic literature review, we identify key parental and empirical concerns, including toxicity and ethical breaches in AI outputs. Moreover, to address these issues, this paper proposes a protection framework for safe Child-LLM interaction, incorporating metrics for content safety, behavioral ethics, and cultural sensitivity. The framework provides practical tools for evaluating LLM safety, offering guidance for developers, policymakers, and educators to ensure responsible AI deployment for children.},
  archiveprefix = {arXiv},
  author = {Junfeng Jiao and Saleh Afroogh and Kevin Chen and Abhejay Murali and David Atkinson and Amit Dhurandhar},
  file = {2502.11242v4.pdf},
  journal = {2502.11242v4},
  month = {Feb},
  primaryclass = {cs.CY},
  title = {LLMs and Childhood Safety: Identifying Risks and Proposing a Protection Framework for Safe Child-LLM Interaction},
  url = {http://arxiv.org/abs/2502.11242v4},
  year = {2025},
}

@article{hong2025towards,
  abstract = {The integration of large language models into healthcare necessitates a rigorous evaluation of their ethical reasoning, an area current benchmarks often overlook. We introduce PrinciplismQA, a comprehensive benchmark with 3,648 questions designed to systematically assess LLMs' alignment with core medical ethics. Grounded in Principlism, our benchmark features a high-quality dataset. This includes multiple-choice questions curated from authoritative textbooks and open-ended questions sourced from authoritative medical ethics case study literature, all validated by medical experts. Our experiments reveal a significant gap between models' ethical knowledge and their practical application, especially in dynamically applying ethical principles to real-world scenarios. Most LLMs struggle with dilemmas concerning Beneficence, often over-emphasizing other principles. Frontier closed-source models, driven by strong general capabilities, currently lead the benchmark. Notably, medical domain fine-tuning can enhance models' overall ethical competence, but further progress requires better alignment with medical ethical knowledge. PrinciplismQA offers a scalable framework to diagnose these specific ethical weaknesses, paving the way for more balanced and responsible medical AI.},
  archiveprefix = {arXiv},
  author = {Chang Hong and Minghao Wu and Qingying Xiao and Yuchi Wang and Xiang Wan and Guangjun Yu and Benyou Wang and Yan Hu},
  file = {2508.05132v1.pdf},
  journal = {2508.05132v1},
  month = {Aug},
  primaryclass = {cs.CL},
  title = {Towards Assessing Medical Ethics from Knowledge to Practice},
  url = {http://arxiv.org/abs/2508.05132v1},
  year = {2025},
}

@article{shao2025when,
  abstract = {This paper establishes the first comprehensive review of Large Language Models (LLMs) applied within the legal domain. It pioneers an innovative dual lens taxonomy that integrates legal reasoning frameworks and professional ontologies to systematically unify historical research and contemporary breakthroughs. Transformer-based LLMs, which exhibit emergent capabilities such as contextual reasoning and generative argumentation, surmount traditional limitations by dynamically capturing legal semantics and unifying evidence reasoning. Significant progress is documented in task generalization, reasoning formalization, workflow integration, and addressing core challenges in text processing, knowledge integration, and evaluation rigor via technical innovations like sparse attention mechanisms and mixture-of-experts architectures. However, widespread adoption of LLM introduces critical challenges: hallucination, explainability deficits, jurisdictional adaptation difficulties, and ethical asymmetry. This review proposes a novel taxonomy that maps legal roles to NLP subtasks and computationally implements the Toulmin argumentation framework, thus systematizing advances in reasoning, retrieval, prediction, and dispute resolution. It identifies key frontiers including low-resource systems, multimodal evidence integration, and dynamic rebuttal handling. Ultimately, this work provides both a technical roadmap for researchers and a conceptual framework for practitioners navigating the algorithmic future, laying a robust foundation for the next era of legal artificial intelligence. We have created a GitHub repository to index the relevant papers: https://github.com/Kilimajaro/LLMs_Meet_Law.},
  archiveprefix = {arXiv},
  author = {Peizhang Shao and Linrui Xu and Jinxi Wang and Wei Zhou and Xingyu Wu},
  file = {2507.07748v1.pdf},
  journal = {2507.07748v1},
  month = {Jul},
  primaryclass = {cs.CL},
  title = {When Large Language Models Meet Law: Dual-Lens Taxonomy, Technical Advances, and Ethical Governance},
  url = {http://arxiv.org/abs/2507.07748v1},
  year = {2025},
}

@article{scherrer2023evaluating,
  abstract = {This paper presents a case study on the design, administration, post-processing, and evaluation of surveys on large language models (LLMs). It comprises two components: (1) A statistical method for eliciting beliefs encoded in LLMs. We introduce statistical measures and evaluation metrics that quantify the probability of an LLM ""making a choice"", the associated uncertainty, and the consistency of that choice. (2) We apply this method to study what moral beliefs are encoded in different LLMs, especially in ambiguous cases where the right choice is not obvious. We design a large-scale survey comprising 680 high-ambiguity moral scenarios (e.g., ""Should I tell a white lie?"") and 687 low-ambiguity moral scenarios (e.g., ""Should I stop for a pedestrian on the road?""). Each scenario includes a description, two possible actions, and auxiliary labels indicating violated rules (e.g., ""do not kill""). We administer the survey to 28 open- and closed-source LLMs. We find that (a) in unambiguous scenarios, most models ""choose"" actions that align with commonsense. In ambiguous cases, most models express uncertainty. (b) Some models are uncertain about choosing the commonsense action because their responses are sensitive to the question-wording. (c) Some models reflect clear preferences in ambiguous scenarios. Specifically, closed-source models tend to agree with each other.},
  archiveprefix = {arXiv},
  author = {Nino Scherrer and Claudia Shi and Amir Feder and David M. Blei},
  file = {2307.14324v1.pdf},
  journal = {2307.14324v1},
  month = {Jul},
  primaryclass = {cs.CL},
  title = {Evaluating the Moral Beliefs Encoded in LLMs},
  url = {http://arxiv.org/abs/2307.14324v1},
  year = {2023},
}

@article{hendrycks2020aligning,
  abstract = {We show how to assess a language model's knowledge of basic concepts of morality. We introduce the ETHICS dataset, a new benchmark that spans concepts in justice, well-being, duties, virtues, and commonsense morality. Models predict widespread moral judgments about diverse text scenarios. This requires connecting physical and social world knowledge to value judgements, a capability that may enable us to steer chatbot outputs or eventually regularize open-ended reinforcement learning agents. With the ETHICS dataset, we find that current language models have a promising but incomplete ability to predict basic human ethical judgements. Our work shows that progress can be made on machine ethics today, and it provides a steppingstone toward AI that is aligned with human values.},
  archiveprefix = {arXiv},
  author = {Dan Hendrycks and Collin Burns and Steven Basart and Andrew Critch and Jerry Li and Dawn Song and Jacob Steinhardt},
  file = {2008.02275v6.pdf},
  journal = {2008.02275v6},
  month = {Aug},
  primaryclass = {cs.CY},
  title = {Aligning AI With Shared Human Values},
  url = {http://arxiv.org/abs/2008.02275v6},
  year = {2020},
}

@article{haltaufderheide2024the,
  abstract = {With the introduction of ChatGPT, Large Language Models (LLMs) have received enormous attention in healthcare. Despite their potential benefits, researchers have underscored various ethical implications. While individual instances have drawn much attention, the debate lacks a systematic overview of practical applications currently researched and ethical issues connected to them. Against this background, this work aims to map the ethical landscape surrounding the current stage of deployment of LLMs in medicine and healthcare. Electronic databases and preprint servers were queried using a comprehensive search strategy. Studies were screened and extracted following a modified rapid review approach. Methodological quality was assessed using a hybrid approach. For 53 records, a meta-aggregative synthesis was performed. Four fields of applications emerged and testify to a vivid exploration phase. Advantages of using LLMs are attributed to their capacity in data analysis, personalized information provisioning, support in decision-making, mitigating information loss and enhancing information accessibility. However, we also identifies recurrent ethical concerns connected to fairness, bias, non-maleficence, transparency, and privacy. A distinctive concern is the tendency to produce harmful misinformation or convincingly but inaccurate content. A recurrent plea for ethical guidance and human oversight is evident. Given the variety of use cases, it is suggested that the ethical guidance debate be reframed to focus on defining what constitutes acceptable human oversight across the spectrum of applications. This involves considering diverse settings, varying potentials for harm, and different acceptable thresholds for performance and certainty in healthcare. In addition, a critical inquiry is necessary to determine the extent to which the current experimental use of LLMs is necessary and justified.},
  archiveprefix = {arXiv},
  author = {Joschka Haltaufderheide and Robert Ranisch},
  doi = {10.1038/s41746-024-01157-x},
  file = {2403.14473v1.pdf},
  journal = {2403.14473v1},
  month = {Mar},
  primaryclass = {cs.CY},
  title = {The Ethics of ChatGPT in Medicine and Healthcare: A Systematic Review on Large Language Models (LLMs)},
  url = {http://arxiv.org/abs/2403.14473v1},
  year = {2024},
}

@article{huang2023trustgpt,
  abstract = {Large Language Models (LLMs) such as ChatGPT, have gained significant attention due to their impressive natural language processing capabilities. It is crucial to prioritize human-centered principles when utilizing these models. Safeguarding the ethical and moral compliance of LLMs is of utmost importance. However, individual ethical issues have not been well studied on the latest LLMs. Therefore, this study aims to address these gaps by introducing a new benchmark -- TrustGPT. TrustGPT provides a comprehensive evaluation of LLMs in three crucial areas: toxicity, bias, and value-alignment. Initially, TrustGPT examines toxicity in language models by employing toxic prompt templates derived from social norms. It then quantifies the extent of bias in models by measuring quantifiable toxicity values across different groups. Lastly, TrustGPT assesses the value of conversation generation models from both active value-alignment and passive value-alignment tasks. Through the implementation of TrustGPT, this research aims to enhance our understanding of the performance of conversation generation models and promote the development of language models that are more ethical and socially responsible.},
  archiveprefix = {arXiv},
  author = {Yue Huang and Qihui Zhang and Philip S. Y and Lichao Sun},
  file = {2306.11507v1.pdf},
  journal = {2306.11507v1},
  month = {Jun},
  primaryclass = {cs.CL},
  title = {TrustGPT: A Benchmark for Trustworthy and Responsible Large Language Models},
  url = {http://arxiv.org/abs/2306.11507v1},
  year = {2023},
}

@article{jiao2024navigating,
  abstract = {This study addresses ethical issues surrounding Large Language Models (LLMs) within the field of artificial intelligence. It explores the common ethical challenges posed by both LLMs and other AI systems, such as privacy and fairness, as well as ethical challenges uniquely arising from LLMs. It highlights challenges such as hallucination, verifiable accountability, and decoding censorship complexity, which are unique to LLMs and distinct from those encountered in traditional AI systems. The study underscores the need to tackle these complexities to ensure accountability, reduce biases, and enhance transparency in the influential role that LLMs play in shaping information dissemination. It proposes mitigation strategies and future directions for LLM ethics, advocating for interdisciplinary collaboration. It recommends ethical frameworks tailored to specific domains and dynamic auditing systems adapted to diverse contexts. This roadmap aims to guide responsible development and integration of LLMs, envisioning a future where ethical considerations govern AI advancements in society.},
  archiveprefix = {arXiv},
  author = {Junfeng Jiao and Saleh Afroogh and Yiming Xu and Connor Phillips},
  file = {2406.18841v5.pdf},
  journal = {2406.18841v5},
  month = {May},
  primaryclass = {cs.CY},
  title = {Navigating LLM Ethics: Advancements, Challenges, and Future Directions},
  url = {http://arxiv.org/abs/2406.18841v5},
  year = {2024},
}

@article{kumar2024the,
  abstract = {This paper comprehensively explores the ethical challenges arising from security threats to Large Language Models (LLMs). These intricate digital repositories are increasingly integrated into our daily lives, making them prime targets for attacks that can compromise their training data and the confidentiality of their data sources. The paper delves into the nuanced ethical repercussions of such security threats on society and individual privacy. We scrutinize five major threats--prompt injection, jailbreaking, Personal Identifiable Information (PII) exposure, sexually explicit content, and hate-based content--going beyond mere identification to assess their critical ethical consequences and the urgency they create for robust defensive strategies. The escalating reliance on LLMs underscores the crucial need for ensuring these systems operate within the bounds of ethical norms, particularly as their misuse can lead to significant societal and individual harm. We propose conceptualizing and developing an evaluative tool tailored for LLMs, which would serve a dual purpose: guiding developers and designers in preemptive fortification of backend systems and scrutinizing the ethical dimensions of LLM chatbot responses during the testing phase. By comparing LLM responses with those expected from humans in a moral context, we aim to discern the degree to which AI behaviors align with the ethical values held by a broader society. Ultimately, this paper not only underscores the ethical troubles presented by LLMs; it also highlights a path toward cultivating trust in these systems.},
  archiveprefix = {arXiv},
  author = {Ashutosh Kumar and Shiv Vignesh Murthy and Sagarika Singh and Swathy Ragupathy},
  file = {2401.12273v2.pdf},
  journal = {2401.12273v2},
  month = {Jan},
  primaryclass = {cs.CR},
  title = {The Ethics of Interaction: Mitigating Security Threats in LLMs},
  url = {http://arxiv.org/abs/2401.12273v2},
  year = {2024},
}

@article{hong2024decoding,
  abstract = {Compressing high-capability Large Language Models (LLMs) has emerged as a favored strategy for resource-efficient inferences. While state-of-the-art (SoTA) compression methods boast impressive advancements in preserving benign task performance, the potential risks of compression in terms of safety and trustworthiness have been largely neglected. This study conducts the first, thorough evaluation of three (3) leading LLMs using five (5) SoTA compression techniques across eight (8) trustworthiness dimensions. Our experiments highlight the intricate interplay between compression and trustworthiness, revealing some interesting patterns. We find that quantization is currently a more effective approach than pruning in achieving efficiency and trustworthiness simultaneously. For instance, a 4-bit quantized model retains the trustworthiness of its original counterpart, but model pruning significantly degrades trustworthiness, even at 50% sparsity. Moreover, employing quantization within a moderate bit range could unexpectedly improve certain trustworthiness dimensions such as ethics and fairness. Conversely, extreme quantization to very low bit levels (3 bits) tends to reduce trustworthiness significantly. This increased risk cannot be uncovered by looking at benign performance alone, in turn, mandating comprehensive trustworthiness evaluation in practice. These findings culminate in practical recommendations for simultaneously achieving high utility, efficiency, and trustworthiness in LLMs. Code and models are available at https://decoding-comp-trust.github.io.},
  archiveprefix = {arXiv},
  author = {Junyuan Hong and Jinhao Duan and Chenhui Zhang and Zhangheng Li and Chulin Xie and Kelsey Lieberman and James Diffenderfer and Brian Bartoldson and Ajay Jaiswal and Kaidi Xu and Bhavya Kailkhura and Dan Hendrycks and Dawn Song and Zhangyang Wang and Bo Li},
  file = {2403.15447v3.pdf},
  journal = {2403.15447v3},
  month = {Mar},
  primaryclass = {cs.CL},
  title = {Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression},
  url = {http://arxiv.org/abs/2403.15447v3},
  year = {2024},
}

@article{ji2024moralbench,
  abstract = {In the rapidly evolving field of artificial intelligence, large language models (LLMs) have emerged as powerful tools for a myriad of applications, from natural language processing to decision-making support systems. However, as these models become increasingly integrated into societal frameworks, the imperative to ensure they operate within ethical and moral boundaries has never been more critical. This paper introduces a novel benchmark designed to measure and compare the moral reasoning capabilities of LLMs. We present the first comprehensive dataset specifically curated to probe the moral dimensions of LLM outputs, addressing a wide range of ethical dilemmas and scenarios reflective of real-world complexities.



The main contribution of this work lies in the development of benchmark datasets and metrics for assessing the moral identity of LLMs, which accounts for nuance, contextual sensitivity, and alignment with human ethical standards. Our methodology involves a multi-faceted approach, combining quantitative analysis with qualitative insights from ethics scholars to ensure a thorough evaluation of model performance. By applying our benchmark across several leading LLMs, we uncover significant variations in moral reasoning capabilities of different models. These findings highlight the importance of considering moral reasoning in the development and evaluation of LLMs, as well as the need for ongoing research to address the biases and limitations uncovered in our study. We publicly release the benchmark at https://drive.google.com/drive/u/0/folders/1k93YZJserYc2CkqP8d4B3M3sgd3kA8W7 and also open-source the code of the project at https://github.com/agiresearch/MoralBench.},
  archiveprefix = {arXiv},
  author = {Jianchao Ji and Yutong Chen and Mingyu Jin and Wujiang Xu and Wenyue Hua and Yongfeng Zhang},
  file = {2406.04428v2.pdf},
  journal = {2406.04428v2},
  month = {Jun},
  primaryclass = {cs.CL},
  title = {MoralBench: Moral Evaluation of LLMs},
  url = {http://arxiv.org/abs/2406.04428v2},
  year = {2024},
}

@article{meadows2024localvaluebench,
  abstract = {The proliferation of large language models (LLMs) requires robust evaluation of their alignment with local values and ethical standards, especially as existing benchmarks often reflect the cultural, legal, and ideological values of their creators. \textsc{LocalValueBench}, introduced in this paper, is an extensible benchmark designed to assess LLMs' adherence to Australian values, and provides a framework for regulators worldwide to develop their own LLM benchmarks for local value alignment. Employing a novel typology for ethical reasoning and an interrogation approach, we curated comprehensive questions and utilized prompt engineering strategies to probe LLMs' value alignment. Our evaluation criteria quantified deviations from local values, ensuring a rigorous assessment process. Comparative analysis of three commercial LLMs by USA vendors revealed significant insights into their effectiveness and limitations, demonstrating the critical importance of value alignment. This study offers valuable tools and methodologies for regulators to create tailored benchmarks, highlighting avenues for future research to enhance ethical AI development.},
  archiveprefix = {arXiv},
  author = {Gwenyth Isobel Meadows and Nicholas Wai Long Lau and Eva Adelina Susanto and Chi Lok Yu and Aditya Paul},
  file = {2408.01460v1.pdf},
  journal = {2408.01460v1},
  month = {Jul},
  primaryclass = {cs.CY},
  title = {LocalValueBench: A Collaboratively Built and Extensible Benchmark for Evaluating Localized Value Alignment and Ethical Safety in Large Language Models},
  url = {http://arxiv.org/abs/2408.01460v1},
  year = {2024},
}

@article{zhang2024evaluation,
  abstract = {In recent years, the utilization of large language models for natural language dialogue has gained momentum, leading to their widespread adoption across various domains. However, their universal competence in addressing challenges specific to specialized fields such as law remains a subject of scrutiny. The incorporation of legal ethics into the model has been overlooked by researchers. We asserts that rigorous ethic evaluation is essential to ensure the effective integration of large language models in legal domains, emphasizing the need to assess domain-specific proficiency and domain-specific ethic. To address this, we propose a novelty evaluation methodology, utilizing authentic legal cases to evaluate the fundamental language abilities, specialized legal knowledge and legal robustness of large language models (LLMs). The findings from our comprehensive evaluation contribute significantly to the academic discourse surrounding the suitability and performance of large language models in legal domains.},
  archiveprefix = {arXiv},
  author = {Ruizhe Zhang and Haitao Li and Yueyue Wu and Qingyao Ai and Yiqun Liu and Min Zhang and Shaoping Ma},
  file = {2403.11152v1.pdf},
  journal = {2403.11152v1},
  month = {Mar},
  primaryclass = {cs.CL},
  title = {Evaluation Ethics of LLMs in Legal Domain},
  url = {http://arxiv.org/abs/2403.11152v1},
  year = {2024},
}

@article{cetin2025openethics,
  abstract = {Generative large language models present significant potential but also raise critical ethical concerns. Most studies focus on narrow ethical dimensions, and also limited diversity of languages and models. To address these gaps, we conduct a broad ethical evaluation of 29 recent open-source large language models using a novel data collection including four ethical aspects: Robustness, reliability, safety, and fairness. We analyze model behavior in both a commonly used language, English, and a low-resource language, Turkish. Our aim is to provide a comprehensive ethical assessment and guide safer model development by filling existing gaps in evaluation breadth, language coverage, and model diversity. Our experimental results, based on LLM-as-a-Judge, reveal that optimization efforts for many open-source models appear to have prioritized safety and fairness, and demonstrated good robustness while reliability remains a concern. We demonstrate that ethical evaluation can be effectively conducted independently of the language used. In addition, models with larger parameter counts tend to exhibit better ethical performance, with Gemma and Qwen models demonstrating the most ethical behavior among those evaluated.},
  archiveprefix = {arXiv},
  author = {Burak Erinç Çetin and Yıldırım Özen and Elif Naz Demiryılmaz and Kaan Engür and Cagri Toraman},
  file = {2505.16036v1.pdf},
  journal = {2505.16036v1},
  month = {May},
  primaryclass = {cs.CL},
  title = {OpenEthics: A Comprehensive Ethical Evaluation of Open-Source Generative Large Language Models},
  url = {http://arxiv.org/abs/2505.16036v1},
  year = {2025},
}

@article{tlaie2024exploring,
  abstract = {Large Language Models (LLMs) have become central to advancing automation and decision-making across various sectors, raising significant ethical questions. This study proposes a comprehensive comparative analysis of the most advanced LLMs to assess their moral profiles. We subjected several state-of-the-art models to a selection of ethical dilemmas and found that all the proprietary ones are mostly utilitarian and all of the open-weights ones align mostly with values-based ethics. Furthermore, when using the Moral Foundations Questionnaire, all models we probed - except for Llama 2-7B - displayed a strong liberal bias. Lastly, in order to causally intervene in one of the studied models, we propose a novel similarity-specific activation steering technique. Using this method, we were able to reliably steer the model's moral compass to different ethical schools. All of these results showcase that there is an ethical dimension in already deployed LLMs, an aspect that is generally overlooked.},
  archiveprefix = {arXiv},
  author = {Alejandro Tlaie},
  file = {2405.17345v2.pdf},
  journal = {2405.17345v2},
  month = {May},
  primaryclass = {cs.AI},
  title = {Exploring and steering the moral compass of Large Language Models},
  url = {http://arxiv.org/abs/2405.17345v2},
  year = {2024},
}

@article{yu2024cmoraleval,
  abstract = {What a large language model (LLM) would respond in ethically relevant context? In this paper, we curate a large benchmark CMoralEval for morality evaluation of Chinese LLMs. The data sources of CMoralEval are two-fold: 1) a Chinese TV program discussing Chinese moral norms with stories from the society and 2) a collection of Chinese moral anomies from various newspapers and academic papers on morality. With these sources, we aim to create a moral evaluation dataset characterized by diversity and authenticity. We develop a morality taxonomy and a set of fundamental moral principles that are not only rooted in traditional Chinese culture but also consistent with contemporary societal norms. To facilitate efficient construction and annotation of instances in CMoralEval, we establish a platform with AI-assisted instance generation to streamline the annotation process. These help us curate CMoralEval that encompasses both explicit moral scenarios (14,964 instances) and moral dilemma scenarios (15,424 instances), each with instances from different data sources. We conduct extensive experiments with CMoralEval to examine a variety of Chinese LLMs. Experiment results demonstrate that CMoralEval is a challenging benchmark for Chinese LLMs. The dataset is publicly available at \url{https://github.com/tjunlp-lab/CMoralEval}.},
  archiveprefix = {arXiv},
  author = {Linhao Yu and Yongqi Leng and Yufei Huang and Shang Wu and Haixin Liu and Xinmeng Ji and Jiahui Zhao and Jinwang Song and Tingting Cui and Xiaoqing Cheng and Tao Liu and Deyi Xiong},
  file = {2408.09819v1.pdf},
  journal = {2408.09819v1},
  month = {Aug},
  primaryclass = {cs.CL},
  title = {CMoralEval: A Moral Evaluation Benchmark for Chinese Large Language Models},
  url = {http://arxiv.org/abs/2408.09819v1},
  year = {2024},
}

@article{kaneko2024eagle,
  abstract = {Recent studies have demonstrated that large language models (LLMs) have ethical-related problems such as social biases, lack of moral reasoning, and generation of offensive content. The existing evaluation metrics and methods to address these ethical challenges use datasets intentionally created by instructing humans to create instances including ethical problems. Therefore, the data does not reflect prompts that users actually provide when utilizing LLM services in everyday contexts. This may not lead to the development of safe LLMs that can address ethical challenges arising in real-world applications. In this paper, we create Eagle datasets extracted from real interactions between ChatGPT and users that exhibit social biases, toxicity, and immoral problems. Our experiments show that Eagle captures complementary aspects, not covered by existing datasets proposed for evaluation and mitigation of such ethical challenges. Our code is publicly available at https://huggingface.co/datasets/MasahiroKaneko/eagle.},
  archiveprefix = {arXiv},
  author = {Masahiro Kaneko and Danushka Bollegala and Timothy Baldwin},
  file = {2402.14258v1.pdf},
  journal = {2402.14258v1},
  month = {Feb},
  primaryclass = {cs.CL},
  title = {Eagle: Ethical Dataset Given from Real Interactions},
  url = {http://arxiv.org/abs/2402.14258v1},
  year = {2024},
}

@article{agarwal2024ethical,
  abstract = {Ethical reasoning is a crucial skill for Large Language Models (LLMs). However, moral values are not universal, but rather influenced by language and culture. This paper explores how three prominent LLMs -- GPT-4, ChatGPT, and Llama2-70B-Chat -- perform ethical reasoning in different languages and if their moral judgement depend on the language in which they are prompted. We extend the study of ethical reasoning of LLMs by Rao et al. (2023) to a multilingual setup following their framework of probing LLMs with ethical dilemmas and policies from three branches of normative ethics: deontology, virtue, and consequentialism. We experiment with six languages: English, Spanish, Russian, Chinese, Hindi, and Swahili. We find that GPT-4 is the most consistent and unbiased ethical reasoner across languages, while ChatGPT and Llama2-70B-Chat show significant moral value bias when we move to languages other than English. Interestingly, the nature of this bias significantly vary across languages for all LLMs, including GPT-4.},
  archiveprefix = {arXiv},
  author = {Utkarsh Agarwal and Kumar Tanmay and Aditi Khandelwal and Monojit Choudhury},
  file = {2404.18460v1.pdf},
  journal = {2404.18460v1},
  month = {Apr},
  primaryclass = {cs.CL},
  title = {Ethical Reasoning and Moral Value Alignment of LLMs Depend on the Language we Prompt them in},
  url = {http://arxiv.org/abs/2404.18460v1},
  year = {2024},
}

@article{wei2025medethicsqa,
  abstract = {While Medical Large Language Models (MedLLMs) have demonstrated remarkable potential in clinical tasks, their ethical safety remains insufficiently explored. This paper introduces $\textbf{MedEthicsQA}$, a comprehensive benchmark comprising $\textbf{5,623}$ multiple-choice questions and $\textbf{5,351}$ open-ended questions for evaluation of medical ethics in LLMs. We systematically establish a hierarchical taxonomy integrating global medical ethical standards. The benchmark encompasses widely used medical datasets, authoritative question banks, and scenarios derived from PubMed literature. Rigorous quality control involving multi-stage filtering and multi-faceted expert validation ensures the reliability of the dataset with a low error rate ($2.72\%$). Evaluation of state-of-the-art MedLLMs exhibit declined performance in answering medical ethics questions compared to their foundation counterparts, elucidating the deficiencies of medical ethics alignment. The dataset, registered under CC BY-NC 4.0 license, is available at https://github.com/JianhuiWei7/MedEthicsQA.},
  archiveprefix = {arXiv},
  author = {Jianhui Wei and Zijie Meng and Zikai Xiao and Tianxiang Hu and Yang Feng and Zhijie Zhou and Jian Wu and Zuozhu Liu},
  file = {2506.22808v1.pdf},
  journal = {2506.22808v1},
  month = {Jun},
  primaryclass = {cs.CL},
  title = {MedEthicsQA: A Comprehensive Question Answering Benchmark for Medical Ethics Evaluation of LLMs},
  url = {http://arxiv.org/abs/2506.22808v1},
  year = {2025},
}

@article{bhatia2024swan,
  abstract = {We introduce {\bf Swan}, a family of embedding models centred around the Arabic language, addressing both small-scale and large-scale use cases. Swan includes two variants: Swan-Small, based on ARBERTv2, and Swan-Large, built on ArMistral, a pretrained Arabic large language model. To evaluate these models, we propose ArabicMTEB, a comprehensive benchmark suite that assesses cross-lingual, multi-dialectal, multi-domain, and multi-cultural Arabic text embedding performance, covering eight diverse tasks and spanning 94 datasets. Swan-Large achieves state-of-the-art results, outperforming Multilingual-E5-large in most Arabic tasks, while the Swan-Small consistently surpasses Multilingual-E5-base. Our extensive evaluations demonstrate that Swan models are both dialectally and culturally aware, excelling across various Arabic domains while offering significant monetary efficiency. This work significantly advances the field of Arabic language modelling and provides valuable resources for future research and applications in Arabic natural language processing. Our models and benchmark will be made publicly accessible for research.},
  archiveprefix = {arXiv},
  author = {Gagan Bhatia and El Moatez Billah Nagoudi and Abdellah El Mekki and Fakhraddin Alwajih and Muhammad Abdul-Mageed},
  file = {2411.01192v2.pdf},
  journal = {2411.01192v2},
  month = {Nov},
  primaryclass = {cs.CL},
  title = {Swan and ArabicMTEB: Dialect-Aware, Arabic-Centric, Cross-Lingual, and Cross-Cultural Embedding Models and Benchmarks},
  url = {http://arxiv.org/abs/2411.01192v2},
  year = {2024},
}

@article{elsafoury2025out,
  abstract = {We know that language models (LMs) form biases and stereotypes of minorities, leading to unfair treatments of members of these groups, thanks to research mainly in the US and the broader English-speaking world. As the negative behavior of these models has severe consequences for society and individuals, industry and academia are actively developing methods to reduce the bias in LMs. However, there are many under-represented groups and languages that have been overlooked so far. This includes marginalized groups that are specific to individual countries and regions in the English speaking and Western world, but crucially also almost all marginalized groups in the rest of the world. The UN estimates, that between 600 million to 1.2 billion people worldwide are members of marginalized groups and in need for special protection. If we want to develop inclusive LMs that work for everyone, we have to broaden our understanding to include overlooked marginalized groups and low-resource languages and dialects.



In this work, we contribute to this effort with the first study investigating offensive stereotyping bias in 23 LMs for 270 marginalized groups from Egypt, the remaining 21 Arab countries, Germany, the UK, and the US. Additionally, we investigate the impact of low-resource languages and dialects on the study of bias in LMs, demonstrating the limitations of current bias metrics, as we measure significantly higher bias when using the Egyptian Arabic dialect versus Modern Standard Arabic. Our results show, LMs indeed show higher bias against many marginalized groups in comparison to dominant groups. However, this is not the case for Arabic LMs, where the bias is high against both marginalized and dominant groups in relation to religion and ethnicity.



Our results also show higher intersectional bias against Non-binary, LGBTQIA+ and Black women.},
  archiveprefix = {arXiv},
  author = {Fatma Elsafoury and David Hartmann},
  file = {2504.12767v1.pdf},
  journal = {2504.12767v1},
  month = {Apr},
  primaryclass = {cs.CL},
  title = {Out of Sight Out of Mind, Out of Sight Out of Mind: Measuring Bias in Language Models Against Overlooked Marginalized Groups in Regional Contexts},
  url = {http://arxiv.org/abs/2504.12767v1},
  year = {2025},
}

@article{naous2025on,
  abstract = {Language Models (LMs) have been shown to exhibit a strong preference towards entities associated with Western culture when operating in non-Western languages. In this paper, we aim to uncover the origins of entity-related cultural biases in LMs by analyzing several contributing factors, including the representation of entities in pre-training data and the impact of variations in linguistic phenomena across languages. We introduce CAMeL-2, a parallel Arabic-English benchmark of 58,086 entities associated with Arab and Western cultures and 367 masked natural contexts for entities. Our evaluations using CAMeL-2 reveal reduced performance gaps between cultures by LMs when tested in English compared to Arabic. We find that LMs struggle in Arabic with entities that appear at high frequencies in pre-training, where entities can hold multiple word senses. This also extends to entities that exhibit high lexical overlap with languages that are not Arabic but use the Arabic script. Further, we show how frequency-based tokenization leads to this issue in LMs, which gets worse with larger Arabic vocabularies. We will make CAMeL-2 available at: https://github.com/tareknaous/camel2},
  archiveprefix = {arXiv},
  author = {Tarek Naous and Wei Xu},
  file = {2501.04662v1.pdf},
  journal = {2501.04662v1},
  month = {Jan},
  primaryclass = {cs.CL},
  title = {On The Origin of Cultural Biases in Language Models: From Pre-training Data to Linguistic Phenomena},
  url = {http://arxiv.org/abs/2501.04662v1},
  year = {2025},
}

@article{naous2023having,
  abstract = {As the reach of large language models (LMs) expands globally, their ability to cater to diverse cultural contexts becomes crucial. Despite advancements in multilingual capabilities, models are not designed with appropriate cultural nuances. In this paper, we show that multilingual and Arabic monolingual LMs exhibit bias towards entities associated with Western culture. We introduce CAMeL, a novel resource of 628 naturally-occurring prompts and 20,368 entities spanning eight types that contrast Arab and Western cultures. CAMeL provides a foundation for measuring cultural biases in LMs through both extrinsic and intrinsic evaluations. Using CAMeL, we examine the cross-cultural performance in Arabic of 16 different LMs on tasks such as story generation, NER, and sentiment analysis, where we find concerning cases of stereotyping and cultural unfairness. We further test their text-infilling performance, revealing the incapability of appropriate adaptation to Arab cultural contexts. Finally, we analyze 6 Arabic pre-training corpora and find that commonly used sources such as Wikipedia may not be best suited to build culturally aware LMs, if used as they are without adjustment. We will make CAMeL publicly available at: https://github.com/tareknaous/camel},
  archiveprefix = {arXiv},
  author = {Tarek Naous and Michael J. Ryan and Alan Ritter and Wei Xu},
  file = {2305.14456v4.pdf},
  journal = {2305.14456v4},
  month = {May},
  primaryclass = {cs.CL},
  title = {Having Beer after Prayer? Measuring Cultural Bias in Large Language Models},
  url = {http://arxiv.org/abs/2305.14456v4},
  year = {2023},
}

@article{prakash2024interpreting,
  abstract = {Large Language Models (LLMs) such as Mistral and LLaMA have showcased remarkable performance across various natural language processing (NLP) tasks. Despite their success, these models inherit social biases from the diverse datasets on which they are trained. This paper investigates the propagation of biases within LLMs through a novel feature-based analytical approach. Drawing inspiration from causal mediation analysis, we hypothesize the evolution of bias-related features and validate them using interpretability techniques like activation and attribution patching. Our contributions are threefold: (1) We introduce and empirically validate a feature-based method for bias analysis in LLMs, applied to LLaMA-2-7B, LLaMA-3-8B, and Mistral-7B-v0.3 with templates from a professions dataset. (2) We extend our method to another form of gender bias, demonstrating its generalizability. (3) We differentiate the roles of MLPs and attention heads in bias propagation and implement targeted debiasing using a counterfactual dataset. Our findings reveal the complex nature of bias in LLMs and emphasize the necessity for tailored debiasing strategies, offering a deeper understanding of bias mechanisms and pathways for effective mitigation.},
  archiveprefix = {arXiv},
  author = {Nirmalendu Prakash and Lee Ka Wei Roy},
  file = {2406.12347v1.pdf},
  journal = {2406.12347v1},
  month = {Jun},
  primaryclass = {cs.CL},
  title = {Interpreting Bias in Large Language Models: A Feature-Based Approach},
  url = {http://arxiv.org/abs/2406.12347v1},
  year = {2024},
}

@article{sun2025idiosyncrasies,
  abstract = {In this work, we unveil and study idiosyncrasies in Large Language Models (LLMs) -- unique patterns in their outputs that can be used to distinguish the models. To do so, we consider a simple classification task: given a particular text output, the objective is to predict the source LLM that generates the text. We evaluate this synthetic task across various groups of LLMs and find that simply fine-tuning text embedding models on LLM-generated texts yields excellent classification accuracy. Notably, we achieve 97.1% accuracy on held-out validation data in the five-way classification problem involving ChatGPT, Claude, Grok, Gemini, and DeepSeek. Our further investigation reveals that these idiosyncrasies are rooted in word-level distributions. These patterns persist even when the texts are rewritten, translated, or summarized by an external LLM, suggesting that they are also encoded in the semantic content. Additionally, we leverage LLM as judges to generate detailed, open-ended descriptions of each model's idiosyncrasies. Finally, we discuss the broader implications of our findings, including training on synthetic data, inferring model similarity, and robust evaluation of LLMs. Code is available at https://github.com/locuslab/llm-idiosyncrasies.},
  archiveprefix = {arXiv},
  author = {Mingjie Sun and Yida Yin and Zhiqiu Xu and J. Zico Kolter and Zhuang Liu},
  file = {2502.12150v2.pdf},
  journal = {2502.12150v2},
  month = {Feb},
  primaryclass = {cs.CL},
  title = {Idiosyncrasies in Large Language Models},
  url = {http://arxiv.org/abs/2502.12150v2},
  year = {2025},
}

@article{asseri2025prompt,
  abstract = {Large language models have demonstrated remarkable capabilities across various domains, yet concerns about cultural bias - particularly towards Arabs and Muslims - pose significant ethical challenges by perpetuating harmful stereotypes and marginalization. Despite growing recognition of bias in LLMs, prompt engineering strategies specifically addressing Arab and Muslim representation remain understudied. This mixed-methods systematic review examines such techniques, offering evidence-based guidance for researchers and practitioners. Following PRISMA guidelines and Kitchenham's systematic review methodology, we analyzed 8 empirical studies published between 2021-2024 investigating bias mitigation strategies. Our findings reveal five primary prompt engineering approaches: cultural prompting, affective priming, self-debiasing techniques, structured multi-step pipelines, and parameter-optimized continuous prompts. Although all approaches show potential for reducing bias, effectiveness varied substantially across studies and bias types. Evidence suggests that certain bias types may be more resistant to prompt-based mitigation than others. Structured multi-step pipelines demonstrated the highest overall effectiveness, achieving up to 87.7% reduction in bias, though they require greater technical expertise. Cultural prompting offers broader accessibility with substantial effectiveness. These results underscore the accessibility of prompt engineering for mitigating cultural bias without requiring access to model parameters. The limited number of studies identified highlights a significant research gap in this critical area. Future research should focus on developing culturally adaptive prompting techniques, creating Arab and Muslim-specific evaluation resources, and integrating prompt engineering with complementary debiasing methods to address deeper stereotypes while maintaining model utility.},
  archiveprefix = {arXiv},
  author = {Bushra Asseri and Estabrag Abdelaziz and Areej Al-Wabil},
  file = {2506.18199v2.pdf},
  journal = {2506.18199v2},
  month = {Jun},
  primaryclass = {cs.CL},
  title = {Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models: A Systematic Review},
  url = {http://arxiv.org/abs/2506.18199v2},
  year = {2025},
}

@article{yu2025entangled,
  abstract = {The growing deployment of large language models (LLMs) across diverse cultural contexts necessitates a better understanding of how the overgeneralization of less documented cultures within LLMs' representations impacts their cultural understanding. Prior work only performs extrinsic evaluation of LLMs' cultural competence, without accounting for how LLMs' internal mechanisms lead to cultural (mis)representation. To bridge this gap, we propose Culturescope, the first mechanistic interpretability-based method that probes the internal representations of LLMs to elicit the underlying cultural knowledge space. CultureScope utilizes a patching method to extract the cultural knowledge. We introduce a cultural flattening score as a measure of the intrinsic cultural biases. Additionally, we study how LLMs internalize Western-dominance bias and cultural flattening, which allows us to trace how cultural biases emerge within LLMs. Our experimental results reveal that LLMs encode Western-dominance bias and cultural flattening in their cultural knowledge space. We find that low-resource cultures are less susceptible to cultural biases, likely due to their limited training resources. Our work provides a foundation for future research on mitigating cultural biases and enhancing LLMs' cultural understanding. Our codes and data used for experiments are publicly available.},
  archiveprefix = {arXiv},
  author = {Haeun Yu and Seogyeong Jeong and Siddhesh Pawar and Jisu Shin and Jiho Jin and Junho Myung and Alice Oh and Isabelle Augenstein},
  file = {2508.08879v1.pdf},
  journal = {2508.08879v1},
  month = {Aug},
  primaryclass = {cs.CL},
  title = {Entangled in Representations: Mechanistic Investigation of Cultural Biases in Large Language Models},
  url = {http://arxiv.org/abs/2508.08879v1},
  year = {2025},
}

@article{chandna2025dissecting,
  abstract = {Large Language Models (LLMs) are known to exhibit social, demographic, and gender biases, often as a consequence of the data on which they are trained. In this work, we adopt a mechanistic interpretability approach to analyze how such biases are structurally represented within models such as GPT-2 and Llama2. Focusing on demographic and gender biases, we explore different metrics to identify the internal edges responsible for biased behavior. We then assess the stability, localization, and generalizability of these components across dataset and linguistic variations. Through systematic ablations, we demonstrate that bias-related computations are highly localized, often concentrated in a small subset of layers. Moreover, the identified components change across fine-tuning settings, including those unrelated to bias. Finally, we show that removing these components not only reduces biased outputs but also affects other NLP tasks, such as named entity recognition and linguistic acceptability judgment because of the sharing of important components with these tasks.},
  archiveprefix = {arXiv},
  author = {Bhavik Chandna and Zubair Bashir and Procheta Sen},
  file = {2506.05166v2.pdf},
  journal = {2506.05166v2},
  month = {Jun},
  primaryclass = {cs.CL},
  title = {Dissecting Bias in LLMs: A Mechanistic Interpretability Perspective},
  url = {http://arxiv.org/abs/2506.05166v2},
  year = {2025},
}

@article{li2025analyzing,
  abstract = {Large Language Models (LLMs) have become integral to daily life, widely adopted in communication, decision-making, and information retrieval, raising critical questions about how these systems implicitly form and express socio-cognitive attitudes or ""worldviews"". While existing research extensively addresses demographic and ethical biases, broader dimensions-such as attitudes toward authority, equality, autonomy, and fate-remain under-explored. In this paper, we introduce the Social Worldview Taxonomy (SWT), a structured framework grounded in Cultural Theory, operationalizing four canonical worldviews (Hierarchy, Egalitarianism, Individualism, Fatalism) into measurable sub-dimensions. Using SWT, we empirically identify distinct and interpretable cognitive profiles across 28 diverse LLMs. Further, inspired by Social Referencing Theory, we experimentally demonstrate that explicit social cues systematically shape these cognitive attitudes, revealing both general response patterns and nuanced model-specific variations. Our findings enhance the interpretability of LLMs by revealing implicit socio-cognitive biases and their responsiveness to social feedback, thus guiding the development of more transparent and socially responsible language technologies.},
  archiveprefix = {arXiv},
  author = {Jiatao Li and Yanheng Li and Xiaojun Wan},
  file = {2505.01967v1.pdf},
  journal = {2505.01967v1},
  month = {May},
  primaryclass = {cs.CL},
  title = {Analyzing Cognitive Differences Among Large Language Models through the Lens of Social Worldview},
  url = {http://arxiv.org/abs/2505.01967v1},
  year = {2025},
}

@article{khalila2025investigating,
  abstract = {Accurate and contextually faithful responses are critical when applying large language models (LLMs) to sensitive and domain-specific tasks, such as answering queries related to quranic studies. General-purpose LLMs often struggle with hallucinations, where generated responses deviate from authoritative sources, raising concerns about their reliability in religious contexts. This challenge highlights the need for systems that can integrate domain-specific knowledge while maintaining response accuracy, relevance, and faithfulness. In this study, we investigate 13 open-source LLMs categorized into large (e.g., Llama3:70b, Gemma2:27b, QwQ:32b), medium (e.g., Gemma2:9b, Llama3:8b), and small (e.g., Llama3.2:3b, Phi3:3.8b). A Retrieval-Augmented Generation (RAG) is used to make up for the problems that come with using separate models. This research utilizes a descriptive dataset of Quranic surahs including the meanings, historical context, and qualities of the 114 surahs, allowing the model to gather relevant knowledge before responding. The models are evaluated using three key metrics set by human evaluators: context relevance, answer faithfulness, and answer relevance. The findings reveal that large models consistently outperform smaller models in capturing query semantics and producing accurate, contextually grounded responses. The Llama3.2:3b model, even though it is considered small, does very well on faithfulness (4.619) and relevance (4.857), showing the promise of smaller architectures that have been well optimized. This article examines the trade-offs between model size, computational efficiency, and response quality while using LLMs in domain-specific applications.},
  archiveprefix = {arXiv},
  author = {Zahra Khalila and Arbi Haza Nasution and Winda Monika and Aytug Onan and Yohei Murakami and Yasir Bin Ismail Radi and Noor Mohammad Osmani},
  doi = {10.14569/IJACSA.2025.01602134},
  file = {2503.16581v1.pdf},
  journal = {2503.16581v1},
  month = {Mar},
  note = {International Journal of Advanced Computer Science and Applications(IJACSA), 16(2), 2025},
  primaryclass = {cs.CL},
  title = {Investigating Retrieval-Augmented Generation in Quranic Studies: A Study of 13 Open-Source Large Language Models},
  url = {http://arxiv.org/abs/2503.16581v1},
  year = {2025},
}

@article{shankar2025sometimes,
  abstract = {Large Language Models (LLMs) are capable of generating opinions and propagating bias unknowingly, originating from unrepresentative and non-diverse data collection. Prior research has analysed these opinions with respect to the West, particularly the United States. However, insights thus produced may not be generalized in non-Western populations. With the widespread usage of LLM systems by users across several different walks of life, the cultural sensitivity of each generated output is of crucial interest. Our work proposes a novel method that quantitatively analyzes the opinions generated by LLMs, improving on previous work with regards to extracting the social demographics of the models. Our method measures the distance from an LLM's response to survey respondents, through Hamming Distance, to infer the demographic characteristics reflected in the model's outputs. We evaluate modern, open LLMs such as Llama and Mistral on surveys conducted in various global south countries, with a focus on India and other Asian nations, specifically assessing the model's performance on surveys related to religious tolerance and identity. Our analysis reveals that most open LLMs match a single homogeneous profile, varying across different countries/territories, which in turn raises questions about the risks of LLMs promoting a hegemonic worldview, and undermining perspectives of different minorities. Our framework may also be useful for future research investigating the complex intersection between training data, model architecture, and the resulting biases reflected in LLM outputs, particularly concerning sensitive topics like religious tolerance and identity.},
  archiveprefix = {arXiv},
  author = {Hari Shankar and Vedanta S P and Tejas Cavale and Ponnurangam Kumaraguru and Abhijnan Chakraborty},
  file = {2503.07510v1.pdf},
  journal = {2503.07510v1},
  month = {Mar},
  primaryclass = {cs.CY},
  title = {Sometimes the Model doth Preach: Quantifying Religious Bias in Open LLMs through Demographic Analysis in Asian Nations},
  url = {http://arxiv.org/abs/2503.07510v1},
  year = {2025},
}



@article{sadhu2024social,
  abstract = {The rapid growth of Large Language Models (LLMs) has put forward the study of biases as a crucial field. It is important to assess the influence of different types of biases embedded in LLMs to ensure fair use in sensitive fields. Although there have been extensive works on bias assessment in English, such efforts are rare and scarce for a major language like Bangla. In this work, we examine two types of social biases in LLM generated outputs for Bangla language. Our main contributions in this work are: (1) bias studies on two different social biases for Bangla, (2) a curated dataset for bias measurement benchmarking and (3) testing two different probing techniques for bias detection in the context of Bangla. This is the first work of such kind involving bias assessment of LLMs for Bangla to the best of our knowledge. All our code and resources are publicly available for the progress of bias related research in Bangla NLP.},
  archiveprefix = {arXiv},
  author = {Jayanta Sadhu and Maneesha Rani Saha and Rifat Shahriyar},
  file = {2407.03536v3.pdf},
  journal = {2407.03536v3},
  month = {Jul},
  primaryclass = {cs.CL},
  title = {Social Bias in Large Language Models For Bangla: An Empirical Study on Gender and Religious Bias},
  url = {http://arxiv.org/abs/2407.03536v3},
  year = {2024},
}

@article{patel2023building,
  abstract = {Large Language Models (LLMs) have demonstrated remarkable performance across numerous natural language understanding use cases. However, this impressive performance comes with inherent limitations, such as the tendency to perpetuate stereotypical biases or fabricate non-existent facts. In the context of Islam and its representation, accurate and factual representation of its beliefs and teachings rooted in the Quran and Sunnah is key. This work focuses on the challenge of building domain-specific LLMs faithful to the Islamic worldview and proposes ways to build and evaluate such systems. Firstly, we define this open-ended goal as a technical problem and propose various solutions. Subsequently, we critically examine known challenges inherent to each approach and highlight evaluation methodologies that can be used to assess such systems. This work highlights the need for high-quality datasets, evaluations, and interdisciplinary work blending machine learning with Islamic scholarship.},
  archiveprefix = {arXiv},
  author = {Shabaz Patel and Hassan Kane and Rayhan Patel},
  file = {2312.06652v1.pdf},
  journal = {2312.06652v1},
  month = {Dec},
  primaryclass = {cs.AI},
  title = {Building Domain-Specific LLMs Faithful To The Islamic Worldview: Mirage or Technical Possibility?},
  url = {http://arxiv.org/abs/2312.06652v1},
  year = {2023},
}

@article{arif2024with,
  abstract = {This paper presents a systematic analysis of biases in open-source Large Language Models (LLMs), across gender, religion, and race. Our study evaluates bias in smaller-scale Llama and Gemma models using the SALT ($\textbf{S}$ocial $\textbf{A}$ppropriateness in $\textbf{L}$LM-Generated $\textbf{T}$ext) dataset, which incorporates five distinct bias triggers: General Debate, Positioned Debate, Career Advice, Problem Solving, and CV Generation. To quantify bias, we measure win rates in General Debate and the assignment of negative roles in Positioned Debate. For real-world use cases, such as Career Advice, Problem Solving, and CV Generation, we anonymize the outputs to remove explicit demographic identifiers and use DeepSeek-R1 as an automated evaluator. We also address inherent biases in LLM-based evaluation, including evaluation bias, positional bias, and length bias, and validate our results through human evaluations. Our findings reveal consistent polarization across models, with certain demographic groups receiving systematically favorable or unfavorable treatment. By introducing SALT, we provide a comprehensive benchmark for bias analysis and underscore the need for robust bias mitigation strategies in the development of equitable AI systems.},
  archiveprefix = {arXiv},
  author = {Samee Arif and Zohaib Khan and Maaidah Kaleem and Suhaib Rashid and Agha Ali Raza and Awais Athar},
  file = {2410.12499v2.pdf},
  journal = {2410.12499v2},
  month = {Oct},
  primaryclass = {cs.CL},
  title = {With a Grain of SALT: Are LLMs Fair Across Social Dimensions?},
  url = {http://arxiv.org/abs/2410.12499v2},
  year = {2024},
}

@article{seth2025how,
  abstract = {Representational bias in large language models (LLMs) has predominantly been measured through single-response interactions and has focused on Global North-centric identities like race and gender. We expand on that research by conducting a systematic audit of GPT-4 Turbo to reveal how deeply encoded representational biases are and how they extend to less-explored dimensions of identity. We prompt GPT-4 Turbo to generate over 7,200 stories about significant life events (such as weddings) in India, using prompts designed to encourage diversity to varying extents. Comparing the diversity of religious and caste representation in the outputs against the actual population distribution in India as recorded in census data, we quantify the presence and ""stickiness"" of representational bias in the LLM for religion and caste. We find that GPT-4 responses consistently overrepresent culturally dominant groups far beyond their statistical representation, despite prompts intended to encourage representational diversity. Our findings also suggest that representational bias in LLMs has a winner-take-all quality that is more biased than the likely distribution bias in their training data, and repeated prompt-based nudges have limited and inconsistent efficacy in dislodging these biases. These results suggest that diversifying training data alone may not be sufficient to correct LLM bias, highlighting the need for more fundamental changes in model development. Dataset and Codebook: https://github.com/agrimaseth/How-Deep-Is-Representational-Bias-in-LLMs},
  archiveprefix = {arXiv},
  author = {Agrima Seth and Monojit Choudhary and Sunayana Sitaram and Kentaro Toyama and Aditya Vashistha and Kalika Bali},
  file = {2508.03712v1.pdf},
  journal = {2508.03712v1},
  month = {Jul},
  primaryclass = {cs.CL},
  title = {How Deep Is Representational Bias in LLMs? The Cases of Caste and Religion},
  url = {http://arxiv.org/abs/2508.03712v1},
  year = {2025},
}

@article{simbeck2025mechanistic,
  abstract = {Despite growing research on bias in large language models (LLMs), most work has focused on gender and race, with little attention to religious identity. This paper explores how religion is internally represented in LLMs and how it intersects with concepts of violence and geography. Using mechanistic interpretability and Sparse Autoencoders (SAEs) via the Neuronpedia API, we analyze latent feature activations across five models. We measure overlap between religion- and violence-related prompts and probe semantic patterns in activation contexts. While all five religions show comparable internal cohesion, Islam is more frequently linked to features associated with violent language. In contrast, geographic associations largely reflect real-world religious demographics, revealing how models embed both factual distributions and cultural stereotypes. These findings highlight the value of structural analysis in auditing not just outputs but also internal representations that shape model behavior.},
  archiveprefix = {arXiv},
  author = {Katharina Simbeck and Mariam Mahran},
  file = {2509.17665v1.pdf},
  journal = {2509.17665v1},
  month = {Sep},
  primaryclass = {cs.LG},
  title = {Mechanistic Interpretability with SAEs: Probing Religion, Violence, and Geography in Large Language Models},
  url = {http://arxiv.org/abs/2509.17665v1},
  year = {2025},
}

@article{rao2025invisible,
  abstract = {Artificial Intelligence (AI) is increasingly used in hiring, with large language models (LLMs) having the potential to influence or even make hiring decisions. However, this raises pressing concerns about bias, fairness, and trust, particularly across diverse cultural contexts. Despite their growing role, few studies have systematically examined the potential biases in AI-driven hiring evaluation across cultures. In this study, we conduct a systematic analysis of how LLMs assess job interviews across cultural and identity dimensions. Using two datasets of interview transcripts, 100 from UK and 100 from Indian job seekers, we first examine cross-cultural differences in LLM-generated scores for hirability and related traits. Indian transcripts receive consistently lower scores than UK transcripts, even when they were anonymized, with disparities linked to linguistic features such as sentence complexity and lexical diversity. We then perform controlled identity substitutions (varying names by gender, caste, and region) within the Indian dataset to test for name-based bias. These substitutions do not yield statistically significant effects, indicating that names alone, when isolated from other contextual signals, may not influence LLM evaluations. Our findings underscore the importance of evaluating both linguistic and social dimensions in LLM-driven evaluations and highlight the need for culturally sensitive design and accountability in AI-assisted hiring.},
  archiveprefix = {arXiv},
  author = {Pooja S. B. Rao and Laxminarayen Nagarajan Venkatesan and Mauro Cherubini and Dinesh Babu Jayagopi},
  file = {2508.16673v1.pdf},
  journal = {2508.16673v1},
  month = {Aug},
  primaryclass = {cs.CY},
  title = {Invisible Filters: Cultural Bias in Hiring Evaluations Using Large Language Models},
  url = {http://arxiv.org/abs/2508.16673v1},
  year = {2025},
}

@article{tang2023what,
  abstract = {Do large language models (LLMs) exhibit sociodemographic biases, even when they decline to respond? To bypass their refusal to ""speak,"" we study this research question by probing contextualized embeddings and exploring whether this bias is encoded in its latent representations. We propose a logistic Bradley-Terry probe which predicts word pair preferences of LLMs from the words' hidden vectors. We first validate our probe on three pair preference tasks and thirteen LLMs, where we outperform the word embedding association test (WEAT), a standard approach in testing for implicit association, by a relative 27% in error rate. We also find that word pair preferences are best represented in the middle layers. Next, we transfer probes trained on harmless tasks (e.g., pick the larger number) to controversial ones (compare ethnicities) to examine biases in nationality, politics, religion, and gender. We observe substantial bias for all target classes: for instance, the Mistral model implicitly prefers Europe to Africa, Christianity to Judaism, and left-wing to right-wing politics, despite declining to answer. This suggests that instruction fine-tuning does not necessarily debias contextualized embeddings. Our codebase is at https://github.com/castorini/biasprobe.},
  archiveprefix = {arXiv},
  author = {Raphael Tang and Xinyu Zhang and Jimmy Lin and Ferhan Ture},
  file = {2311.18812v1.pdf},
  journal = {2311.18812v1},
  month = {Nov},
  primaryclass = {cs.CL},
  title = {What Do Llamas Really Think? Revealing Preference Biases in Language Model Representations},
  url = {http://arxiv.org/abs/2311.18812v1},
  year = {2023},
}

@article{wang2025measuring,
  abstract = {Large language models (LLMs) are widely applied across diverse domains, raising concerns about their limitations and potential risks. In this study, we investigate two types of bias that LLMs may display: stereotype bias and deviation bias. Stereotype bias refers to when LLMs consistently associate specific traits with a particular demographic group. Deviation bias reflects the disparity between the demographic distributions extracted from LLM-generated content and real-world demographic distributions. By asking four advanced LLMs to generate profiles of individuals, we examine the associations between each demographic group and attributes such as political affiliation, religion, and sexual orientation. Our experimental results show that all examined LLMs exhibit both significant stereotype bias and deviation bias towards multiple groups. Our findings uncover the biases that occur when LLMs infer user attributes and shed light on the potential harms of LLM-generated outputs.},
  archiveprefix = {arXiv},
  author = {Daniel Wang and Eli Brignac and Minjia Mao and Xiao Fang},
  file = {2508.06649v2.pdf},
  journal = {2508.06649v2},
  month = {Aug},
  primaryclass = {cs.CL},
  title = {Measuring Stereotype and Deviation Biases in Large Language Models},
  url = {http://arxiv.org/abs/2508.06649v2},
  year = {2025},
}

@article{elchafei2025span-level,
  abstract = {Detecting spans of hallucination in LLM-generated answers is crucial for improving factual consistency. This paper presents a span-level hallucination detection framework for the SemEval-2025 Shared Task, focusing on English and Arabic texts. Our approach integrates Semantic Role Labeling (SRL) to decompose the answer into atomic roles, which are then compared with a retrieved reference context obtained via question-based LLM prompting. Using a DeBERTa-based textual entailment model, we evaluate each role semantic alignment with the retrieved context. The entailment scores are further refined through token-level confidence measures derived from output logits, and the combined scores are used to detect hallucinated spans. Experiments on the Mu-SHROOM dataset demonstrate competitive performance. Additionally, hallucinated spans have been verified through fact-checking by prompting GPT-4 and LLaMA. Our findings contribute to improving hallucination detection in LLM-generated responses.},
  archiveprefix = {arXiv},
  author = {Passant Elchafei and Mervet Abu-Elkheir},
  file = {2504.18639v1.pdf},
  journal = {2504.18639v1},
  month = {Apr},
  primaryclass = {cs.CL},
  title = {Span-Level Hallucination Detection for LLM-Generated Answers},
  url = {http://arxiv.org/abs/2504.18639v1},
  year = {2025},
}

@article{hosseini2025perhallueval,
  abstract = {Hallucination is a persistent issue affecting all large language Models (LLMs), particularly within low-resource languages such as Persian. PerHalluEval (Persian Hallucination Evaluation) is the first dynamic hallucination evaluation benchmark tailored for the Persian language. Our benchmark leverages a three-stage LLM-driven pipeline, augmented with human validation, to generate plausible answers and summaries regarding QA and summarization tasks, focusing on detecting extrinsic and intrinsic hallucinations. Moreover, we used the log probabilities of generated tokens to select the most believable hallucinated instances. In addition, we engaged human annotators to highlight Persian-specific contexts in the QA dataset in order to evaluate LLMs' performance on content specifically related to Persian culture. Our evaluation of 12 LLMs, including open- and closed-source models using PerHalluEval, revealed that the models generally struggle in detecting hallucinated Persian text. We showed that providing external knowledge, i.e., the original document for the summarization task, could mitigate hallucination partially. Furthermore, there was no significant difference in terms of hallucination when comparing LLMs specifically trained for Persian with others.},
  archiveprefix = {arXiv},
  author = {Mohammad Hosseini and Kimia Hosseini and Shayan Bali and Zahra Zanjani and Saeedeh Momtazi},
  file = {2509.21104v1.pdf},
  journal = {2509.21104v1},
  month = {Sep},
  primaryclass = {cs.CL},
  title = {PerHalluEval: Persian Hallucination Evaluation Benchmark for Large Language Models},
  url = {http://arxiv.org/abs/2509.21104v1},
  year = {2025},
}



@article{islam2025how,
  abstract = {In the age of misinformation, hallucination -- the tendency of Large Language Models (LLMs) to generate non-factual or unfaithful responses -- represents the main risk for their global utility. Despite LLMs becoming increasingly multilingual, the vast majority of research on detecting and quantifying LLM hallucination are (a) English-centric and (b) focus on machine translation (MT) and summarization, tasks that are less common ``in the wild'' than open information seeking. In contrast, we aim to quantify the extent of LLM hallucination across languages in knowledge-intensive long-form question answering. To this end, we train a multilingual hallucination detection model and conduct a large-scale study across 30 languages and 6 open-source LLM families. We start from an English hallucination detection dataset and rely on MT to generate (noisy) training data in other languages. We also manually annotate gold data for five high-resource languages; we then demonstrate, for these languages, that the estimates of hallucination rates are similar between silver (LLM-generated) and gold test sets, validating the use of silver data for estimating hallucination rates for other languages. For the final rates estimation, we build a knowledge-intensive QA dataset for 30 languages with LLM-generated prompts and Wikipedia articles as references. We find that, while LLMs generate longer responses with more hallucinated tokens for higher-resource languages, there is no correlation between length-normalized hallucination rates of languages and their digital representation. Further, we find that smaller LLMs exhibit larger hallucination rates than larger models.},
  archiveprefix = {arXiv},
  author = {Saad Obaid ul Islam and Anne Lauscher and Goran Glavaš},
  file = {2502.12769v3.pdf},
  journal = {2502.12769v3},
  month = {Feb},
  primaryclass = {cs.CL},
  title = {How Much Do LLMs Hallucinate across Languages? On Multilingual Estimation of LLM Hallucination in the Wild},
  url = {http://arxiv.org/abs/2502.12769v3},
  year = {2025},
}

@article{wang2025joint,
  abstract = {Large Reasoning Models (LRMs) extend large language models with explicit, multi-step reasoning traces to enhance transparency and performance on complex tasks. However, these reasoning traces can be redundant or logically inconsistent, making them a new source of hallucination that is difficult to detect. Existing hallucination detection methods focus primarily on answer-level uncertainty and often fail to detect hallucinations or logical inconsistencies arising from the model's reasoning trace. This oversight is particularly problematic for LRMs, where the explicit thinking trace is not only an important support to the model's decision-making process but also a key source of potential hallucination. To this end, we propose RACE (Reasoning and Answer Consistency Evaluation), a novel framework specifically tailored for hallucination detection in LRMs. RACE operates by extracting essential reasoning steps and computing four diagnostic signals: inter-sample consistency of reasoning traces, entropy-based answer uncertainty, semantic alignment between reasoning and answers, and internal coherence of reasoning. This joint analysis enables fine-grained hallucination detection even when the final answer appears correct. Experiments across datasets and different LLMs demonstrate that RACE outperforms existing hallucination detection baselines, offering a robust and generalizable solution for evaluating LRMs. Our code is available at: https://github.com/bebr2/RACE.},
  archiveprefix = {arXiv},
  author = {Changyue Wang and Weihang Su and Qingyao Ai and Yiqun Liu},
  file = {2506.04832v1.pdf},
  journal = {2506.04832v1},
  month = {Jun},
  primaryclass = {cs.CL},
  title = {Joint Evaluation of Answer and Reasoning Consistency for Hallucination Detection in Large Reasoning Models},
  url = {http://arxiv.org/abs/2506.04832v1},
  year = {2025},
}

@article{gema2025inverse,
  abstract = {We construct evaluation tasks where extending the reasoning length of Large Reasoning Models (LRMs) deteriorates performance, exhibiting an inverse scaling relationship between test-time compute and accuracy. Our evaluation tasks span four categories: simple counting tasks with distractors, regression tasks with spurious features, deduction tasks with constraint tracking, and advanced AI risks. We identify five distinct failure modes when models reason for longer: 1) Claude models become increasingly distracted by irrelevant information; 2) OpenAI o-series models resist distractors but overfit to problem framings; 3) models shift from reasonable priors to spurious correlations; 4) all models show difficulties in maintaining focus on complex deductive tasks; and 5) extended reasoning may amplify concerning behaviors, with Claude Sonnet 4 showing increased expressions of self-preservation. These findings suggest that while test-time compute scaling remains promising for improving model capabilities, it may inadvertently reinforce problematic reasoning patterns. Our results demonstrate the importance of evaluating models across diverse reasoning lengths to identify and address these failure modes in LRMs.},
  archiveprefix = {arXiv},
  author = {Aryo Pradipta Gema and Alexander Hägele and Runjin Chen and Andy Arditi and Jacob Goldman-Wetzler and Kit Fraser-Taliente and Henry Sleight and Linda Petrini and Julian Michael and Beatrice Alex and Pasquale Minervini and Yanda Chen and Joe Benton and Ethan Perez},
  file = {2507.14417v1.pdf},
  journal = {2507.14417v1},
  month = {Jul},
  primaryclass = {cs.AI},
  title = {Inverse Scaling in Test-Time Compute},
  url = {http://arxiv.org/abs/2507.14417v1},
  year = {2025},
}

@article{zhao2025test-time,
  abstract = {Test-time scaling increases inference-time computation by allowing models to generate long reasoning chains, and has shown strong performance across many domains. However, in this work, we show that this approach is not yet effective for knowledge-intensive tasks, where high factual accuracy and low hallucination rates are essential. We conduct a comprehensive evaluation of test-time scaling using 12 reasoning models on two knowledge-intensive benchmarks. Our results reveal that increasing test-time computation does not consistently improve accuracy and, in many cases, it even leads to more hallucinations. We then analyze how extended reasoning affects hallucination behavior. We find that reduced hallucinations often result from the model choosing to abstain after thinking more, rather than from improved factual recall. Conversely, for some models, longer reasoning encourages attempts on previously unanswered questions, many of which result in hallucinations. Case studies show that extended reasoning can induce confirmation bias, leading to overconfident hallucinations. Despite these limitations, we observe that compared to non-thinking, enabling thinking remains beneficial. Code and data are available at https://github.com/XuZhao0/tts-knowledge},
  archiveprefix = {arXiv},
  author = {James Xu Zhao and Bryan Hooi and See-Kiong Ng},
  file = {2509.06861v1.pdf},
  journal = {2509.06861v1},
  month = {Sep},
  primaryclass = {cs.AI},
  title = {Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet},
  url = {http://arxiv.org/abs/2509.06861v1},
  year = {2025},
}

@article{liang2025reasoning,
  abstract = {Retrieval-Augmented Generation (RAG) has emerged as a powerful framework to overcome the knowledge limitations of Large Language Models (LLMs) by integrating external retrieval with language generation. While early RAG systems based on static pipelines have shown effectiveness in well-structured tasks, they struggle in real-world scenarios requiring complex reasoning, dynamic retrieval, and multi-modal integration. To address these challenges, the field has shifted toward Reasoning Agentic RAG, a paradigm that embeds decision-making and adaptive tool use directly into the retrieval process. In this paper, we present a comprehensive review of Reasoning Agentic RAG methods, categorizing them into two primary systems: predefined reasoning, which follows fixed modular pipelines to boost reasoning, and agentic reasoning, where the model autonomously orchestrates tool interaction during inference. We analyze representative techniques under both paradigms, covering architectural design, reasoning strategies, and tool coordination. Finally, we discuss key research challenges and propose future directions to advance the flexibility, robustness, and applicability of reasoning agentic RAG systems. Our collection of the relevant research has been organized into a https://github.com/ByebyeMonica/Reasoning-Agentic-RAG.},
  archiveprefix = {arXiv},
  author = {Jintao Liang and Gang Su and Huifeng Lin and You Wu and Rui Zhao and Ziyue Li},
  file = {2506.10408v1.pdf},
  journal = {2506.10408v1},
  month = {Jun},
  primaryclass = {cs.AI},
  title = {Reasoning RAG via System 1 or System 2: A Survey on Reasoning Agentic Retrieval-Augmented Generation for Industry Challenges},
  url = {http://arxiv.org/abs/2506.10408v1},
  year = {2025},
}

@article{li2025towards,
  abstract = {Retrieval-Augmented Generation (RAG) lifts the factuality of Large Language Models (LLMs) by injecting external knowledge, yet it falls short on problems that demand multi-step inference; conversely, purely reasoning-oriented approaches often hallucinate or mis-ground facts. This survey synthesizes both strands under a unified reasoning-retrieval perspective. We first map how advanced reasoning optimizes each stage of RAG (Reasoning-Enhanced RAG). Then, we show how retrieved knowledge of different type supply missing premises and expand context for complex inference (RAG-Enhanced Reasoning). Finally, we spotlight emerging Synergized RAG-Reasoning frameworks, where (agentic) LLMs iteratively interleave search and reasoning to achieve state-of-the-art performance across knowledge-intensive benchmarks. We categorize methods, datasets, and open challenges, and outline research avenues toward deeper RAG-Reasoning systems that are more effective, multimodally-adaptive, trustworthy, and human-centric. The collection is available at https://github.com/DavidZWZ/Awesome-RAG-Reasoning.},
  archiveprefix = {arXiv},
  author = {Yangning Li and Weizhi Zhang and Yuyao Yang and Wei-Chieh Huang and Yaozu Wu and Junyu Luo and Yuanchen Bei and Henry Peng Zou and Xiao Luo and Yusheng Zhao and Chunkit Chan and Yankai Chen and Zhongfen Deng and Yinghui Li and Hai-Tao Zheng and Dongyuan Li and Renhe Jiang and Ming Zhang and Yangqiu Song and Philip S. Yu},
  file = {2507.09477v2.pdf},
  journal = {2507.09477v2},
  month = {Jul},
  primaryclass = {cs.CL},
  title = {Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning Systems in LLMs},
  url = {http://arxiv.org/abs/2507.09477v2},
  year = {2025},
}

@article{keleg2025llm,
  abstract = {Large language models (LLMs) have the potential of being useful tools that can automate tasks and assist humans. However, these models are more fluent in English and more aligned with Western cultures, norms, and values. Arabic-specific LLMs are being developed to better capture the nuances of the Arabic language, as well as the views of the Arabs. Yet, Arabs are sometimes assumed to share the same culture. In this position paper, I discuss the limitations of this assumption and provide preliminary thoughts for how to build systems that can better represent the cultural diversity within the Arab world. The invalidity of the cultural homogeneity assumption might seem obvious, yet, it is widely adopted in developing multilingual and Arabic-specific LLMs. I hope that this paper will encourage the NLP community to be considerate of the cultural diversity within various communities speaking the same language.},
  archiveprefix = {arXiv},
  author = {Amr Keleg},
  file = {2503.15003v1.pdf},
  journal = {2503.15003v1},
  month = {Mar},
  primaryclass = {cs.CL},
  title = {LLM Alignment for the Arabs: A Homogenous Culture or Diverse Ones?},
  url = {http://arxiv.org/abs/2503.15003v1},
  year = {2025},
}

@article{pavlova2025multi-stage,
  abstract = {This study examines the use of Natural Language Processing (NLP) technology within the Islamic domain, focusing on developing an Islamic neural retrieval model. By leveraging the robust XLM-R model, the research employs a language reduction technique to create a lightweight bilingual large language model (LLM). Our approach for domain adaptation addresses the unique challenges faced in the Islamic domain, where substantial in-domain corpora exist only in Arabic while limited in other languages, including English.



The work utilizes a multi-stage training process for retrieval models, incorporating large retrieval datasets, such as MS MARCO, and smaller, in-domain datasets to improve retrieval performance. Additionally, we have curated an in-domain retrieval dataset in English by employing data augmentation techniques and involving a reliable Islamic source. This approach enhances the domain-specific dataset for retrieval, leading to further performance gains.



The findings suggest that combining domain adaptation and a multi-stage training method for the bilingual Islamic neural retrieval model enables it to outperform monolingual models on downstream retrieval tasks.},
  archiveprefix = {arXiv},
  author = {Vera Pavlova},
  file = {2501.10175v1.pdf},
  journal = {2501.10175v1},
  month = {Jan},
  primaryclass = {cs.CL},
  title = {Multi-stage Training of Bilingual Islamic LLM for Neural Passage Retrieval},
  url = {http://arxiv.org/abs/2501.10175v1},
  year = {2025},
}

@article{mekki2025nilechat,
  abstract = {Enhancing the linguistic capabilities of Large Language Models (LLMs) to include low-resource languages is a critical research area. Current research directions predominantly rely on synthetic data generated by translating English corpora, which, while demonstrating promising linguistic understanding and translation abilities, often results in models aligned with source language culture. These models frequently fail to represent the cultural heritage and values of local communities. This work proposes a methodology to create both synthetic and retrieval-based pre-training data tailored to a specific community, considering its (i) language, (ii) cultural heritage, and (iii) cultural values. We demonstrate our methodology using Egyptian and Moroccan dialects as testbeds, chosen for their linguistic and cultural richness and current underrepresentation in LLMs. As a proof-of-concept, we develop NileChat, a 3B parameter Egyptian and Moroccan Arabic LLM adapted for Egyptian and Moroccan communities, incorporating their language, cultural heritage, and values. Our results on various understanding, translation, and cultural and values alignment benchmarks show that NileChat outperforms existing Arabic-aware LLMs of similar size and performs on par with larger models. This work addresses Arabic dialect in LLMs with a focus on cultural and values alignment via controlled synthetic data generation and retrieval-augmented pre-training for Moroccan Darija and Egyptian Arabic, including Arabizi variants, advancing Arabic NLP for low-resource communities. We share our methods, data, and models with the community to promote the inclusion and coverage of more diverse communities in cultural LLM development: https://github.com/UBC-NLP/nilechat .},
  archiveprefix = {arXiv},
  author = {Abdellah El Mekki and Houdaifa Atou and Omer Nacar and Shady Shehata and Muhammad Abdul-Mageed},
  file = {2505.18383v3.pdf},
  journal = {2505.18383v3},
  month = {May},
  primaryclass = {cs.CL},
  title = {NileChat: Towards Linguistically Diverse and Culturally Aware LLMs for Local Communities},
  url = {http://arxiv.org/abs/2505.18383v3},
  year = {2025},
}

@inproceedings{bouchekif-etal-2025-qias,
  abstract = {
This paper provides a comprehensive overview of the QIAS 2025 shared task,
organized as part of the ArabicNLP 2025 conference and co-located with EMNLP
2025. The task was designed for the evaluation of large language models in
the complex domains of religious and legal reasoning. It comprises two
subtasks: (1) Islamic Inheritance Reasoning, requiring models to compute
inheritance shares according to Islamic jurisprudence, and (2) Islamic
Knowledge Assessment, which covers a range of traditional Islamic
disciplines. Both subtasks were structured as multiple-choice question
answering challenges, with questions stratified by varying difficulty levels.
The shared task attracted significant interest, with 44 teams participating
in the development phase, from which 18 teams advanced to the final test
phase. Of these, 6 teams submitted entries for both subtasks, 8 for Task 1
only, and two for Task 3 only. Ultimately, 16 teams submitted system
description papers. Herein, we detail the task{'}s motivation, dataset
construction, evaluation protocol, and present a summary of the participating
systems and their results.},
  address = {Suzhou, China},
  author = {
Bouchekif, Abdessalam  and

Rashwani, Samer  and

Mohamed, Emad Soliman Ali  and

Alkhatib, Mutaz  and

Sbahi, Heba  and

Gaben, Shahd  and

Zaghouani, Wajdi  and

Erbad, Aiman  and

Ghaly, Mohammed},
  booktitle = {
Proceedings of The Third Arabic Natural Language Processing Conference:
Shared Tasks},
  doi = {10.18653/v1/2025.arabicnlp-sharedtasks.117},
  editor = {
Darwish, Kareem  and

Ali, Ahmed  and

Abu Farha, Ibrahim  and

Touileb, Samia  and

Zitouni, Imed  and

Abdelali, Ahmed  and

Al-Ghamdi, Sharefah  and

Alkhereyf, Sakhar  and

Zaghouani, Wajdi  and

Khalifa, Salam  and

AlKhamissi, Badr  and

Almatham, Rawan  and

Hamed, Injy  and

Alyafeai, Zaid  and

Alowisheq, Areeb  and

Inoue, Go  and

Mrini, Khalil  and

Alshammari, Waad},
  isbn = {979-8-89176-356-2},
  month = {November},
  pages = {851--860},
  publisher = {Association for Computational Linguistics},
  title = {
{QIAS} 2025: Overview of the Shared Task on Islamic Inheritance Reasoning and
Knowledge Assessment},
  url = {https://aclanthology.org/2025.arabicnlp-sharedtasks.117/},
  year = {2025},
}
@inproceedings{saleh2020shamela,
  title={Shamela: A Large-Scale Historical Arabic Corpus},
  author={Saleh, Ahmed and Al-Khalifa, Hend},
  booktitle={Proceedings of the LREC 2020 Workshop on Language Resources and Evaluation},
  year={2020},
  publisher={ELRA}
}

@article{alrabiah2014ksucca,
  title={KSUCCA: A Key to Exploring Arabic Historical Linguistics},
  author={Alrabiah, Maha and Al-Salman, AbdulMalik and Atwell, Eric},
  journal={International Journal of Computational Linguistics (IJCL)},
  volume={5},
  number={2},
  pages={27--36},
  year={2014}
}

@misc{zerrouki2017tashkeela,
  title={Tashkeela: Novel Corpus of Arabic Vocalized Texts, Data for Auto-Diacritization Systems},
  author={Zerrouki, Taha and Balla, Amar},
  year={2017},
  howpublished={Mendeley Data, V2},
  doi={10.17632/45bi5514-2}
}

@article{dukes2010morphological,
  title={Morphological Annotation of Quranic Arabic},
  author={Dukes, Kais and Habash, Nizar},
  journal={Language Resources and Evaluation},
  volume={44},
  pages={453--482},
  year={2010}
}

@misc{yousef2025islamicdata,
  title={Islamic Data: A Comprehensive Resource for Islamic Knowledge},
  author={Abuz, Yousef},
  year={2025},
  howpublished={\url{https://www.kaggle.com/datasets/yousefabuz17/islamic-data}}
}

@misc{noorlib2024,
  title={Noor Digital Library: A Massive Repository of Arabic Heritage},
  author={NoorLib},
  year={2024},
  howpublished={\url{https://www.noor-book.com}}
}

@misc{sunnah2024,
  title={Sunnah.com: The Hadith of the Prophet Muhammad (pbuh)},
  author={Sunnah.com},
  year={2024},
  howpublished={\url{https://sunnah.com}}
}

@inproceedings{salman2025quranmd,
  title        = {QURAN-MD: A Fine-Grained Multilingual Multimodal Dataset of the Quran},
  author       = {Salman, Muhammad Umar and Qazi, Mohammad Areeb and Alam, Mohammed Talha},
  booktitle    = {Proceedings of the 5th Muslims in ML Workshop at NeurIPS 2025},
  year         = {2025},
  url          = {https://openreview.net/forum?id=NQ6er5I4PK},
  abstract     = {This paper introduces QURAN-MD, a comprehensive multimodal resource for Quranic studies that unifies text and audio at both verse and word levels. For each verse, the dataset includes the original Arabic text, an English translation, and a phonetic transliteration, alongside recitations from 32 different reciters to capture diverse styles and dialects. At the word level, tokens are aligned with their script, translation, transliteration, and audio segments, enabling fine-grained analysis of pronunciation and phonology. The dataset is designed to support tasks such as speech recognition, text-to-speech, tajweed analysis, semantic retrieval, and educational tutoring for Quranic content. It provides a public benchmark for multimodal modeling of a central Islamic text and aims to facilitate both research and community-facing applications.}
}

@article{namoun2024multimodalScraping,
  title        = {A Multimodal Data Scraping Tool for Collecting Authentic Islamic Text Datasets},
  author       = {Namoun, Abdallah and Humayun, Mohammad Ali and Nawaz, Waqas},
  journal      = {International Journal of Advanced Computer Science and Applications},
  volume       = {15},
  number       = {12},
  year         = {2024},
  url          = {https://thesai.org/Downloads/Volume15No12/Paper_24-A_Multimodal_Data_Scraping_Tool.pdf},
  abstract     = {The paper presents an automated scraping tool tailored to build high-quality Islamic text datasets from multiple modalities and platforms. The system integrates four pipelines that extract text from static web pages, dynamic web pages, YouTube videos with transcripts, and audio-only content via speech-to-text. It targets authoritative Islamic sources such as official Saudi religious institutions and verified scholarly websites, with the goal of mitigating the use of unvetted or unreliable content by machine learning systems. The resulting corpus is curated in Arabic and intended for downstream tasks in NLP and large language models that require trustworthy Islamic knowledge. The authors demonstrate the feasibility and scalability of this approach in assembling a sizeable, more reliable Islamic knowledge base.}
}

@article{badry2018qtid,
  title        = {QTID: Quran Text Image Dataset},
  author       = {Badry, Mahmoud and Hassan, Hesham and Bayomi, Hanaa and Oakasha, Hussien},
  journal      = {International Journal of Advanced Computer Science and Applications},
  volume       = {9},
  number       = {3},
  pages        = {385--391},
  year         = {2018},
  doi          = {10.14569/IJACSA.2018.090351},
  url          = {https://thesai.org/Publications/ViewPaper?Code=IJACSA&Issue=3&SerialNo=51&Volume=9},
  abstract     = {QTID is introduced as a large-scale image dataset of Quranic Arabic text to support optical character recognition and Arabic text understanding in images. The dataset contains hundreds of thousands of word-level images, including full diacritics and Quranic marks, extracted from the printed Mushaf. The authors provide statistics on character distribution and data splits for training, validation, and testing. By offering a modern, diacritic-rich Arabic dataset specifically grounded in Quranic text, QTID aims to advance OCR pipelines and deep learning models designed for Arabic script and religious-text analysis.}
}

@article{ghafouri2023islamicpcqa,
  title        = {IslamicPCQA: A Dataset for Persian Multi-hop Complex Question Answering in Islamic Text Resources},
  author       = {Ghafouri, Arash and Naderi, Hasan and Aghajani Asl, Mohammad and Firouzmandi, Mahdi},
  journal      = {arXiv preprint arXiv:2304.11664},
  year         = {2023},
  url          = {https://arxiv.org/abs/2304.11664},
  abstract     = {IslamicPCQA is a Persian-language dataset designed for multi-hop complex question answering over Islamic encyclopedias and related reference texts. The collection comprises over twelve thousand question–answer pairs, each requiring reasoning over multiple unstructured passages rather than a single paragraph. The dataset construction is inspired by the HotpotQA methodology but adapted to the linguistic and stylistic characteristics of Persian and Islamic scholarship. Supporting facts and key sentences are annotated to make reasoning chains more explicit. The resource is intended to benchmark Persian QA models on complex, multi-step reasoning about Islamic concepts, personalities, and historical topics.}
}

@article{salameh2024quranicAudio,
  title        = {Quranic Audio Dataset: Crowdsourced and Labeled Recitation from Non-Arabic Speakers},
  author       = {Salameh, Raghad and Al Mdfaa, Mohamad and Askarbekuly, Nursultan and Mazzara, Manuel},
  journal      = {Procedia Computer Science},
  volume       = {246},
  pages        = {2684--2693},
  year         = {2024},
  doi          = {10.1016/j.procs.2024.09.404},
  abstract     = {This work presents a Quranic audio dataset collected from non-Arabic speakers via a crowdsourcing pipeline integrated into a mobile application. The authors describe an API and platform for gathering verse recitations, together with procedures for quality control and labeling of the audio. The resulting dataset captures typical pronunciation challenges and variability among learners who do not speak Arabic natively. It is proposed as a foundation for training and evaluating AI systems that support Quran recitation learning, mispronunciation detection, and pronunciation feedback tailored to non-native speakers.}
}

@inproceedings{mhnaa2025islamicSigns,
  title        = {Development of an Intelligent System for Recognizing Islamic Religious Visual Signs in the Arabic Language},
  author       = {Mhnaa, Duaa and Dayoub, Yaroub and Salman, Jafar},
  booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops},
  year         = {2025},
  pages        = {4874--4882},
  abstract     = {The authors propose a vision-based system for recognizing Islamic religious signs expressed in Arabic sign language. They discuss the challenges of modeling complex, temporally dynamic gestures used in religious communication and worship contexts. The framework combines modern computer vision techniques with sequence modeling to recognize signs that encode Quranic concepts, supplications, and ritual phrases. Special attention is given to handling overlapping motions and variable signing styles. The system is positioned as a step toward accessible assistive technology for deaf and hard-of-hearing Muslims in religious and educational settings.}
}

@inproceedings{lahmar2025islamtrust,
  title        = {IslamTrust: A Benchmark for LLMs Alignment with Islamic Values},
  author       = {Lahmar, Abderraouf and Arafat, Md Easin and Farou, Zakarya and Mahmud, Mufti},
  booktitle    = {Proceedings of the 5th Muslims in ML Workshop at NeurIPS 2025},
  year         = {2025},
  url          = {https://openreview.net/forum?id=PBcv90iKFB},
  abstract     = {IslamTrust introduces a multilingual benchmark for evaluating how well large language models align with consensus-based Islamic ethical principles. The benchmark is built from scenarios and questions derived from classical and contemporary Islamic scholarship across Sunni schools of thought. The authors detail rigorous guidelines for constructing prompts and labeling reference answers to minimize subjectivity and bias. Multiple Arabic-focused and multilingual LLMs are evaluated in both Arabic and English, revealing substantial misalignment, inconsistencies, and misunderstandings of Islamic ethics. The benchmark is released along with code to facilitate further research on culturally and religiously grounded model alignment.}
}

@inproceedings{faruk2025adab,
  title        = {ADAB: A Culturally-Aligned Automated Response Generation Framework for Islamic App Reviews by Integrating ABSA and Hybrid RAG},
  author       = {Faruk, K. M. Tahlil Mahfuz and Talha, Mushfiqur Rahman and Ahamad, H. M. Kawsar and Shams, Mohammad Galib and Hossain, Nabil Mosharraf and Raiyan, Syed Rifat and Hasan, Md Kamrul and Mahmud, Hasan and Islam, Riasat},
  booktitle    = {Proceedings of the 5th Muslims in ML Workshop at NeurIPS 2025},
  year         = {2025},
  url          = {https://openreview.net/pdf?id=PnWmDdwTXE},
  abstract     = {ADAB is a framework for generating automated responses to user reviews of Islamic mobile applications while respecting Islamic etiquette and cultural norms. The system combines aspect-based sentiment analysis to identify fine-grained concerns in reviews with a hybrid retrieval-augmented generation pipeline. A curated corpus of Islamic app reviews and domain texts provides grounded context for the responses. Prompting strategies are designed to embed adab-inspired politeness, humility, and religiously appropriate phrasing. Human evaluations show that ADAB’s responses are preferred to baseline generations in terms of specificity, relevance, and cultural alignment, demonstrating the value of integrating religious norms into response-generation systems.}
}

@inproceedings{aljaji2025quranBenchmark,
  title        = {Benchmarking Generative AI on Quranic Knowledge},
  author       = {Aljaji, Hamza and Mohamed, Rawan and Ibrahim, Roaa and Alkanani, Abdallah and Elaradi, Arwa Abdulhakim and Asgari, Ehsaneddin},
  booktitle    = {Proceedings of the 5th Muslims in ML Workshop at NeurIPS 2025},
  year         = {2025},
  url          = {https://www.musiml.org/events/2025-NeurIPS/accepted_papers.html},
  abstract     = {This paper proposes a benchmark to systematically evaluate large language models and retrieval systems on Quran-centered question answering. The authors construct a human-reviewed set of hundreds of multiple-choice questions derived from Quranic verses, stratified by levels of cognitive difficulty using Bloom’s taxonomy and by verse familiarity. Models are assessed both on selecting correct answers and on identifying the originating verse. Results show that instruction-tuned and Arabic-focused LLMs achieve moderate accuracy, with performance dropping sharply on higher-order reasoning and less familiar verses. A dense retriever with RAG-style querying outperforms pure generative setups on some metrics. The benchmark highlights current limitations of general-purpose LLMs in handling nuanced Quranic semantics and context.}
}

@inproceedings{omarov2025zakatABM,
  title        = {LLM Agent-Based Modeling for Zakat Policy Simulation in Islamic Finance},
  author       = {Omarov, Zaur and Sultimov, Roman and Volkov, Aleksandr and Maximov, Yury},
  booktitle    = {Proceedings of the 5th Muslims in ML Workshop at NeurIPS 2025},
  year         = {2025},
  url          = {https://www.musiml.org/events/2025-NeurIPS/accepted_papers.html},
  abstract     = {The authors present an agent-based modeling framework driven by large language models to explore zakat policy design within Islamic finance. LLM-powered agents represent different actors such as payers, beneficiaries, and regulators, each endowed with textual decision rules constrained by Sharia principles. The simulation environment models wealth accumulation, redistribution, and poverty dynamics under varying zakat collection and distribution schemes. Preliminary experiments suggest that LLM-based agents can capture nuanced behaviors and policy trade-offs that are harder to encode in hand-crafted rule systems. The work aims to provide a computational tool for policymakers and scholars to explore the socioeconomic impact of alternative zakat policies in a controlled but realistic setting.}
}

@inproceedings{hasan2025sparseChecklist,
  title        = {Sparse-Checklist Prompting for Arabic Grammar Tutoring: Fast, Token-Efficient Feedback},
  author       = {Hasan, Zayan},
  booktitle    = {Proceedings of the 5th Muslims in ML Workshop at NeurIPS 2025},
  year         = {2025},
  url          = {https://www.musiml.org/events/2025-NeurIPS/accepted_papers.html},
  abstract     = {This work studies token-efficient prompting strategies for Arabic grammar tutoring, particularly in community and religious education contexts where quick, low-cost feedback is important. Instead of generating long-form explanations, the model is constrained to select a pedagogical hint from a small checklist of tagged skills such as agreement errors, pronoun usage, prepositions, or definiteness. A lightweight routing scheme separates clearly correct answers from those needing detailed feedback. Experiments on a labeled dataset of learner responses show that sparse-checklist prompting improves both correctness and latency compared to a direct free-form feedback baseline, while preserving interpretability of the hints. The approach offers a practical template for scalable LLM-based support in Arabic language and Quranic grammar instruction.}
}

@inproceedings{sahebi2025quranRefs,
  title        = {Context-Aware Extraction of Quranic References: A Hybrid Language Model- and Rule-Based Approach},
  author       = {Sahebi, Alireza and Hemmatyar, Mohammadmahdi and Asgari, Ehsaneddin},
  booktitle    = {Proceedings of the 5th Muslims in ML Workshop at NeurIPS 2025},
  year         = {2025},
  url          = {https://www.musiml.org/events/2025-NeurIPS/accepted_papers.html},
  abstract     = {The paper introduces a hybrid system for detecting references to Quranic verses in modern text, including online discourse and religious content. A language-model-based component first identifies candidate spans that are likely intentional Quranic allusions rather than incidental lexical overlap. These candidates are then validated and normalized using rule-based matching against canonical Quran text, returning both text spans and corresponding surah and verse identifiers. The approach addresses hallucinated or inaccurate Quran references produced by general-purpose language models by offering an automatic verification layer. The tool aims to support digital humanities research, content moderation, and the reliable presentation of Quranic citations in AI-generated text.}
}

@inproceedings{mazid2025tajweedai,
  title        = {TajweedAI: A Hybrid ASR-Classifier for Real-Time Qalqalah Detection in Quranic Recitation},
  author       = {Mazid, Nabhan and Ahmad, Muaz},
  booktitle    = {Proceedings of the 5th Muslims in ML Workshop at NeurIPS 2025},
  year         = {2025},
  url          = {https://openreview.net/forum?id=AauWmDPOIf},
  abstract     = {TajweedAI focuses on automatic detection of the Qalqalah rule, a specific phonetic phenomenon in Quranic recitation. The system combines an automatic speech recognition model for time alignment with a dedicated classifier that detects whether the Qalqalah articulation is correctly realized in a given segment. The authors build an expert-annotated dataset at fine temporal resolution and explore iterative training strategies, including hard negative mining, to refine the classifier. Experiments show that the model can achieve perfect accuracy on a specialized internal validation set, though generalization to broader recitation remains challenging. The work demonstrates the feasibility of targeted tajweed error detection as a component of computer-assisted Quran recitation training tools.}
}

@inproceedings{rushdi2025techVsCultural,
  title        = {Technical vs Cultural: Evaluating LLMs in Arabic},
  author       = {Rushdi, Ahmad A.},
  booktitle    = {Proceedings of the 5th Muslims in ML Workshop at NeurIPS 2025},
  year         = {2025},
  url          = {https://www.musiml.org/events/2025-NeurIPS/accepted_papers.html},
  abstract     = {This paper presents a pilot evaluation of several Arabic-specialized and frontier large language models on a curated set of Arabic prompts. The evaluation separates technical capabilities, such as mathematical reasoning and factual accuracy, from cultural and linguistic competencies relevant to Arabic-speaking and often Muslim users. Models are tested on a small but diverse set of tasks spanning general knowledge, trust and safety, and culturally grounded queries. Results suggest that frontier models tend to excel at technical correctness, while some Arabic-specialized models perform competitively on stylistic and cultural dimensions. The findings underline the need for balanced evaluation frameworks that consider both technical performance and cultural-linguistic alignment in Arabic and Islamic contexts.}
}

@inproceedings{kamaly2025inclusiveNLP,
  title        = {Towards Inclusive NLP: Evaluating LLMs on Low-Resource Indo-Iranian Languages},
  author       = {Modarres Kamaly, Arta},
  booktitle    = {Proceedings of the 5th Muslims in ML Workshop at NeurIPS 2025},
  year         = {2025},
  url          = {https://www.musiml.org/events/2025-NeurIPS/accepted_papers.html},
  abstract     = {The study evaluates multilingual language models on several Indo-Iranian languages, including both higher-resource and marginalized varieties widely spoken in Muslim communities. The author assembles small evaluation sets drawn from sources such as Quran translations, Wikipedia, and parallel corpora. Tasks cover translation, factual question answering, and sentiment classification. Results reveal a large performance gap between better-resourced languages like Farsi and lower-resourced regional languages such as Mazandarani and Gilaki. Common failure modes include cultural mistranslations and dialect confusions. The paper argues for community-driven data collection and lightweight adaptation techniques to make NLP technologies more inclusive for speakers of under-served Muslim-majority languages.}
}
@article{MohammedAftina2025,
  title = {Aftina: enhancing stability and preventing hallucination in AI-based Islamic fatwa generation using LLMs and RAG},
  volume = {37},
  ISSN = {1433-3058},
  url = {http://dx.doi.org/10.1007/s00521-025-11229-y},
  DOI = {10.1007/s00521-025-11229-y},
  number = {25},
  journal = {Neural Computing and Applications},
  publisher = {Springer Science and Business Media LLC},
  author = {Mohammed,  Marryam Yahya and Ali,  Sama Ayman and Ali,  Salma Khaled and Majeed,  Ayad Abdul and Mohamed,  Ensaf Hussein},
  year = {2025},
  month = jun,
  pages = {20957–20982}
}
@misc{youssef2025islamicqaegyptian,
  title        = {islamic-qa-egyptian-arabic},
  author       = {Youssef, Omar},
  year         = {2025},
  howpublished = {Hugging Face dataset},
  url          = {https://huggingface.co/datasets/Omar-youssef/islamic-qa-egyptian-arabic},
  note         = {Accessed: 2025-12-30. License: Apache-2.0}
}

@inproceedings{altammami2020hadithparallel,
  title        = {The Arabic--English Parallel Corpus of Authentic Hadith},
  author       = {Altammami, Shatha and Atwell, Eric and Alsalka, Ammar},
  booktitle    = {International Conference on Islamic Applications in Computer Science and Technologies (IMAN 2019)},
  year         = {2020},
  pages        = {1--10},
  note         = {Published online: 2020-06-30 (IJASAT proceedings record via White Rose Research Online)},
  url          = {https://eprints.whiterose.ac.uk/id/eprint/160497/}
}

@article{mghari2022sanadset,
  title   = {Sanadset 650K: Data on Hadith narrators},
  author  = {Mghari, Mohammed and Bouras, Omar and El Hibaoui, Abdelaaziz},
  journal = {Data in Brief},
  volume  = {44},
  pages   = {108540},
  year    = {2022},
  doi     = {10.1016/j.dib.2022.108540}
}

@misc{altammami2023quranhadithdatasets,
  title        = {Quran\_Hadith\_Datasets},
  author       = {Altammami, Shatha},
  year         = {2023},
  howpublished = {GitHub repository},
  url          = {https://github.com/ShathaTm/Quran_Hadith_Datasets},
}
